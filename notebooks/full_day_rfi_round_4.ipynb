{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-title-r4",
   "metadata": {},
   "source": [
    "# Fourth Round of Full Day RFI Flagging Using FRF-Filtered pI SNRs\n",
    "\n",
    "\n",
    "**by Josh Dillon**, last updated February 19, 2026\n",
    "\n",
    "# TODO: EDIT \n",
    "This notebook brings together the results of the [single-baseline pI FRF SNR notebook](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/single_baseline_pI_FRF_SNR.ipynb) to make a set of flagging decisions after inpainting. This approach is iterative, and very similar to [Round 3 flagging](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/full_day_rfi_round_3.ipynb), though it uses delay+fringe-rate filtered pseudo-Stokes pI SNRs rather than 2D-filtered SNRs, includes integration of Round 3 flags for watershed seeding, and detects persistent single-channel RFI. \n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "# [• Figure 1: Waterfall of pI z-Score Before Round 4 Flagging](#Figure-1:-Waterfall-of-pI-z-Score-Before-Round-4-Flagging)\n",
    "# [• Figure 2: Histogram of z-Scores](#Figure-2:-Histogram-of-z-Scores)\n",
    "# [• Figure 3: Waterfall of pI z-Score After Round 4 Flagging](#Figure-3:-Waterfall-of-pI-z-Score-After-Round-4-Flagging)\n",
    "# [• Figure 4: Summary of Flags Before and After Round 4 Flagging](#Figure-4:-Summary-of-Flags-Before-and-After-Round-4-Flagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5-timing-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T17:33:25.623192Z",
     "iopub.status.busy": "2026-02-19T17:33:25.622953Z",
     "iopub.status.idle": "2026-02-19T17:33:26.023297Z",
     "shell.execute_reply": "2026-02-19T17:33:26.022810Z",
     "shell.execute_reply.started": "2026-02-19T17:33:25.623173Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6-imports-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T17:33:26.040530Z",
     "iopub.status.busy": "2026-02-19T17:33:26.040288Z",
     "iopub.status.idle": "2026-02-19T17:34:13.112389Z",
     "shell.execute_reply": "2026-02-19T17:34:13.111885Z",
     "shell.execute_reply.started": "2026-02-19T17:33:26.040507Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import yaml\n",
    "import glob\n",
    "import re\n",
    "import matplotlib\n",
    "from scipy.signal import convolve, convolve2d\n",
    "from pyuvdata import UVFlag\n",
    "from hera_qm import xrfi\n",
    "from hera_cal import io, flag_utils\n",
    "from hera_filters import dspec\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.coordinates import Angle\n",
    "import astropy.constants as const\n",
    "from hera_cal.utils import eq2top_m\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "_ = np.seterr(all='ignore')  # get rid of red warnings\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6g7-params-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:46:37.328275Z",
     "iopub.status.busy": "2026-02-19T23:46:37.328026Z",
     "iopub.status.idle": "2026-02-19T23:46:37.357456Z",
     "shell.execute_reply": "2026-02-19T23:46:37.356855Z",
     "shell.execute_reply.started": "2026-02-19T23:46:37.328254Z"
    }
   },
   "outputs": [],
   "source": [
    "RED_AVG_FILE = os.environ.get(\"RED_AVG_FILE\", None)\n",
    "# RED_AVG_FILE = '/lustre/aoc/projects/hera/h6c-analysis/IDR3/2459935/zen.2459935.25792.sum.smooth_calibrated.red_avg.uvh5'\n",
    "\n",
    "CORNER_TURN_MAP_YAML = os.environ.get(\"CORNER_TURN_MAP_YAML\", \n",
    "                                        os.path.join(os.path.dirname(RED_AVG_FILE), \"single_baseline_files/corner_turn_map.yaml\"))\n",
    "SNR_SUFFIX = os.environ.get(\"SNR_SUFFIX\", \".inpainted.pI_FRF_SNR.uvh5\")\n",
    "OUTFILE = os.environ.get(\"OUTFILE\", None)\n",
    "if OUTFILE is None:\n",
    "    jdstr = [s for s in os.path.basename(RED_AVG_FILE).split('.') if s.isnumeric()][0]\n",
    "    OUTFILE = os.path.basename(RED_AVG_FILE).split(jdstr)[0] + jdstr + '.flag_waterfall_round_4.h5'\n",
    "    OUTFILE = os.path.join(os.path.dirname(CORNER_TURN_MAP_YAML), OUTFILE)\n",
    "\n",
    "ROUND_3_FLAG_FILE = os.environ.get(\"ROUND_3_FLAG_FILE\", None)\n",
    "if ROUND_3_FLAG_FILE is None:\n",
    "    ROUND_3_FLAG_FILE = OUTFILE.replace('round_4', 'round_3')\n",
    "\n",
    "MIN_SAMP_FRAC = float(os.environ.get(\"MIN_SAMP_FRAC\", .15))\n",
    "FM_LOW_FREQ = float(os.environ.get(\"FM_LOW_FREQ\", 87.5)) # in MHz\n",
    "FM_HIGH_FREQ = float(os.environ.get(\"FM_HIGH_FREQ\", 108.0)) # in MHz\n",
    "\n",
    "Z_THRESH = float(os.environ.get(\"Z_THRESH\", 4))\n",
    "WS_Z_THRESH = float(os.environ.get(\"WS_Z_THRESH\", 2))\n",
    "AVG_Z_THRESH = float(os.environ.get(\"AVG_Z_THRESH\", 1))\n",
    "MAX_FREQ_FLAG_FRAC = float(os.environ.get(\"MAX_FREQ_FLAG_FRAC\", .25))\n",
    "MAX_TIME_FLAG_FRAC = float(os.environ.get(\"MAX_TIME_FLAG_FRAC\", .25))\n",
    "\n",
    "FREQ_CONV_SIZE  = float(os.environ.get(\"FREQ_CONV_SIZE\", 8.0)) # in MHz\n",
    "\n",
    "SINGLE_CHAN_FLAG_FRAC = float(os.environ.get(\"SINGLE_CHAN_FLAG_FRAC\", .25))\n",
    "_sczt = os.environ.get(\"SINGLE_CHAN_Z_THRESH\", \"\")\n",
    "SINGLE_CHAN_Z_THRESH = float(_sczt) if _sczt else Z_THRESH\n",
    "\n",
    "PULSAR_RA = os.environ.get(\"PULSAR_RA\", \"06h30m49.3s\")\n",
    "PULSAR_DEC = os.environ.get(\"PULSAR_DEC\", \"-28d34m42.6s\")\n",
    "COHERENT_COMBINE = os.environ.get(\"COHERENT_COMBINE\", \"True\").lower() in ('true', '1', 'yes')\n",
    "\n",
    "for setting in ['RED_AVG_FILE', 'CORNER_TURN_MAP_YAML', 'SNR_SUFFIX', 'OUTFILE', 'ROUND_3_FLAG_FILE', 'PULSAR_RA', 'PULSAR_DEC']:\n",
    "    print(f'{setting} = \"{eval(setting)}\"')\n",
    "for setting in ['MIN_SAMP_FRAC', 'FM_LOW_FREQ', 'FM_HIGH_FREQ', 'Z_THRESH', 'WS_Z_THRESH',\n",
    "                'AVG_Z_THRESH', 'MAX_FREQ_FLAG_FRAC', 'MAX_TIME_FLAG_FRAC', 'FREQ_CONV_SIZE',\n",
    "                'SINGLE_CHAN_FLAG_FRAC', 'SINGLE_CHAN_Z_THRESH', 'COHERENT_COMBINE']:\n",
    "    print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6g7h8-corner-turn-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:46:38.032838Z",
     "iopub.status.busy": "2026-02-19T23:46:38.032401Z",
     "iopub.status.idle": "2026-02-19T23:46:41.094091Z",
     "shell.execute_reply": "2026-02-19T23:46:41.093545Z",
     "shell.execute_reply.started": "2026-02-19T23:46:38.032820Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(CORNER_TURN_MAP_YAML, 'r') as file:\n",
    "    corner_turn_map = yaml.unsafe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6g7h8i9-snr-files-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:46:41.095216Z",
     "iopub.status.busy": "2026-02-19T23:46:41.095016Z",
     "iopub.status.idle": "2026-02-19T23:46:41.249063Z",
     "shell.execute_reply": "2026-02-19T23:46:41.248642Z",
     "shell.execute_reply.started": "2026-02-19T23:46:41.095187Z"
    }
   },
   "outputs": [],
   "source": [
    "all_snr_files = [snr_file.replace('.uvh5', SNR_SUFFIX) \n",
    "                 for snr_files in corner_turn_map['files_to_outfiles_map'].values() \n",
    "                 for snr_file in snr_files]\n",
    "extant_snr_files = [snr_file for snr_file in all_snr_files if os.path.exists(snr_file)]\n",
    "print(f'Found {len(extant_snr_files)} SNR files, starting with {extant_snr_files[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g7h8i9j0-load-autos-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:46:41.249790Z",
     "iopub.status.busy": "2026-02-19T23:46:41.249563Z",
     "iopub.status.idle": "2026-02-19T23:46:44.075687Z",
     "shell.execute_reply": "2026-02-19T23:46:44.075125Z",
     "shell.execute_reply.started": "2026-02-19T23:46:41.249774Z"
    }
   },
   "outputs": [],
   "source": [
    "# get autocorrelations\n",
    "# TODO: generalize for not-inpainted data\n",
    "all_outfiles = [outfile.replace('.uvh5', '.inpainted.uvh5') for outfiles in corner_turn_map['files_to_outfiles_map'].values() for outfile in outfiles]\n",
    "for outfile in all_outfiles:\n",
    "    match = re.search(r'\\.(\\d+)_(\\d+)\\.', os.path.basename(outfile))\n",
    "    if match and match.group(1) == match.group(2):\n",
    "        hd_autos = io.HERAData(outfile)\n",
    "        _, _, auto_nsamples = hd_autos.read(polarizations=['ee', 'nn'])\n",
    "        break\n",
    "\n",
    "# For pI data, use the mean of ee and nn auto nsamples as the reference\n",
    "med_auto_nsamples_pI = np.mean([np.median(auto_nsamples[bl]) for bl in auto_nsamples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca0f59-76e8-43e7-89e2-35b5ebd175aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:46:45.141404Z",
     "iopub.status.busy": "2026-02-19T23:46:45.141157Z",
     "iopub.status.idle": "2026-02-19T23:46:45.145573Z",
     "shell.execute_reply": "2026-02-19T23:46:45.145037Z",
     "shell.execute_reply.started": "2026-02-19T23:46:45.141386Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9j0k1l2-load-snr-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:46:45.695875Z",
     "iopub.status.busy": "2026-02-19T23:46:45.695646Z",
     "iopub.status.idle": "2026-02-19T23:52:26.721185Z",
     "shell.execute_reply": "2026-02-19T23:52:26.719865Z",
     "shell.execute_reply.started": "2026-02-19T23:46:45.695859Z"
    }
   },
   "outputs": [],
   "source": [
    "# load up SNRs, counts, and nsamples\n",
    "SNRs = {}\n",
    "SNR_counts = {}\n",
    "SNR_med_nsamples = {}\n",
    "\n",
    "for snr_file in tqdm(extant_snr_files):\n",
    "    hd = io.HERADataFastReader(snr_file)\n",
    "    data, flags, nsamples = hd.read()\n",
    "    for bl in data:\n",
    "        SNRs[bl] = np.where(flags[bl], 0, data[bl])\n",
    "        SNR_counts[bl] = np.where(flags[bl], 0, 1)\n",
    "        SNR_med_nsamples[bl] = np.median(nsamples[bl][~flags[bl]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j0k1l2m3-combine-bls-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:52:26.723793Z",
     "iopub.status.busy": "2026-02-19T23:52:26.723075Z",
     "iopub.status.idle": "2026-02-19T23:52:27.685253Z",
     "shell.execute_reply": "2026-02-19T23:52:27.684716Z",
     "shell.execute_reply.started": "2026-02-19T23:52:26.723773Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine SNRs, excluding those with too few samples and autocorrelations\n",
    "if COHERENT_COMBINE:\n",
    "    ra_source = Angle(PULSAR_RA).radian\n",
    "    dec_source = Angle(PULSAR_DEC).radian\n",
    "    lat_rad = hd.info['latitude'] * np.pi / 180\n",
    "    ha = np.array(hd.lsts) - ra_source\n",
    "    s_eq = np.array([np.cos(dec_source), 0.0, np.sin(dec_source)])\n",
    "    rot = eq2top_m(ha, lat_rad)\n",
    "    s_enu = np.einsum('tij,j->ti', rot, s_eq)\n",
    "    s_diff_over_c = (s_enu - np.array([0., 0., 1.])) / const.c.value\n",
    "    complex_SNR_sum = np.zeros((len(hd.times), len(hd.freqs)), dtype=complex)\n",
    "\n",
    "abs_SNR_sum = np.zeros((len(hd.times), len(hd.freqs)), dtype=float)\n",
    "abs_SNR_count = np.zeros((len(hd.times), len(hd.freqs)), dtype=float)\n",
    "bls_used = []\n",
    "for bl in SNRs:\n",
    "    if np.median(SNR_med_nsamples[bl]) > MIN_SAMP_FRAC * med_auto_nsamples_pI:\n",
    "        bl_len = np.linalg.norm(hd.antpos[bl[0]] - hd.antpos[bl[1]])\n",
    "        if bl_len > 1 and bl_len < 50:\n",
    "            bls_used.append(bl)\n",
    "            if COHERENT_COMBINE:\n",
    "                bl_vec = hd.antpos[bl[0]] - hd.antpos[bl[1]]\n",
    "                tau = np.einsum('ti,i->t', s_diff_over_c, bl_vec)\n",
    "                phs = np.exp(-2j * np.pi * hd.freqs[np.newaxis, :] * tau[:, np.newaxis])\n",
    "                complex_SNR_sum += SNRs[bl] * phs\n",
    "            else:\n",
    "                abs_SNR_sum += np.abs(SNRs[bl])\n",
    "            abs_SNR_count += SNR_counts[bl]\n",
    "\n",
    "if COHERENT_COMBINE:\n",
    "    abs_SNR_sum = np.abs(complex_SNR_sum)\n",
    "    print(f'Coherently combined {len(bls_used)} baselines rephased to {PULSAR_RA}, {PULSAR_DEC}')\n",
    "else:\n",
    "    print(f'Incoherently combined {len(bls_used)} baselines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k1l2m3n4-zscore-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:52:27.686150Z",
     "iopub.status.busy": "2026-02-19T23:52:27.685941Z",
     "iopub.status.idle": "2026-02-19T23:52:27.916855Z",
     "shell.execute_reply": "2026-02-19T23:52:27.916312Z",
     "shell.execute_reply.started": "2026-02-19T23:52:27.686132Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert SNRs to a z-score\n",
    "if COHERENT_COMBINE:\n",
    "    predicted_mean = 1.0 / np.sqrt(np.where(abs_SNR_count > 0, abs_SNR_count, 1))\n",
    "else:\n",
    "    predicted_mean = 1.0\n",
    "sigma = predicted_mean * np.sqrt(2 / np.pi)\n",
    "variance_expected = (4 - np.pi) / 2 * sigma**2 / abs_SNR_count\n",
    "zscore = (abs_SNR_sum / abs_SNR_count - predicted_mean) / variance_expected**.5\n",
    "zscore = np.where(abs_SNR_count == 0, np.nan, zscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055847e4-2896-4b73-85f3-7f14d0295262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:52:27.918286Z",
     "iopub.status.busy": "2026-02-19T23:52:27.918056Z",
     "iopub.status.idle": "2026-02-19T23:52:28.384979Z",
     "shell.execute_reply": "2026-02-19T23:52:28.384387Z",
     "shell.execute_reply.started": "2026-02-19T23:52:27.918269Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Round 3 flags for watershed seeding\n",
    "uvf_r3 = UVFlag(ROUND_3_FLAG_FILE)\n",
    "round3_flags = np.all(uvf_r3.flag_array, axis=-1)\n",
    "assert round3_flags.shape == (len(hd.times), len(hd.freqs)), \\\n",
    "    f\"Round 3 flag shape {round3_flags.shape} doesn't match data shape {(len(hd.times), len(hd.freqs))}\"\n",
    "zscore[round3_flags] = np.nan\n",
    "print(f'Loaded Round 3 flags from {ROUND_3_FLAG_FILE}: {np.mean(round3_flags):.3%} flagged.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13097d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COHERENT_COMBINE:\n",
    "    fig, ax = plt.subplots(figsize=(14, 10), dpi=200)\n",
    "    noise_floor = 1.0 / np.sqrt(np.where(abs_SNR_count > 0, abs_SNR_count, 1))\n",
    "    mean_SNR = abs_SNR_sum / np.where(abs_SNR_count > 0, abs_SNR_count, 1)\n",
    "    to_plot = np.where(abs_SNR_count > 0, mean_SNR / noise_floor, np.nan)\n",
    "    extent = [data.freqs[0] / 1e6, data.freqs[-1] / 1e6,\n",
    "              data.times[-1] - int(data.times[0]), data.times[0] - int(data.times[0])]\n",
    "    im = ax.imshow(to_plot, aspect='auto', cmap='plasma',\n",
    "                   interpolation='none', vmin=0, vmax=5, extent=extent)\n",
    "    plt.colorbar(im, ax=ax, location='top', label='|coherent pI SNR| / noise expectation',\n",
    "                 extend='max', aspect=40, pad=.02)\n",
    "    ax.set_xlabel('Frequency (MHz)')\n",
    "    ax.set_ylabel(f'JD - {int(data.times[0])}')\n",
    "    ax.set_title(f'Coherent combination rephased to {PULSAR_RA}, {PULSAR_DEC}')\n",
    "    transit_lst_hours = np.degrees(ra_source) / 15\n",
    "    lsts_hours = np.array(hd.lsts) * 12 / np.pi\n",
    "    closest_t = np.argmin(np.abs((lsts_hours - transit_lst_hours + 12) % 24 - 12))\n",
    "    transit_jd = hd.times[closest_t] - int(hd.times[0])\n",
    "    ax.axhline(transit_jd, color='w', ls='--', lw=1, label=f'Transit LST={transit_lst_hours:.2f}h')\n",
    "    ax.legend(loc='upper right')\n",
    "    print(f'Pulsar transit LST = {transit_lst_hours:.4f} hours, '\n",
    "          f'closest time index = {closest_t}, JD = {hd.times[closest_t]:.5f}')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l2m3n4o5-recenter-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:52:28.385799Z",
     "iopub.status.busy": "2026-02-19T23:52:28.385585Z",
     "iopub.status.idle": "2026-02-19T23:52:28.598329Z",
     "shell.execute_reply": "2026-02-19T23:52:28.597806Z",
     "shell.execute_reply.started": "2026-02-19T23:52:28.385781Z"
    }
   },
   "outputs": [],
   "source": [
    "# recenter z-scores above and below FM and per-polarization\n",
    "_, (low_band, high_band) = flag_utils.get_minimal_slices(~np.isfinite(zscore), freqs=data.freqs, \n",
    "                                                         freq_cuts=[FM_LOW_FREQ / 2 + FM_HIGH_FREQ / 2])\n",
    "for band in [low_band, high_band]:\n",
    "    zscore[:, band] -= np.nanmedian(zscore[:, band])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n4o5p6q7-plot-header-r4",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o5p6q7r8-plot-zscore-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:52:28.599262Z",
     "iopub.status.busy": "2026-02-19T23:52:28.599044Z",
     "iopub.status.idle": "2026-02-19T23:52:28.608077Z",
     "shell.execute_reply": "2026-02-19T23:52:28.607633Z",
     "shell.execute_reply.started": "2026-02-19T23:52:28.599245Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_z_score(zscore, flags=None, vmin=-7.5, vmax=7.5):\n",
    "    if flags is None:\n",
    "        flags = ~np.isfinite(zscore)\n",
    "    plt.figure(figsize=(14,10), dpi=300)\n",
    "    extent = [data.freqs[0] / 1e6, data.freqs[-1] / 1e6, \n",
    "              data.times[-1] - int(data.times[0]), data.times[0] - int(data.times[0])]\n",
    "    \n",
    "    plt.imshow(np.where(flags, np.nan, zscore), aspect='auto', \n",
    "               cmap='coolwarm', interpolation='none', vmin=vmin, vmax=vmax, extent=extent)\n",
    "    plt.colorbar(location='top', label='pI z-score Incoherently Averaged Across Baselines', extend='both', aspect=40, pad=.02)\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel(f'JD - {int(data.times[0])}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Add LST right axis with proper wrapping\n",
    "    lst_grid = hd.lsts * 12 / np.pi  # radians to hours\n",
    "    lst_grid[lst_grid > lst_grid[-1]] -= 24\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.set_ylim(lst_grid[-1], lst_grid[0])\n",
    "    mod24 = lambda x, _: f\"{x % 24:.1f}\"\n",
    "    ax2.yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(mod24))\n",
    "    ax2.set_ylabel('LST (hours)')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p6q7r8s9-plot-hist-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:52:28.608995Z",
     "iopub.status.busy": "2026-02-19T23:52:28.608647Z",
     "iopub.status.idle": "2026-02-19T23:52:28.615135Z",
     "shell.execute_reply": "2026-02-19T23:52:28.614650Z",
     "shell.execute_reply.started": "2026-02-19T23:52:28.608976Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_histogram():\n",
    "    plt.figure(figsize=(14,4), dpi=100)\n",
    "    bins = np.arange(-50, 100, .1)\n",
    "    hist = plt.hist(np.ravel(zscore), bins=bins, density=True, label=f'z-scores', alpha=.5)\n",
    "    plt.plot(bins, (2*np.pi)**-.5 * np.exp(-bins**2 / 2), 'k:', label='Gaussian approximate\\nnoise-only distribution')\n",
    "    plt.axvline(WS_Z_THRESH, c='r', ls='--', label='Watershed z-score')\n",
    "    plt.axvline(Z_THRESH, c='r', ls='-', label='Threshold z-score')    \n",
    "    plt.yscale('log')\n",
    "    all_densities = hist[0][hist[0] > 0]\n",
    "    plt.ylim(np.min(all_densities) / 2, np.max(all_densities) * 2)\n",
    "    plt.xlim([-50, 100])\n",
    "    plt.legend()\n",
    "    plt.xlabel('z-score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q7r8s9t0-summarize-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:52:28.616003Z",
     "iopub.status.busy": "2026-02-19T23:52:28.615747Z",
     "iopub.status.idle": "2026-02-19T23:52:28.624948Z",
     "shell.execute_reply": "2026-02-19T23:52:28.624330Z",
     "shell.execute_reply.started": "2026-02-19T23:52:28.615985Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_flagging(zscore, flags):\n",
    "    plt.figure(figsize=(14,10), dpi=200)\n",
    "    cmap = matplotlib.colors.ListedColormap(((0, 0, 0),) + matplotlib.cm.get_cmap(\"Set2\").colors[0:2])\n",
    "    extent = [data.freqs[0] / 1e6, data.freqs[-1] / 1e6, \n",
    "              data.times[-1] - int(data.times[0]), data.times[0] - int(data.times[0])]    \n",
    "    plt.imshow(np.where(~np.isfinite(zscore), 1, np.where(flags, 2, 0)), \n",
    "               aspect='auto', cmap=cmap, interpolation='none', extent=extent)\n",
    "    plt.clim([-.5, 2.5])\n",
    "    cbar = plt.colorbar(location='top', aspect=40, pad=.02)\n",
    "    cbar.set_ticks([0, 1, 2])\n",
    "    cbar.set_ticklabels(['Unflagged', 'Flagged After Round 3', 'Flagged After Round 4'])\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel(f'JD - {int(data.times[0])}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r8s9t0u1-fig1-header-r4",
   "metadata": {},
   "source": [
    "# Figure 1: Waterfall of pI z-Score Before Round 4 Flagging\n",
    "\n",
    "This figure shows the pI z-score derived from delay+fringe-rate-filtered pseudo-Stokes I SNRs. Dotted lines in the high band show TV allocations, which receive special treatment. Large positive excursions are problematic and likely need flagging. Note that below and above FM are handled separately and may have different levels of post-filter residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s9t0u1v2-fig1-plot-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:52:28.625836Z",
     "iopub.status.busy": "2026-02-19T23:52:28.625596Z",
     "iopub.status.idle": "2026-02-19T23:52:39.231255Z",
     "shell.execute_reply": "2026-02-19T23:52:39.230528Z",
     "shell.execute_reply.started": "2026-02-19T23:52:28.625817Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_z_score(zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t0u1v2w3-fig2-header-r4",
   "metadata": {},
   "source": [
    "# Figure 2: Histogram of z-Scores\n",
    "\n",
    "Shows a comparison of the histogram of pI z-scores to a Gaussian approximation of what one might expect from thermal noise. The underlying SNR is the absolute value of complex delay+fringe-rate-filtered pseudo-Stokes I data, which should follow a Rayleigh distribution for noise-only data. To make the z-scores more reliable, a single per-band median is subtracted from the waterfall. Any points beyond the solid red line are flagged. Any points neighboring a flag beyond the dashed red line are also flagged (watershed, seeded with Round 3 flags). Channels with persistent single-channel outliers are also flagged entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x4-fig2-plot-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T23:52:52.917088Z",
     "iopub.status.busy": "2026-02-19T23:52:52.916751Z",
     "iopub.status.idle": "2026-02-19T23:52:56.210765Z",
     "shell.execute_reply": "2026-02-19T23:52:56.210294Z",
     "shell.execute_reply.started": "2026-02-19T23:52:52.917067Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2w3x4y5-flag-header-r4",
   "metadata": {},
   "source": [
    "## Flagging functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w3x4y5z6-flag-funcs-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T18:33:48.766514Z",
     "iopub.status.busy": "2026-02-19T18:33:48.766239Z",
     "iopub.status.idle": "2026-02-19T18:33:48.780723Z",
     "shell.execute_reply": "2026-02-19T18:33:48.780165Z",
     "shell.execute_reply.started": "2026-02-19T18:33:48.766495Z"
    }
   },
   "outputs": [],
   "source": [
    "def iteratively_flag_on_averaged_zscore(flags, zscore, avg_func=np.nanmean, avg_z_thresh=AVG_Z_THRESH, verbose=True):\n",
    "    '''Flag whole integrations or channels based on average z-score. This is done\n",
    "    iteratively to prevent bad times affecting channel averages or vice versa.'''\n",
    "\n",
    "    _, (low_band, high_band) = flag_utils.get_minimal_slices(flags, freqs=data.freqs, freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "    flagged_chan_count = 0\n",
    "    flagged_int_count = {low_band: 0, high_band: 0}\n",
    "    for band in (low_band, high_band):\n",
    "        while True:\n",
    "            zspec = avg_func(np.where(flags, np.nan, zscore)[:, band], axis=0)\n",
    "            ztseries = avg_func(np.where(flags, np.nan, zscore)[:, band], axis=1)\n",
    "    \n",
    "            if (np.nanmax(zspec) < avg_z_thresh) and (np.nanmax(ztseries) < avg_z_thresh):\n",
    "                break\n",
    "    \n",
    "            if np.nanmax(zspec) >= np.nanmax(ztseries):\n",
    "                flagged_chan_count += np.sum((zspec >= np.nanmax(ztseries)) & (zspec >= avg_z_thresh))\n",
    "                flags[:, band][:, (zspec >= np.nanmax(ztseries)) & (zspec >= avg_z_thresh)] = True\n",
    "            else:\n",
    "                flagged_int_count[band] += np.sum((ztseries >= np.nanmax(zspec)) & (ztseries >= avg_z_thresh))\n",
    "                flags[(ztseries >= np.nanmax(zspec)) & (ztseries >= avg_z_thresh), band] = True\n",
    "\n",
    "    ztseries_low = avg_func(np.where(flags, np.nan, zscore)[:, low_band], axis=1)\n",
    "    flags[(ztseries_low > avg_z_thresh) & np.all(flags[:, high_band], axis=1), low_band] = True\n",
    "    \n",
    "    if verbose:\n",
    "        if (flagged_int_count[low_band] > 0) or (flagged_int_count[high_band] > 0) or (flagged_chan_count > 0):\n",
    "            print(f'\\tFlagging an additional {flagged_int_count[low_band]} low-band integrations, '\n",
    "                  f'{flagged_int_count[high_band]} high-band integrations, and {flagged_chan_count} channels.')\n",
    "\n",
    "def impose_max_chan_flag_frac(flags, max_flag_frac=MAX_FREQ_FLAG_FRAC, verbose=True):\n",
    "    '''Flag channels already flagged more than max_flag_frac (excluding completely flagged times).'''\n",
    "    _, (low_band, high_band) = flag_utils.get_minimal_slices(flags, freqs=data.freqs, freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "    for band in [low_band, high_band]:\n",
    "        unflagged_times = ~np.all(flags[:, band], axis=1)\n",
    "        frequently_flagged_chans =  np.mean(flags[unflagged_times, band], axis=0) >= max_flag_frac\n",
    "        if verbose:\n",
    "            flag_diff_count = np.sum(frequently_flagged_chans) - np.sum(np.all(flags[:, band], axis=0))\n",
    "            if flag_diff_count > 0:\n",
    "                print(f'\\tFlagging {flag_diff_count} channels previously flagged {max_flag_frac:.2%} or more.')        \n",
    "        flags[:, band][:, frequently_flagged_chans] = True\n",
    "        \n",
    "def impose_max_time_flag_frac(flags, max_flag_frac=MAX_TIME_FLAG_FRAC, verbose=True):\n",
    "    '''Flag times already flagged more than max_flag_frac (excluding completely flagged channels).'''\n",
    "    _, (low_band, high_band) = flag_utils.get_minimal_slices(flags, freqs=data.freqs, freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "    for name, band in zip(['low', 'high'], [low_band, high_band]):\n",
    "        unflagged_chans = ~np.all(flags[:, band], axis=0)\n",
    "        frequently_flagged_times =  np.mean(flags[:, band][:, unflagged_chans], axis=1) >= max_flag_frac\n",
    "        if verbose:\n",
    "            flag_diff_count = np.sum(frequently_flagged_times) - np.sum(np.all(flags[:, band], axis=1))\n",
    "            if flag_diff_count > 0:\n",
    "                print(f'\\tFlagging {flag_diff_count} {name}-band times previously flagged {max_flag_frac:.2%} or more.')\n",
    "        flags[frequently_flagged_times, band] = True\n",
    "\n",
    "def watershed_flag(flags, zscore, ws_z_thresh=WS_Z_THRESH, round3_flags=None):\n",
    "    '''Wrapper around xrfi._ws_flag_waterfall to be performed separately above and below FM.\n",
    "    If round3_flags is provided, uses them as additional seeds for the watershed, fully\n",
    "    re-flagging those locations and their neighbors.'''\n",
    "    while True:        \n",
    "        nflags = np.sum(flags)\n",
    "        _, (low_band, high_band) = flag_utils.get_minimal_slices(flags, freqs=data.freqs, freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "        for band in [low_band, high_band]:\n",
    "            for pol in zscore:\n",
    "                if round3_flags is not None:\n",
    "                    combined_seeds = flags[:, band] | round3_flags[:, band]\n",
    "                    flags[:, band] |= xrfi._ws_flag_waterfall(zscore[pol][:, band], combined_seeds, ws_z_thresh)\n",
    "                else:\n",
    "                    flags[:, band] |= xrfi._ws_flag_waterfall(zscore[pol][:, band], flags[:, band], ws_z_thresh)\n",
    "        if np.sum(flags) == nflags:\n",
    "            break\n",
    "\n",
    "# def flag_single_channel_repeat_outliers(flags, zscore, z_thresh=None, flag_frac=SINGLE_CHAN_FLAG_FRAC, verbose=True):\n",
    "#     '''Iteratively flag entire channels where a disproportionate fraction of unflagged times\n",
    "#     are individually above z_thresh. This catches persistent narrow-band RFI that appears\n",
    "#     at a single channel across many times.'''\n",
    "#     if z_thresh is None:\n",
    "#         z_thresh = SINGLE_CHAN_Z_THRESH\n",
    "#     _, (low_band, high_band) = flag_utils.get_minimal_slices(flags, freqs=data.freqs, freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "#     total_chans_flagged = 0\n",
    "#     for band in [low_band, high_band]:\n",
    "#         while True:\n",
    "#             above_thresh = np.any([zscore[pol][:, band] > z_thresh for pol in zscore], axis=0)\n",
    "#             unflagged = ~flags[:, band]\n",
    "#             n_unflagged = np.sum(unflagged, axis=0).astype(float)\n",
    "#             n_outliers = np.sum(above_thresh & unflagged, axis=0).astype(float)\n",
    "#             with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#                 outlier_frac = np.where(n_unflagged > 0, n_outliers / n_unflagged, 0)\n",
    "#             chans_to_flag = (outlier_frac >= flag_frac) & (n_unflagged > 0)\n",
    "#             if not np.any(chans_to_flag):\n",
    "#                 break\n",
    "#             total_chans_flagged += np.sum(chans_to_flag)\n",
    "#             flags[:, band][:, chans_to_flag] = True\n",
    "#     if verbose and total_chans_flagged > 0:\n",
    "#         print(f'\\tFlagging {total_chans_flagged} channels with > {flag_frac:.1%} of times individually above z = {z_thresh}.')\n",
    "\n",
    "# def iterative_freq_conv_flagging(flags, zscore, conv_size=FREQ_CONV_SIZE, one_chan_thresh=Z_THRESH, full_kernel_thresh=AVG_Z_THRESH):\n",
    "#     '''Looks for stretches of increasing size that fit a decreasing threshold. At conv_size (in MHz), it flags \n",
    "#     stretches with average z-score above full_kernel_thresh. At one pixel, it uses one_chan_thresh.\n",
    "#     In between, it interpolates logarithmically.'''\n",
    "#     _, (low_band, high_band) = flag_utils.get_minimal_slices(flags, freqs=data.freqs, freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "#     df_MHz = np.median(np.diff(data.freqs)) / 1e6\n",
    "#     widths = np.array([int(w) + 1 for w in 2**np.arange(1, np.ceil(np.log2(conv_size / df_MHz) + np.finfo(float).eps))])\n",
    "    \n",
    "#     # prevent any widths from being so big that they mix high and low bands\n",
    "#     max_width = (high_band.start - low_band.stop) * 2\n",
    "#     widths[widths > max_width] = max_width\n",
    "#     widths = np.unique(widths)\n",
    "\n",
    "#     # Create cuts that get more strict as the kernel gets bigger\n",
    "#     cuts = one_chan_thresh * (full_kernel_thresh / one_chan_thresh)**((widths - 1) / (conv_size / df_MHz - 1))\n",
    "\n",
    "#     for width, cut in zip(widths, cuts):\n",
    "#         kernel = np.ones((1, int(width)), dtype=float)\n",
    "#         mask = ~(np.isnan(zscore) | flags)\n",
    "#         filled_data = np.where(mask, zscore, 0.0)\n",
    "#         conv_data = convolve2d(filled_data, kernel, mode='same')\n",
    "#         conv_mask = convolve2d(mask.astype(float), kernel, mode='same')\n",
    "#         with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#             result = conv_data / conv_mask\n",
    "\n",
    "#         for band in [low_band, high_band]:\n",
    "#             above_cut = (result[:, band] > cut)\n",
    "#             flags[:, band] |= (convolve2d(above_cut.astype(float), kernel, mode='same') > 0)\n",
    "        \n",
    "#         print(f'{np.mean(flags):.3%} of waterfall flagged after {width}-channel convolution-based flagging with z-scores above {cut:.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x4y5z6a7-main-header-r4",
   "metadata": {},
   "source": [
    "## Main Flagging Routine\n",
    "\n",
    "# TODO: UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5z6a7b8-main-routine-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T18:33:49.048127Z",
     "iopub.status.busy": "2026-02-19T18:33:49.047854Z",
     "iopub.status.idle": "2026-02-19T18:33:51.344316Z",
     "shell.execute_reply": "2026-02-19T18:33:51.343672Z",
     "shell.execute_reply.started": "2026-02-19T18:33:49.048110Z"
    }
   },
   "outputs": [],
   "source": [
    "flags = ~np.isfinite(zscore)\n",
    "_, (low_band, high_band) = flag_utils.get_minimal_slices(flags, freqs=data.freqs, freq_cuts=[100e6])\n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged to start.')\n",
    "\n",
    "# flag whole integrations or channels using outliers in median\n",
    "while True:\n",
    "    nflags = np.sum(flags)  \n",
    "    iteratively_flag_on_averaged_zscore(flags, zscore, avg_func=np.nanmedian, avg_z_thresh=AVG_Z_THRESH, verbose=True)\n",
    "    impose_max_chan_flag_frac(flags, max_flag_frac=MAX_FREQ_FLAG_FRAC, verbose=True)\n",
    "    impose_max_time_flag_frac(flags, max_flag_frac=MAX_TIME_FLAG_FRAC, verbose=True)\n",
    "    if np.sum(flags) == nflags:\n",
    "        break  \n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged after flagging whole times and channels with median z > {AVG_Z_THRESH}.')\n",
    "\n",
    "# # flag largest outliers\n",
    "# _, (low_band, high_band) = flag_utils.get_minimal_slices(flags, freqs=data.freqs, freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "# for band in [low_band, high_band]:\n",
    "#     flags[:, band] |= (zscore[:, band] > Z_THRESH) \n",
    "# print(f'{np.mean(flags):.3%} of waterfall flagged after flagging z > {Z_THRESH} outliers.')\n",
    "\n",
    "# # # flag channels with persistent single-channel outliers\n",
    "# # flag_single_channel_repeat_outliers(flags, zscore, z_thresh=SINGLE_CHAN_Z_THRESH, flag_frac=SINGLE_CHAN_FLAG_FRAC)\n",
    "# # print(f'{np.mean(flags):.3%} of waterfall flagged after single-channel repeat outlier detection.')\n",
    "\n",
    "# # watershed flagging (with Round 3 flag seeding)\n",
    "# watershed_flag(flags, zscore, ws_z_thresh=WS_Z_THRESH, round3_flags=round3_flags)\n",
    "# print(f'{np.mean(flags):.3%} of waterfall flagged after watershed flagging on z > {WS_Z_THRESH} neighbors of prior flags (seeded with Round 3 flags).')\n",
    "\n",
    "# # # iterative frequency-convolved flagging\n",
    "# # iterative_freq_conv_flagging(flags, zscore, conv_size=FREQ_CONV_SIZE, one_chan_thresh=Z_THRESH, full_kernel_thresh=AVG_Z_THRESH)\n",
    "# # print(f'{np.mean(flags):.3%} of waterfall flagged after channel convolution flagging.')\n",
    "\n",
    "# # watershed flagging again (with Round 3 flag seeding)\n",
    "# watershed_flag(flags, zscore, ws_z_thresh=WS_Z_THRESH, round3_flags=round3_flags)\n",
    "# print(f'{np.mean(flags):.3%} of waterfall flagged after watershed flagging again on z > {WS_Z_THRESH} neighbors of prior flags.')\n",
    "\n",
    "# # flag whole integrations or channels using outliers in mean\n",
    "# while True:\n",
    "#     nflags = np.sum(flags)\n",
    "#     iteratively_flag_on_averaged_zscore(flags, zscore, avg_func=np.nanmean, avg_z_thresh=AVG_Z_THRESH, verbose=True)\n",
    "#     impose_max_chan_flag_frac(flags, max_flag_frac=MAX_FREQ_FLAG_FRAC, verbose=True)\n",
    "#     impose_max_time_flag_frac(flags, max_flag_frac=MAX_TIME_FLAG_FRAC, verbose=True)\n",
    "#     if np.sum(flags) == nflags:\n",
    "#         break  \n",
    "# print(f'{np.mean(flags):.3%} of waterfall flagged after flagging whole times and channels with average z > {AVG_Z_THRESH}.')\n",
    "\n",
    "# # watershed flagging one last time (with Round 3 flag seeding)\n",
    "# watershed_flag(flags, zscore, ws_z_thresh=WS_Z_THRESH, round3_flags=round3_flags)\n",
    "# print(f'{np.mean(flags):.3%} of waterfall flagged after watershed flagging one last time on z > {WS_Z_THRESH} neighbors of prior flags.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z6a7b8c9-fig3-header-r4",
   "metadata": {},
   "source": [
    "# Figure 3: Waterfall of pI z-Score After Round 4 Flagging\n",
    "\n",
    "Same as [Figure 1](#Figure-1:-Waterfall-of-pI-z-Score-Before-Round-4-Flagging) above, but now with additional flagging from this round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-fig3-plot-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T18:33:51.345951Z",
     "iopub.status.busy": "2026-02-19T18:33:51.345717Z",
     "iopub.status.idle": "2026-02-19T18:34:01.576442Z",
     "shell.execute_reply": "2026-02-19T18:34:01.575673Z",
     "shell.execute_reply.started": "2026-02-19T18:33:51.345931Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_z_score(zscore, flags=flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1-fig4-header-r4",
   "metadata": {},
   "source": [
    "# Figure 4: Summary of Flags Before and After Round 4 Flagging\n",
    "\n",
    "This plot shows which times and frequencies were flagged before and after this notebook. It is directly comparable to Figure 4 of the [full_day_rfi_round_3](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/full_day_rfi_round_3.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2-fig4-plot-r4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T18:34:01.577832Z",
     "iopub.status.busy": "2026-02-19T18:34:01.577532Z",
     "iopub.status.idle": "2026-02-19T18:34:06.751507Z",
     "shell.execute_reply": "2026-02-19T18:34:06.750761Z",
     "shell.execute_reply.started": "2026-02-19T18:34:01.577811Z"
    }
   },
   "outputs": [],
   "source": [
    "summarize_flagging(zscore, flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2g3-save-header-r4",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2g3h4-save-r4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uvf = UVFlag(hd_autos, mode='flag', waterfall=True)\n",
    "for polind in range(uvf.flag_array.shape[2]):\n",
    "    uvf.flag_array[:, :, polind] = flags\n",
    "\n",
    "uvf.write(OUTFILE, clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2g3h4i5-meta-header-r4",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g3h4i5j6-meta-versions-r4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h4i5j6k7-meta-timing-r4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

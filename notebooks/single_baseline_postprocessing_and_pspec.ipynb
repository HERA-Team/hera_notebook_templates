{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1113161c",
   "metadata": {},
   "source": [
    "# Single Baseline Filtering and Power Spectrum Estimation\n",
    "\n",
    "**by Josh Dillon**, last updated August 21, 2024\n",
    "\n",
    "This notebook is designed to take a single redundantly-averaged unique baseline (typically after LST-binning) and push it through all the way to the power spectrum. It operates on single files that contain a single baseline for all LSTs and both `'ee'` and `'nn'` polarizations. It then can:\n",
    "* Throw out highly flagged times and/or channels\n",
    "* Inpaint autocorrelations to produce a noise model, if necessary\n",
    "* Inpaint cross-correlations (optional)\n",
    "* Delay-filter cross-correlations (optional)\n",
    "* De-interleave by time into multiple waterfalls with independent noise and rephased to the same set of LSTs\n",
    "* Perform crosstalk notch filtering of the FR = 0 mode\n",
    "* Perform main beam top hat fringe-rate filtering\n",
    "* Convert to pseudo-Stokes I and Q\n",
    "* Perform coherent time averaging\n",
    "* Compute power spectra from pairs of interleaves\n",
    "* Estimate noise, accounting for how the fringe-rate filter and the coherent \n",
    "* Incoherent averaging over time and across interleave-pairs\n",
    "\n",
    "This notebook also produces a series of plots and tables to illustrate the progress of the analysis. These include:\n",
    "\n",
    "# [• Table 1: Band Definitions](#Table-1:-Band-Definitions)\n",
    "# [• Figure 1: Bands and Flag Occupancy](#Figure-1:-Bands-and-Flag-Occupancy)\n",
    "# [• Table 2: Fringe-Rate and Crosstalk Filtering Ranges and Losses](#Table-2:-Fringe-Rate-and-Crosstalk-Filtering-Ranges-and-Losses)\n",
    "# [• Figure 2: Waterfalls Before Delay Filtering and/or Inpainting](#Figure-2:-Waterfalls-Before-Delay-Filtering-and/or-Inpainting)\n",
    "# [• Figure 3: Waterfalls After Delay Filtering and/or Inpainting](#Figure-3:-Waterfalls-After-Delay-Filtering-and/or-Inpainting)\n",
    "# [• Figure 4: First Set of De-Interleaved Waterfalls after Cross-Talk Filtering](#Figure-4:-First-Set-of-De-Interleaved-Waterfalls-after-Cross-Talk-Filtering)\n",
    "# [• Figure 5: First Set of De-Interleaved Waterfalls after Main-Beam Fringe-Rate Filtering](#Figure-5:-First-Set-of-De-Interleaved-Waterfalls-after-Main-Beam-Fringe-Rate-Filtering)\n",
    "# [• Figure 6: First Set of De-Interleaved Waterfalls after Forming Pseudo-Stokes I](#Figure-6:-First-Set-of-De-Interleaved-Waterfalls-after-Forming-Pseudo-Stokes-I)\n",
    "# [• Figure 7: First Set of De-Interleaved Waterfalls after Coherent Time Averaging](#Figure-7:-First-Set-of-De-Interleaved-Waterfalls-after-Coherent-Time-Averaging)\n",
    "# [• Figure 8: Interleave-Averaged Power Spectra (Pseudo-Stokes I, Q, U, & V) vs. LST](#Figure-8:-Interleave-Averaged-Power-Spectra-(Pseudo-Stokes-I,-Q,-U,-&-V)-vs.-LST)\n",
    "# [• Figure 9: Interleave-Averaged Power Spectrum SNR vs. LST (Real and Imaginary for pI)](#Figure-9:-Interleave-Averaged-Power-Spectrum-SNR-vs.-LST-(Real-and-Imaginary-for-pI))\n",
    "# [• Figure 10: High Delay Power Spectrum SNR Histograms Before and After Incoherent Averaging](#Figure-10:-High-Delay-Power-Spectrum-SNR-Histograms-Before-and-After-Incoherent-Averaging)\n",
    "# [• Figure 11: Incoherently Averaged Power Spectrum with Error Bars](#Figure-11:-Incoherently-Averaged-Power-Spectrum-with-Error-Bars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb876146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import warnings\n",
    "from astropy import units\n",
    "from scipy import constants, interpolate, special\n",
    "from pyuvdata import UVFlag, UVData, UVCal, UVBeam\n",
    "from pyuvdata import utils as uvutils\n",
    "from hera_cal import io, utils, abscal, vis_clean, frf, datacontainer, noise, redcal\n",
    "from hera_cal.smooth_cal import CalibrationSmoother, dpss_filters, solve_2D_DPSS\n",
    "from hera_qm import ant_class, xrfi, metrics_io\n",
    "from hera_qm.time_series_metrics import true_stretches\n",
    "from hera_filters import dspec\n",
    "import hera_pspec as hp\n",
    "import uvtools\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib inline\n",
    "\n",
    "from HERA_FRF_cov import FRF_cov_calc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b026f1c",
   "metadata": {},
   "source": [
    "## Parse settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6fb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook settings\n",
    "PLOT = os.environ.get(\"PLOT\", \"TRUE\").upper() == \"TRUE\"\n",
    "SAVE_RESULTS = os.environ.get(\"PLOT\", \"TRUE\").upper() == \"TRUE\"\n",
    "\n",
    "# Data settings\n",
    "SINGLE_BL_FILE = os.environ.get(\"SINGLE_BL_FILE\", '')\n",
    "OUT_PSPEC_FILE = os.environ.get(\"OUT_PSPEC_FILE\", SINGLE_BL_FILE.replace('.uvh5', '.pspec.h5'))\n",
    "\n",
    "# Band settings\n",
    "BAND_STR = os.environ.get(\"BAND_STR\", '50.1~62.2,62.7~73.8,74.6~87.4,108.0~124.5,125.3~136.2,138.3~148.2,'\n",
    "                                      '148.5~159.2,159.3~175.2,175.3~189.2,191.5~208.5,208.7~222.9,223.6~231.1') # in MHz\n",
    "\n",
    "# Inpainting settings \n",
    "ALREADY_INPAINTED = os.environ.get(\"ALREADY_INPAINTED\", \"FALSE\").upper() == \"TRUE\"\n",
    "PERFORM_INPAINT = os.environ.get(\"PERFORM_INPAINT\", \"FALSE\").upper() == \"TRUE\"\n",
    "INPAINT_MIN_DLY = float(os.environ.get(\"INPAINT_MIN_DLY\", 500.0)) # in ns\n",
    "INPAINT_HORIZON = float(os.environ.get(\"INPAINT_HORIZON\", 1.0))\n",
    "INPAINT_STANDOFF = float(os.environ.get(\"INPAINT_STANDOFF\", 0.0)) # in ns\n",
    "INPAINT_EIGENVAL_CUTOFF = float(os.environ.get(\"INPAINT_EIGENVAL_CUTOFF\", 1e-12))\n",
    "\n",
    "# Delay filtering settings\n",
    "PERFORM_DLY_FILT = os.environ.get(\"PERFORM_DLY_FILT\", \"FALSE\").upper() == \"TRUE\"\n",
    "DLY_FILT_MIN_DLY = float(os.environ.get(\"DLY_FILT_MIN_DLY\", 150.0)) # in ns\n",
    "DLY_FILT_HORIZON = float(os.environ.get(\"DLY_FILT_HORIZON\", 1.0))\n",
    "DLY_FILT_STANDOFF = float(os.environ.get(\"DLY_FILT_STANDOFF\", 0.0)) # in ns\n",
    "DLY_FILT_EIGENVAL_CUTOFF = float(os.environ.get(\"DLY_FILT_EIGENVAL_CUTOFF\", 1e-12))\n",
    "\n",
    "# Flagging settings\n",
    "USE_BAND_AVG_NSAMPLES = os.environ.get(\"USE_BAND_AVG_NSAMPLES\", \"FALSE\").upper() == \"TRUE\"  # for time filtering, time averaging, and power spectrum estimation\n",
    "FLAG_COHERENT_CHUNKS = os.environ.get(\"FLAG_COHERENT_CHUNKS\", \"FALSE\").upper() == \"TRUE\"\n",
    "FM_CUT_FREQ = float(os.environ.get(\"FM_CUT_FREQ\", 100e6)) # in Hz\n",
    "PIXEL_FLAG_CUT = float(os.environ.get(\"PIXEL_FLAG_CUT\", .75))\n",
    "INTEGRATION_FLAG_CUT = float(os.environ.get(\"INTEGRATION_FLAG_CUT\", .2))\n",
    "CHANNEL_FLAG_CUT = float(os.environ.get(\"CHANNEL_FLAG_CUT\", .5))  # If neither PERFORM_INPAINT nor PERFORM_DLY_FILT, this is ignored\n",
    "if (not PERFORM_INPAINT) and (not PERFORM_DLY_FILT):\n",
    "    CHANNEL_FLAG_CUT = 0.0\n",
    "    PIXEL_FLAG_CUT = 0.0\n",
    "    \n",
    "# FRF and time-averaging settings\n",
    "NINTERLEAVE = int(os.environ.get(\"EIGENVAL_CUTOFF\", 4)) # number of interleaves to independently FRF\n",
    "XTALK_FR = float(os.environ.get(\"XTALK_FR\", 0.01)) # Fringe rate half-width in Hz used for fringe rate filtering crosstalk\n",
    "FR_SPECTRA_FILE = os.environ.get(\"FR_SPECTRA_FILE\", \"/lustre/aoc/projects/hera/zmartino/hera_frf/spectra_cache/spectra_cache_hera_core.h5\")\n",
    "FR_QUANTILE_LOW = float(os.environ.get(\"FR_QUANTILE_LOW\", 0.05))\n",
    "FR_QUANTILE_HIGH = float(os.environ.get(\"FR_QUANTILE_HIGH\", 0.95))\n",
    "FR_EIGENVAL_CUTOFF = float(os.environ.get(\"FR_EIGENVAL_CUTOFF\", 1e-12))\n",
    "TARGET_AVERAGING_TIME = 300 # coherent integration time in seconds. Actual time might be less to so that all interleaves have the same number of samples averaged\n",
    "\n",
    "# Power spectrum settings\n",
    "EFIELD_HEALPIX_BEAM_FILE = os.environ.get(\"EFIELD_HEALPIX_BEAM_FILE\", \"/lustre/aoc/projects/hera/h6c-analysis/IDR2/beams/NF_HERA_Vivaldi_efield_beam_healpix.fits\")\n",
    "TAPER = os.environ.get(\"TAPER\", \"bh\") # taper applied when doing power spectra\n",
    "INCLUDE_INTERLEAVE_AUTO_PS = os.environ.get(\"INCLUDE_INTERLEAVE_AUTO_PS\", \"FALSE\").upper() == \"TRUE\"\n",
    "STORE_WINDOW_FUNCTIONS = os.environ.get(\"STORE_WINDOW_FUNCTIONS\", \"FALSE\").upper() == \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example set of settings\n",
    "# SINGLE_BL_FILE = '/lustre/aoc/projects/hera/h6c-analysis/IDR2/lstbin-outputs/redavg-smoothcal-inpaint-500ns-lstcal/inpaint/single_baseline_files/zen.LST.baseline.0_4.sum.uvh5' \n",
    "# OUT_PSPEC_FILE = '/lustre/aoc/projects/hera/mwilensk/H6C/PSPEC/pspec_out/zen.LST.baseline.0_4.sum.pspec.h5'\n",
    "# ALREADY_INPAINTED = True\n",
    "# PERFORM_INPAINT = False\n",
    "# PERFORM_DLY_FILT = False\n",
    "# USE_BAND_AVG_NSAMPLES = True \n",
    "# CHANNEL_FLAG_CUT = 0.0\n",
    "# SAVE_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aded501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print settings\n",
    "for setting in ['PLOT', 'SAVE_RESULTS',\n",
    "                'SINGLE_BL_FILE', 'OUT_PSPEC_FILE',\n",
    "                'BAND_STR',\n",
    "                'ALREADY_INPAINTED', 'PERFORM_INPAINT', 'INPAINT_MIN_DLY', 'INPAINT_HORIZON', 'INPAINT_STANDOFF', 'INPAINT_EIGENVAL_CUTOFF',\n",
    "                'PERFORM_DLY_FILT', 'DLY_FILT_MIN_DLY', 'DLY_FILT_HORIZON', 'DLY_FILT_STANDOFF', 'DLY_FILT_EIGENVAL_CUTOFF',\n",
    "                'USE_BAND_AVG_NSAMPLES', 'FM_CUT_FREQ', 'PIXEL_FLAG_CUT', 'INTEGRATION_FLAG_CUT', 'CHANNEL_FLAG_CUT',  \n",
    "                'NINTERLEAVE', 'XTALK_FR', 'FR_SPECTRA_FILE', 'FR_QUANTILE_LOW', 'FR_QUANTILE_HIGH', 'FR_EIGENVAL_CUTOFF', 'TARGET_AVERAGING_TIME',\n",
    "                'EFIELD_HEALPIX_BEAM_FILE', 'TAPER', 'INCLUDE_INTERLEAVE_AUTO_PS', 'STORE_WINDOW_FUNCTIONS']:\n",
    "        if issubclass(type(eval(setting)), str):\n",
    "            print(f'{setting} = \"{eval(setting)}\"')\n",
    "        else:\n",
    "            print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging settings (for advanced users, otherwise leave all False)\n",
    "USE_SIMULATED_NOISE = False  # replaces data with random white noise with the statistics of the autos\n",
    "FLAT_AUTOS = False  # sets autos to flat 10000 Jy\n",
    "NO_FLAGS_FLAT_NSAMPLES = False  # sets all flags to False and all nsamples to the median value for the baseline\n",
    "SKIP_XTALK_AND_FRF = False  # doesn't perform any kind of time-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81076cef",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6442f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out ANTPAIR and corresponding AUTO_BL_FILE\n",
    "ANTPAIR = tuple([int(ant) for ant in re.search(r'\\d+_\\d+', SINGLE_BL_FILE).group().split('_')])\n",
    "all_files = glob.glob(SINGLE_BL_FILE.replace(f'{ANTPAIR[0]}_{ANTPAIR[1]}', '*'))\n",
    "AUTO_BL_FILE = sorted([f for f in all_files if len(set(re.search(r'\\d+_\\d+', f).group().split('_'))) == 1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1db0856",
   "metadata": {},
   "source": [
    "# Added a four_pol option here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarizations = [\"ee\", \"nn\"]\n",
    "\n",
    "FOUR_POL = True\n",
    "if FOUR_POL: \n",
    "    polarizations += [\"en\", \"ne\"]\n",
    "# load data for both crosses and autos with times corresponding only to those in the crosses\n",
    "single_bl_times = np.array(io.HERAData(SINGLE_BL_FILE).times)\n",
    "hd = io.HERAData([AUTO_BL_FILE, SINGLE_BL_FILE])\n",
    "data, flags, nsamples = hd.read(times=single_bl_times, polarizations=polarizations)\n",
    "cross_bls = [ANTPAIR + (pol,) for pol in data.pols()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc97db0",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# check that non-finite data is flagged and flagged data is set to 0\n",
    "for bl in cross_bls:\n",
    "    assert np.all(flags[bl][~np.isfinite(data[bl])])\n",
    "    data[bl][~np.isfinite(data[bl])] = 0\n",
    "    data[bl][flags[bl]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_antpair = sorted(set([k[0:2] for k in data.bls() if k[0] == k[1]]))[0]\n",
    "df = np.median(np.diff(data.freqs))\n",
    "dt = np.median(np.diff(data.times)) * 24 * 3600\n",
    "# Calculate averaging time that divides neatly into NINTERLEAVE\n",
    "AVERAGING_TIME = TARGET_AVERAGING_TIME / (dt * (1 + 1e-10)) // NINTERLEAVE * (dt * (1 + 1e-10)) * NINTERLEAVE \n",
    "print(f'Using an actual coherent averaging time of {AVERAGING_TIME:.3f} seconds to ensure even interleaving.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88661f5c",
   "metadata": {},
   "source": [
    "## NSamples Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405a02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all pixels that are more than 50% (by default) flagged relative to the maximum in that integration.\n",
    "# This is done above and below FM separately because it's possible for a baseline to be entirely flagged above or below but not both.\n",
    "FM_ind = np.argmin(np.abs(data.freqs - FM_CUT_FREQ))\n",
    "for bl in cross_bls:\n",
    "    npix_flagged_before = np.sum(nsamples[bl] == 0)\n",
    "    for fslice in [slice(0, FM_ind), slice(FM_ind, -1)]:\n",
    "        flags[bl][:, fslice][(nsamples[bl][:, fslice] < PIXEL_FLAG_CUT * np.max(nsamples[bl][:, fslice], axis=1, keepdims=True))] = True\n",
    "        nsamples[bl][flags[bl]] = 0\n",
    "    print(f'{bl}: flagging {np.sum(nsamples[bl] == 0) - npix_flagged_before} pixels.')    \n",
    "\n",
    "# Remove all integrations that have fewer integrations than 20% (by default) of the best-observed integration\n",
    "nsamples_by_time = np.sum([np.where(flags[bl], 0, nsamples[bl]) for bl in cross_bls], axis=(0, 2))\n",
    "for bl in cross_bls:\n",
    "    print(f'{bl}: flagging {np.sum((nsamples_by_time < INTEGRATION_FLAG_CUT  * np.max(nsamples_by_time)) & ~np.all(flags[bl], axis=1))} times.')\n",
    "    flags[bl][nsamples_by_time < INTEGRATION_FLAG_CUT  * np.max(nsamples_by_time), :] = True\n",
    "    nsamples[bl][flags[bl]] = 0\n",
    "\n",
    "# Remove all channels that are more than 50% (by default) flagged (relative to the best-observed channel)\n",
    "nsamples_by_chan = np.sum([np.where(flags[bl], 0, nsamples[bl]) for bl in cross_bls], axis=(0, 1))\n",
    "for bl in cross_bls:\n",
    "    print(f'{bl}: flagging {np.sum((nsamples_by_chan < CHANNEL_FLAG_CUT * np.max(nsamples_by_chan)) & ~np.all(flags[bl], axis=0))} channels.')    \n",
    "    flags[bl][:, nsamples_by_chan < CHANNEL_FLAG_CUT * np.max(nsamples_by_chan)] = True\n",
    "    nsamples[bl][flags[bl]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fe4ed",
   "metadata": {},
   "source": [
    "## Define and show bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [tuple([float(edge) for edge in band.split('~')]) for band in BAND_STR.strip().split(',')]\n",
    "all_zs = 1420405751.768 / data.freqs - 1\n",
    "min_freqs = [(np.min(data.freqs[data.freqs >= (1e6 * b[0])]) - df / 2) / 1e6 for b in bands]\n",
    "max_freqs = [(np.max(data.freqs[data.freqs <= (1e6 * b[1])]) + df / 2) / 1e6 for b in bands]\n",
    "min_chan = [np.min(np.arange(len(data.freqs))[data.freqs >= (1e6 * b[0])]) for b in bands]\n",
    "max_chan = [np.max(np.arange(len(data.freqs))[data.freqs <= (1e6 * b[1])]) for b in bands]\n",
    "band_slices = [slice(minc, maxc+1) for minc, maxc in zip(min_chan, max_chan)]\n",
    "nchans = [maxc - minc + 1 for minc, maxc in zip(min_chan, max_chan)]\n",
    "bandwidth = [f'{nc * df / 1e6:.1f}' for nc in nchans]\n",
    "avg_zs = [np.mean(all_zs[(data.freqs >= (1e6 * b[0])) & (data.freqs <= (1e6 * b[1]))]) for b in bands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea71d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bands():\n",
    "    plt.figure(figsize=(18, 6), dpi=100)\n",
    "    to_plot = np.mean([nsamples[ANTPAIR + ('ee',)], nsamples[ANTPAIR + ('nn',)]], axis=(0, 1)) \n",
    "    plt.plot(data.freqs/1e6, to_plot, 'k.-', lw=.5, ms=4, label='Included in a band')\n",
    "\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel(f'Average Nsamples on {ANTPAIR}')\n",
    "\n",
    "    in_any_band = np.sum([(data.freqs / 1e6 <= band[1]) & (data.freqs / 1e6 >= band[0]) for band in bands], axis=0).astype(bool)\n",
    "    plt.plot(data.freqs[~in_any_band] / 1e6, to_plot[~in_any_band], 'r.', lw=.5, ms=4, label='Excluded from all bands')\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "    for i, band in enumerate(bands):\n",
    "        plt.axvspan(band[0], band[1], alpha=.3, color=f'C{i}', zorder=0)\n",
    "        plt.text((band[0] + band[1]) / 2, np.max(to_plot) * 1.05, f'Band {i + 1}', ha='center', va='bottom',\n",
    "                 bbox=dict(facecolor='w', edgecolor='black', alpha=.75, boxstyle='round'))\n",
    "\n",
    "    plt.ylim([-1, np.max(to_plot) * 1.1])    \n",
    "\n",
    "\n",
    "    for freq in [117.19, 133.11, 152.25, 167.97]:\n",
    "        plt.axvline(freq, ls='--', color='k')\n",
    "\n",
    "    for i, freq in enumerate([(117.19 + 133.11)/2, (152.25 + 167.97)/2]):    \n",
    "        plt.text(freq, np.max(to_plot) * .03, f'H1C IDR3\\nBand {i + 1}', ha='center', va='bottom',\n",
    "                 bbox=dict(facecolor='w', edgecolor='black', alpha=.75, boxstyle='round', ls='--'))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "def show_band_table():\n",
    "    table = pd.DataFrame({'Band': np.arange(len(bands)) + 1,\n",
    "                          'Channel Range': [f'{c0} — {c1}' for c0, c1 in zip(min_chan, max_chan)],\n",
    "                          '# of Channels': nchans,\n",
    "                          'Frequency Range (MHz)': [f'{f0:.1f} — {f1:.1f}' for f0, f1 in zip(min_freqs, max_freqs)],\n",
    "                          '$\\\\Delta\\\\nu$ (MHz)': bandwidth,\n",
    "                          '$z$ Range': [f'{1420.405751768 / f1 - 1:.2f} — {1420.405751768 / f0 - 1:.1f}' for f0, f1 in zip(min_freqs, max_freqs)],\n",
    "                          'Center $z$': [f'{(1420.405751768 / f1 - 1) / 2 +  (1420.405751768 / f0 - 1) / 2:.1f}' for f0, f1 in zip(min_freqs, max_freqs)],\n",
    "                          'Delta $z$': [f'{(1420.405751768 / f0 - 1) -  (1420.405751768 / f1 - 1):.1f}' for f0, f1 in zip(min_freqs, max_freqs)],\n",
    "                         })\n",
    "    return table.style.hide().to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b701589",
   "metadata": {},
   "source": [
    "# *Table 1: Band Definitions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa98171",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(show_band_table())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c3c1a",
   "metadata": {},
   "source": [
    "# *Figure 1: Bands and Flag Occupancy*\n",
    "\n",
    "This figure illustrates the definition of the various bands in which the power spectrum is to be estimated, which frequencies are included/excluded, as well as the showing the fraction of each channel flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881abdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if PLOT: plot_bands()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa194bd",
   "metadata": {},
   "source": [
    "## Figure out slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc08525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out high and low bands\n",
    "FM_ind = np.argmin(np.abs(data.freqs - FM_CUT_FREQ))\n",
    "unflagged_chans = np.argwhere(~np.all([np.all(flags[bl], axis=0) for bl in flags], axis=0)).squeeze()\n",
    "low_band = slice(np.min(unflagged_chans), np.max(unflagged_chans[unflagged_chans < FM_ind]) + 1)\n",
    "high_band = slice(np.min(unflagged_chans[unflagged_chans > FM_ind]), np.max(unflagged_chans) + 1)\n",
    "print(f'Below FM Frequency Slice: {low_band}')\n",
    "print(f'Above FM Frequency Slice: {high_band}')\n",
    "\n",
    "# figure out the range of times that includes all unflagged times (though may still have some flags) for all polarizations\n",
    "ORed_flags = np.any([np.all(flags[bl], axis=1) for bl in cross_bls], axis=0)\n",
    "tslice = slice(true_stretches(~ORed_flags)[0].start, true_stretches(~ORed_flags)[-1].stop)\n",
    "print(f'Time Slice Excluded Edge Flags: {tslice}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DIAGNOSTICS/DEBUGGING ONLY: unflag everything and set nsamples to the median\n",
    "if NO_FLAGS_FLAT_NSAMPLES:\n",
    "    for bl in cross_bls:\n",
    "        flags[bl][tslice, :] = False\n",
    "        nsamples[bl][tslice, :] = np.median([nsamples[bl][tslice, :] for bl in cross_bls])\n",
    "    \n",
    "# FOR DIAGNOSTICS/DEBUGGING ONLY: make all the autos a flat 10,000 Jy \n",
    "if FLAT_AUTOS:\n",
    "    for bl in data:\n",
    "        if bl[0] == bl[1]:\n",
    "            data[bl] = 10000 * np.ones_like(data[bl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa2c297",
   "metadata": {},
   "source": [
    "## Figure out per-band fringe-rate filter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: graduate this code into hera_cal\n",
    "\n",
    "# load relevant FR spectrum vs. frequency and associated metadata\n",
    "with h5py.File(FR_SPECTRA_FILE, \"r\") as h5f:\n",
    "    metadata = h5f[\"metadata\"]\n",
    "    bl_to_index_map = {tuple(ap): int(index) for index, antpairs in metadata[\"baseline_groups\"].items() for ap in antpairs}\n",
    "    spectrum_freqs = metadata[\"frequencies_MHz\"][()] * 1e6\n",
    "    m_modes = metadata[\"erh_mode_integer_index\"][()]\n",
    "    if ANTPAIR in bl_to_index_map:\n",
    "        mmode_spectrum = h5f[\"erh_mode_power_spectrum\"][:, :, bl_to_index_map[ANTPAIR]]\n",
    "    else:\n",
    "        # If ANTPAIR is not in the FR_SPECTRA_FILE, but the reverse is, also reverse the spectrum\n",
    "        mmode_spectrum = h5f[\"erh_mode_power_spectrum\"][:, :, bl_to_index_map[ANTPAIR[::-1]]]\n",
    "        m_modes *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee58a2ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: graduate this code into hera_cal\n",
    "\n",
    "# convert to fringe rate, accouting for the fact that we have less than 24 hours of LST\n",
    "def m2f(m_modes):\n",
    "    # Convert m-modes to fringe-rates in mHz.\n",
    "    return m_modes / units.sday.to(units.ks)\n",
    "times_ks = (data.times[tslice] - data.times[0] + np.median(np.diff(data.times))) * units.day.to(units.ks)\n",
    "m2f_phasors = np.exp(2j * np.pi * m2f(m_modes)[None, :] * times_ks[:, None])\n",
    "m2f_mixer = np.fft.fftshift(np.fft.fft(np.fft.ifftshift(m2f_phasors, axes=0), axis=0), axes=0)\n",
    "# f is fringe rate, m is m-mode, n is nu (i.e. freqeuency)\n",
    "fr_spectrum = np.abs(np.einsum('fm,mn,mf->fn', m2f_mixer, mmode_spectrum, m2f_mixer.T.conj()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: graduate this code into hera_cal\n",
    "\n",
    "# interpolate to all frequencies in data\n",
    "interp_fr_spectrum = interpolate.interp1d(spectrum_freqs, fr_spectrum, kind='cubic', fill_value='extrapolate')(data.freqs)    \n",
    "frates = np.fft.fftshift(np.fft.fftfreq(len(times_ks), d=np.median(np.diff(times_ks))))\n",
    "\n",
    "# perform window-weighted average over each band, then get lower and upper quantiles\n",
    "fr_ranges = {}\n",
    "fr_profiles = {}\n",
    "frf_losses = {}\n",
    "xtalk_overlaps = {}\n",
    "for band, bs in zip(bands, band_slices):\n",
    "    taper = dspec.gen_window(TAPER, len(data.freqs[bs]))\n",
    "    band_avg_fr_spectrum = np.average(interp_fr_spectrum[:, bs], weights=taper, axis=1)\n",
    "    band_avg_fr_spectrum /= np.sum(band_avg_fr_spectrum)\n",
    "    fr_profiles[band] = band_avg_fr_spectrum\n",
    "    cumsum_interpolator = interpolate.interp1d(np.cumsum(band_avg_fr_spectrum), frates)\n",
    "    fr_ranges[band] = cumsum_interpolator(FR_QUANTILE_LOW), cumsum_interpolator(FR_QUANTILE_HIGH)\n",
    "    \n",
    "    # account for overlap between FR=0 notch and main beam FRF\n",
    "    def overlap_frs(frs1, frs2):\n",
    "        start = np.maximum(frs1[0], frs2[0])\n",
    "        end = np.minimum(frs1[1], frs2[1])\n",
    "        return (start, end) if start < end else None\n",
    "    frate_interpolator = interpolate.interp1d(frates, np.cumsum(band_avg_fr_spectrum))\n",
    "    frf_losses[band] = 1 - frate_interpolator(fr_ranges[band][1]) + frate_interpolator(fr_ranges[band][0])\n",
    "    xtalk_overlaps[band] = overlap_frs(fr_ranges[band], [-XTALK_FR, XTALK_FR])\n",
    "    if xtalk_overlaps[band] is not None:\n",
    "        frf_losses[band] += frate_interpolator(xtalk_overlaps[band][1]) - frate_interpolator(xtalk_overlaps[band][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_FR_table():\n",
    "    table = pd.DataFrame({'Band': np.arange(len(bands)) + 1,\n",
    "                          'Frequency Range (MHz)': [f'{f0:.1f} — {f1:.1f}' for f0, f1 in zip(min_freqs, max_freqs)],\n",
    "                          f'Main Beam {FR_QUANTILE_LOW:.0%} — {FR_QUANTILE_HIGH:.0%}<br>Kept Fringe Rates (mHz)': [f'{frs[0]:.3f} to {frs[1]:.3f}' for frs in fr_ranges.values()],\n",
    "                          f'Approximate Signal Loss with<br>{-XTALK_FR} to {XTALK_FR} mHz X-Talk Filter': [f'{loss:.0%}' for loss in frf_losses.values()],\n",
    "                         })\n",
    "    return table.style.hide().to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29882d",
   "metadata": {},
   "source": [
    "# *Table 2: Fringe-Rate and Crosstalk Filtering Ranges and Losses*\n",
    "\n",
    "Note that these losses are approximate and assume perfectly sharp filters. Extra extent in fringe-rate space (which is controlled by `FR_EIGENVAL_CUTOFF`) will reduce loss when performing the main beam fringe-rate filter (because it is a top hat). It will also will increase the loss due to the crosstalk filtering (because it is a notch) if and only if there's an overlap between the two filters.\n",
    "\n",
    "TODO: As a future feature, we'd like to implement Bobby's full transfer-matrix formalism for figuring out the actual loss given the set of DPSS filters used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cff2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(show_FR_table())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac398f9",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5edbf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sym_log_norm(to_plot, linthresh=10, clim=None):\n",
    "    '''Convenience interface for matplotlib.colors.SymLogNorm'''\n",
    "    if clim is None:\n",
    "        return matplotlib.colors.SymLogNorm(linthresh, vmin=-np.nanmax(np.abs(to_plot)), vmax=np.nanmax(np.abs(to_plot)))\n",
    "    else:\n",
    "        return matplotlib.colors.SymLogNorm(linthresh, vmin=clim[0], vmax=clim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67094b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_waterfall(data, bl=(ANTPAIR + ('ee',)), flags=flags, nsamples=nsamples, tslice=tslice):\n",
    "    '''Plots data (amplitude and phase) as well as nsamples waterfalls for a baseline.'''\n",
    "    if tslice is None:\n",
    "        tslice = slice(0, data[bl].shape[0], 1)\n",
    "    lsts = np.where(data.lsts > data.lsts[-1], data.lsts - 2 * np.pi, data.lsts)[tslice] * 12 / np.pi\n",
    "    extent = [data.freqs[0]/1e6, data.freqs[-1]/1e6, lsts[-1], lsts[0]]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 12), sharex=True, sharey=True, dpi=100)\n",
    "    im = axes[0].imshow(np.where(flags[bl], np.nan, np.abs(data[bl]))[tslice], aspect='auto', norm=matplotlib.colors.LogNorm(), interpolation='none', cmap='inferno', extent=extent)\n",
    "    fig.colorbar(im, ax=axes[0], location='top', pad=.02, label=f'{bl}: Amplitude (Jy)')\n",
    "\n",
    "    im = axes[1].imshow(np.where(flags[bl], np.nan, np.angle(data[bl]))[tslice], aspect='auto', cmap='twilight', interpolation='none', extent=extent)\n",
    "    fig.colorbar(im, ax=axes[1], location='top', pad=.02, label=f'{bl}: Phase (Radians)')\n",
    "\n",
    "    im = axes[2].imshow(nsamples[bl][tslice], aspect='auto', interpolation='none', extent=extent)\n",
    "    fig.colorbar(im, ax=axes[2], location='top', pad=.02, label=f'{bl}: Number of Samples')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_ylabel('LST (Hours)')\n",
    "        ax.set_xlabel('Frequency (MHz)')\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            ax.set_yticklabels([f'{(int(val) if np.isclose(val, int(val)) else val) % 24:n}' for val in ax.get_yticks()])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547cd7f4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_real_delay_vs_lst(data, bl=(ANTPAIR + ('ee',)), flags=None, xlim=[-1999, 1999], clim=None, linthresh=10, taper=TAPER, tslice=tslice):\n",
    "    '''Plots the real part of the tapered FFT of the data in each power spectrum band as a function of delay and LST.'''\n",
    "    if tslice is None:\n",
    "        tslice = slice(0, data[bl].shape[0], 1)\n",
    "    lsts = np.where(data.lsts > data.lsts[-1], data.lsts - 2 * np.pi, data.lsts)[tslice] * 12 / np.pi\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(bands), figsize=(28, 12), sharex=True, sharey=True, gridspec_kw={'wspace': .03}, dpi=100)\n",
    "    for i, (ax, band, band_slice) in enumerate(zip(axes, bands, band_slices)):\n",
    "        dfft = uvtools.utils.FFT(data[bl][tslice, band_slice], axis=1, taper=taper)\n",
    "        delays = uvtools.utils.fourier_freqs(data.freqs[band_slice]) * 1e9\n",
    "        to_plot = np.real(dfft)\n",
    "        if flags is not None:\n",
    "            flagged_times = np.all(flags[bl][tslice, band_slice], axis=1)\n",
    "            to_plot[flagged_times, :] = np.nan\n",
    "        if i == 0:\n",
    "            _to_plot = copy.deepcopy(to_plot)\n",
    "            ax.set_ylabel('LST (Hours)')\n",
    "        im = ax.imshow(to_plot, interpolation='none', aspect='auto', cmap='bwr', norm=sym_log_norm(_to_plot, linthresh=linthresh, clim=clim),\n",
    "                       extent=[delays[0], delays[-1], lsts[-1], lsts[0]])\n",
    "        for dly in dly_filter_half_widths[0] * 1e9 * np.array([1, -1]):\n",
    "            ax.axvline(dly, ls='--', color='k', lw=.5)\n",
    "        for dly in inpaint_filter_half_widths[0] * 1e9 * np.array([1, -1]):\n",
    "            ax.axvline(dly, ls=':', color='k', lw=.5)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_title(f'Band {i+1}:\\n{band[0]}—{band[1]} MHz', fontsize=10)\n",
    "        ax.set_xlabel('Delay (ns)')\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            ax.set_yticklabels([f'{(int(val) if np.isclose(val, int(val)) else val) % 24:n}' for val in ax.get_yticks()])\n",
    "\n",
    "    plt.colorbar(im, ax=axes, pad=.02, aspect=40, extend='both', label=f'Re$[\\\\widetilde{{V}}_{{{bl}}}]$ (Jy)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3940a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_dly_vs_fr(data, bl=(ANTPAIR + ('ee',)), xlim=[-1999, 1999], ylim=[-5, 5], clim=None, tslice=tslice, taper=TAPER):\n",
    "    '''Plots the magnitude of the 2D tapered FFT of the data in each power spectrum band as a function of delay and FR.\n",
    "    Also shows the foreground filtering delay, the main beam range of FRs, and the expected shape of mutual coupling.'''\n",
    "    fig, axes = plt.subplots(1, len(bands), figsize=(28, 6), sharex=True, sharey=True, gridspec_kw={'wspace': .03}, dpi=100)\n",
    "    if tslice is None:\n",
    "        tslice = slice(0, data[bl].shape[0], 1)\n",
    "\n",
    "    to_plots = []\n",
    "    for i, (ax, band, band_slice) in enumerate(zip(axes, bands, band_slices)):\n",
    "        dfft = uvtools.utils.FFT(data[bl][:, band_slice], axis=1, taper=TAPER)\n",
    "        delays = uvtools.utils.fourier_freqs(data.freqs[band_slice]) * 1e9\n",
    "        frates = uvtools.utils.fourier_freqs((data.times[tslice] - data.times[0]) * 24 * 60 * 60) * 1000\n",
    "\n",
    "        dfft2 = uvtools.utils.FFT(dfft[tslice, :], axis=0, taper=TAPER)\n",
    "\n",
    "        to_plot = np.abs(dfft2)\n",
    "        to_plots.append(to_plot)\n",
    "        if i == 0:\n",
    "            _to_plot = copy.deepcopy(to_plot)\n",
    "            ax.set_ylabel('Fringe Rate (mHz)')        \n",
    "        im = ax.imshow(to_plot, interpolation='none', aspect='auto', cmap='turbo', \n",
    "                       norm=matplotlib.colors.LogNorm(vmin=(clim[0] if clim is not None else np.min(_to_plot)), \n",
    "                                                      vmax=(clim[1] if clim is not None else np.max(_to_plot))),\n",
    "                       extent=[delays[0], delays[-1], frates[-1], frates[0]])\n",
    "        for dly in dly_filter_half_widths[0] * 1e9 * np.array([1, -1]):\n",
    "            ax.axvline(dly, ls='--', color='k', lw=.5)\n",
    "        for dly in inpaint_filter_half_widths[0] * 1e9 * np.array([1, -1]):\n",
    "            ax.axvline(dly, ls=':', color='k', lw=.5)\n",
    "        for fr in fr_ranges[band]:# + (pol,)]:\n",
    "            ax.axhline(fr, ls='--', color='k', lw=.5)\n",
    "\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_title(f'Band {i+1}:\\n{band[0]}—{band[1]} MHz', fontsize=10)\n",
    "        ax.set_xlabel('Delay (ns)')\n",
    "\n",
    "    plt.colorbar(im, ax=axes, pad=.02, aspect=40, extend='both', label=f'$|\\\\widetilde{{V}}_{{{bl}}}|$ (Jy)')\n",
    "    \n",
    "    omega_earth = 2 * np.pi / (24 * 3600) #rad/s\n",
    "    hera_dec = -30.72152612068925 * np.pi / 180\n",
    "    def calculate_fr(bl_vec, freq):\n",
    "        \"\"\"bl_vec in meters, freq in Hz, returns fr in mHz\"\"\"\n",
    "        bl_we = bl_vec[0]\n",
    "        fr = -bl_we * omega_earth * freq * np.cos(hera_dec) / constants.c * 1e3\n",
    "        return fr\n",
    "    def max_fr(tau, freq):\n",
    "        \"\"\"takes in tau in ns, freq in Hz, returns corresponding max fringe rate in mHz\"\"\"\n",
    "        return omega_earth * freq * tau * np.cos(hera_dec) * 1e-6 # mHz \n",
    "\n",
    "    b_ij = data.antpos[bl[1]] - data.antpos[bl[0]]\n",
    "    for i in range(len(bands)):\n",
    "        freq = np.mean(bands[i]) * 1e6\n",
    "        axes[i].plot(delays, max_fr(delays, freq) + calculate_fr(b_ij, freq), color='k', ls='--', lw=.5)\n",
    "        axes[i].plot(delays, -max_fr(delays, freq) + calculate_fr(b_ij, freq), color='k', ls='--', lw=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b457ac",
   "metadata": {},
   "source": [
    "## Filtering and Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay_filter(data, wgts, filter_centers, filter_half_widths, eigenval_cutoff, cache={}, bls=None, zeros_where_zero_wgt=True):\n",
    "    '''This function performs a high-pass delay filter, removing the wedge plus some buffer. It also performs inpainting with the same delay.'''\n",
    "    dly_filt_data = copy.deepcopy(data)\n",
    "    inpainted_data = copy.deepcopy(data)\n",
    "    if bls is None:\n",
    "        bls = cross_bls\n",
    "    \n",
    "    for bl in bls:\n",
    "        d_mdl = np.zeros_like(dly_filt_data[bl])\n",
    "        for band in [low_band, high_band]:\n",
    "            d_mdl[:, band], _, info = dspec.fourier_filter(data.freqs[band], dly_filt_data[bl][:, band], wgts=wgts[bl][:, band], filter_centers=filter_centers, \n",
    "                                                           filter_half_widths=filter_half_widths, mode='dpss_solve', \n",
    "                                                           eigenval_cutoff=[eigenval_cutoff], suppression_factors=[eigenval_cutoff], \n",
    "                                                           max_contiguous_edge_flags=len(data.freqs), cache=cache)\n",
    "        if zeros_where_zero_wgt:\n",
    "            dly_filt_data[bl] = np.where(wgts[bl] == 0, 0, dly_filt_data[bl] - d_mdl)\n",
    "        else:\n",
    "            dly_filt_data[bl] = dly_filt_data[bl] - d_mdl\n",
    "        inpainted_data[bl] = np.where(wgts[bl] == 0, d_mdl, data[bl])\n",
    "    \n",
    "    return dly_filt_data, inpainted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xtalk_filter(data, wgts, xtalk_fr=XTALK_FR, tslice=tslice, cache={}, bls=None):\n",
    "    '''This function performs a high-pass filter in fringe rate, removing some small range around the 0 FR mode.'''\n",
    "    xtalk_filt_data = copy.deepcopy(data)\n",
    "    if bls is None:\n",
    "        bls = cross_bls\n",
    "    \n",
    "    for bl in bls:\n",
    "        if tslice is None:\n",
    "            tslice = slice(0, data[bl].shape[0], 1)\n",
    "\n",
    "        d_mdl, _, info = dspec.fourier_filter(data.times[tslice] * 24 * 60 * 60, data[bl][tslice], \n",
    "                                              wgts=wgts[bl][tslice, :], filter_centers=[0], \n",
    "                                              filter_half_widths=[xtalk_fr / 1000], mode='dpss_solve', \n",
    "                                              eigenval_cutoff=[FR_EIGENVAL_CUTOFF], suppression_factors=[FR_EIGENVAL_CUTOFF], \n",
    "                                              max_contiguous_edge_flags=len(data.times), cache=cache, filter_dims=0)\n",
    "\n",
    "        xtalk_filt_data[bl][tslice, :] = np.where(wgts[bl][tslice, :] == 0, 0, xtalk_filt_data[bl][tslice, :] - d_mdl)\n",
    "    return xtalk_filt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4735a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_beam_FR_filter(data, wgts, tslice=tslice, cache={}, bls=None, suppression_factors=[FR_EIGENVAL_CUTOFF]):\n",
    "    '''This function performs fringe rate filtering, keeping a range determined by fr_ranges for each band.'''\n",
    "    frf_data = copy.deepcopy(data)\n",
    "    if bls is None:\n",
    "        bls = cross_bls\n",
    "    \n",
    "    for bl in bls:    \n",
    "        if tslice is None:\n",
    "            tslice = slice(0, data[bl].shape[0], 1)\n",
    "\n",
    "    \n",
    "        d_mdl = np.zeros_like(data[bl])\n",
    "        for band, band_slice in zip(bands, band_slices):\n",
    "            d_mdl[tslice, band_slice], _, _ = dspec.fourier_filter(data.times[tslice] * 24 * 60 * 60,\n",
    "                                                                   data[bl][tslice, band_slice],\n",
    "                                                                   wgts=wgts[bl][tslice, band_slice],\n",
    "                                                                   filter_centers=[np.mean(fr_ranges[band]) / 1000],\n",
    "                                                                   filter_half_widths=[np.diff(fr_ranges[band]) / 2 / 1000], \n",
    "                                                                   mode='dpss_solve', eigenval_cutoff=[FR_EIGENVAL_CUTOFF], \n",
    "                                                                   suppression_factors=suppression_factors, \n",
    "                                                                   max_contiguous_edge_flags=len(data.times), cache=cache, filter_dims=0)\n",
    "        frf_data[bl] *= 0\n",
    "        frf_data[bl][tslice, :] = np.where(wgts[bl][tslice, :] == 0, 0, d_mdl[tslice, :])\n",
    "    \n",
    "    return frf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c71b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_pseudostokes(data=None, flags=None, nsamples=None, pol_convention=hd.pol_convention, x_orientation=hd.x_orientation):\n",
    "    '''This function uses hera_pspec.pstokes to supplement existing datacontainers with pstokes I, Q, U, and/or V (where possible).'''\n",
    "    for ap in data.antpairs():\n",
    "        # loop over pseudo-stokes parameters\n",
    "        iter_list = [('ee', 'nn', 'pI'), ('ee', 'nn', 'pQ'), ('en', 'ne', 'pU'), ('en', 'ne', 'pV')]\n",
    "        if not FOUR_POL:\n",
    "            iter_list = iter_list[:2]\n",
    "        for pol1, pol2, pstokes in iter_list:\n",
    "            bl1 = ap + (pol1,)\n",
    "            bl2 = ap + (pol2,)\n",
    "            data_list = ([data[bl1], data[bl2]] if (data is not None) and (bl1 in data) and (bl2 in data) else None)\n",
    "            flags_list = ([flags[bl1], flags[bl2]] if (flags is not None) and (bl1 in flags) and (bl2 in flags) else None)\n",
    "            nsamples_list = ([nsamples[bl1], nsamples[bl2]] if (nsamples is not None) and (bl1 in nsamples) and (bl2 in nsamples) else None)\n",
    "\n",
    "            # use hp.pstokes._combine_pol_arrays() to properly combine data/flags/nsamples in a pol_convention-aware way\n",
    "            (combined_data, \n",
    "             combined_flags, \n",
    "             combined_nsamples) = hp.pstokes._combine_pol_arrays(pol1, pol2, pstokes, \n",
    "                                                                 pol_convention=pol_convention,\n",
    "                                                                 data_list=data_list,\n",
    "                                                                 flags_list=flags_list,\n",
    "                                                                 nsamples_list=nsamples_list,\n",
    "                                                                 x_orientation=x_orientation)\n",
    "            # put results in original data containers\n",
    "            if data is not None:\n",
    "                data[ap + (pstokes,)] = combined_data\n",
    "            if flags is not None:\n",
    "                flags[ap + (pstokes,)] = combined_flags\n",
    "            if nsamples is not None:\n",
    "                nsamples[ap + (pstokes,)] = combined_nsamples * 4.0\n",
    "                # TODO: This 4.0 is very ad hoc and is put here to fix an issue with error bars that arose in the \n",
    "                # change of pol_convention from \"avg\" to \"sum\". Once we've tracked down all the appropriate factors\n",
    "                # of 2, this should not be necessary. See https://github.com/HERA-Team/hera_pspec/issues/406 for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e04ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: graduate this function into hera_cal\n",
    "\n",
    "def deinterleave_datacontainer(dc, ninterleave=NINTERLEAVE, tslice=slice(None)):\n",
    "    '''Breaks datacontainers into ninterleave separate containers and returns a list of deinterleaved datacontainers.\n",
    "    Also updates .times and .lsts attributes. Integrations at the end that do not evenly divide are dropped.'''\n",
    "    deint_dcs = []\n",
    "    for i in range(ninterleave):\n",
    "        islice = slice(i, (len(dc.times[tslice]) // ninterleave) * ninterleave, ninterleave)  # ensures all slices have same shape\n",
    "        new_dc = copy.deepcopy(dc)\n",
    "        new_dc.times = dc.times[tslice][islice]\n",
    "        new_dc.lsts = dc.lsts[tslice][islice]\n",
    "        for bl in new_dc:\n",
    "            new_dc[bl] = dc[bl][tslice, :][islice, :]\n",
    "        deint_dcs.append(new_dc)\n",
    "    return deint_dcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b15cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeavg_data(data, flags, nsamples, Navg=int(np.round(AVERAGING_TIME / (dt * NINTERLEAVE))), pols=None, tslice=slice(None), rephase=True):\n",
    "    '''Performs coherent averaging of Navg integrations, rephasing to the common phase center.'''\n",
    "    avg_data = datacontainer.DataContainer({})\n",
    "    avg_flags = datacontainer.DataContainer({})\n",
    "    avg_nsamples = datacontainer.DataContainer({})\n",
    "    \n",
    "    # perform time-averaging\n",
    "    for bl in data:\n",
    "        if (pols is not None) and (bl[2] not in pols):\n",
    "            continue\n",
    "        bl_vec =  data.antpos[bl[0]] - data.antpos[bl[1]]\n",
    "        (avg_data[bl], \n",
    "         avg_flags[bl], \n",
    "         avg_nsamples[bl], \n",
    "         avg_lsts, \n",
    "         extra) = frf.timeavg_waterfall(data[bl][tslice, :], Navg,\n",
    "                                        flags=np.zeros_like(flags[bl][tslice, :]),\n",
    "                                        nsamples=nsamples[bl][tslice, :], \n",
    "                                        extra_arrays={'times': data.times[tslice]},\n",
    "                                        lsts=data.lsts[tslice], freqs=data.freqs,\n",
    "                                        rephase=rephase, bl_vec=bl_vec, verbose=False)\n",
    "        avg_flags[bl][avg_nsamples[bl] == 0] = True # TODO: is this right???\n",
    "    \n",
    "    # attach relevant quantities to datacontainer\n",
    "    for dc in (avg_data, avg_flags, avg_nsamples):\n",
    "        dc.freqs = copy.deepcopy(data.freqs)\n",
    "        dc.antpos = copy.deepcopy(data.antpos)\n",
    "        dc.lsts = avg_lsts\n",
    "        dc.times = extra['avg_times']\n",
    "    return avg_data, avg_flags, avg_nsamples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b977fca",
   "metadata": {},
   "source": [
    "## Figure out delay filter properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eeb741",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_vec = (data.antpos[ANTPAIR[1]] - data.antpos[ANTPAIR[0]])\n",
    "bl_len = np.linalg.norm(bl_vec[:2]) / constants.c\n",
    "dly_filter_centers, dly_filter_half_widths = vis_clean.gen_filter_properties(ax='freq', horizon=DLY_FILT_HORIZON, standoff=DLY_FILT_STANDOFF, \n",
    "                                                                             min_dly=DLY_FILT_MIN_DLY, bl_len=bl_len)\n",
    "inpaint_filter_centers, inpaint_filter_half_widths = vis_clean.gen_filter_properties(ax='freq', horizon=INPAINT_HORIZON, standoff=INPAINT_STANDOFF, \n",
    "                                                                                     min_dly=INPAINT_MIN_DLY, bl_len=bl_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d946f1a",
   "metadata": {},
   "source": [
    "## If desired, propagate flags on a channel to all times that will be coherently averaged together\n",
    "\n",
    "This is primarily useful in the delay-filtered case with flags, where we want to avoid different interleaves having different flagging patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b0867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factored_flags(flag_array, tslice=slice(None)):\n",
    "    '''If any channel is flagged in a boolean flag_array, flag all times for that channel unless the channel flag comes from an entirely flagged time.'''\n",
    "    out_flags = np.zeros_like(flag_array)\n",
    "    flagged_times = np.all(flag_array, axis=1)\n",
    "    out_flags[flagged_times, :] = True\n",
    "    if not np.all(flagged_times) :\n",
    "        chan_flags = np.any(flag_array[~flagged_times], axis=0)\n",
    "        out_flags[:, chan_flags] = True\n",
    "    return out_flags\n",
    "\n",
    "if FLAG_COHERENT_CHUNKS:\n",
    "    Nchunk = int(AVERAGING_TIME // (dt * NINTERLEAVE)) * NINTERLEAVE\n",
    "    for ci in range(int(np.ceil(flags[bl][tslice].shape[0] / Nchunk))):\n",
    "        for bl in flags:\n",
    "            flags[bl][tslice][ci * Nchunk:(ci + 1) * Nchunk] = factored_flags(flags[bl][tslice][ci * Nchunk:(ci + 1) * Nchunk], tslice=tslice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7041ec",
   "metadata": {},
   "source": [
    "## Perform inpainting and/or delay-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_band_avg_nsamples(nsamples, band_slices):\n",
    "    '''Create new datacontainer where nsamples has been averaged per-integration in band_slices.\n",
    "    This is an approximate way to account for the fact that inpainted data is considered Nsamples=0.'''\n",
    "    out_nsamples = copy.deepcopy(nsamples)\n",
    "    for bl in out_nsamples:\n",
    "        for band in band_slices:\n",
    "            for i in range(out_nsamples[bl].shape[0]):\n",
    "                out_nsamples[bl][i, band] = np.mean(out_nsamples[bl][i, band])\n",
    "    return out_nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weights(data, flags, nsamples, wgt_by_avg_nsamples=False, band_slices=[]):\n",
    "    '''Construct weights proportional to inverse noise variance (i.e. Nsamples / Autocorr^2).\n",
    "    If wgt_by_avg_nsamples is True, average Nsamples in each subband (defined with band_slices).\n",
    "    This avoids the introduction of spectral structure.'''\n",
    "    wgts = copy.deepcopy(data)\n",
    "    if wgt_by_avg_nsamples:\n",
    "        nsamples_here = per_band_avg_nsamples(nsamples, band_slices)\n",
    "    else:\n",
    "        nsamples_here = copy.deepcopy(nsamples)        \n",
    "        \n",
    "    for bl in wgts:               \n",
    "        auto_bl = auto_antpair + bl[2:]\n",
    "        wgts[bl] = np.where(flags[bl], 0, np.abs(data[auto_bl])**-2 * nsamples_here[bl])\n",
    "        wgts[bl] /= np.abs(np.nanmean(np.where(flags[bl], np.nan, wgts[bl])))  # avoid dynamic range issues\n",
    "        wgts[bl][~np.isfinite(wgts[bl])] = 0\n",
    "    \n",
    "    return wgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5197c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build weights for delay-filter and/or inpainting that don't involve any Nsample averaging\n",
    "freq_filt_wgts = build_weights(data, flags, nsamples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df22ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpaint autocorrelations to allow for prediction of thermal noise on every channel\n",
    "if not ALREADY_INPAINTED:\n",
    "    _, data = delay_filter(data, freq_filt_wgts, inpaint_filter_centers, inpaint_filter_half_widths, INPAINT_EIGENVAL_CUTOFF, \n",
    "                           bls=[auto_antpair + (pol,) for pol in ['ee', 'nn']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_data = copy.deepcopy(data)\n",
    "filt_flags = copy.deepcopy(flags)\n",
    "filt_nsamples = copy.deepcopy(nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c69eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell replaces data with appropriate noise, which is useful for debugging\n",
    "if USE_SIMULATED_NOISE:\n",
    "    np.random.seed(21)\n",
    "\n",
    "    reds = redcal.get_reds(filt_data.data_antpos, pols=filt_data.pols(), include_autos=True, bl_error_tol=2.0)\n",
    "    red_inpainted = datacontainer.RedDataContainer(data, reds=reds)\n",
    "\n",
    "    for bl in cross_bls:\n",
    "        predicted_var = noise.predict_noise_variance_from_autos(bl, red_inpainted, nsamples=nsamples)\n",
    "        predicted_var = np.where(~np.isfinite(predicted_var), 0, predicted_var)\n",
    "        filt_data[bl] = np.sqrt(predicted_var) / 2**.5 * (np.random.randn(hd.Ntimes, hd.Nfreqs) + 1.0j * np.random.randn(hd.Ntimes, hd.Nfreqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ace645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpaint crosses\n",
    "if PERFORM_INPAINT:\n",
    "    _, filt_data = delay_filter(data, freq_filt_wgts, inpaint_filter_centers, inpaint_filter_half_widths, INPAINT_EIGENVAL_CUTOFF)\n",
    "    for bl in cross_bls:\n",
    "        for band in [high_band, low_band]:\n",
    "            for i in range(filt_flags[bl].shape[0]):\n",
    "                if not np.all(filt_flags[bl][i, band]):\n",
    "                    filt_flags[bl][i, band] = False\n",
    "inpainted = copy.deepcopy(filt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform delay filtering on crosses\n",
    "if PERFORM_DLY_FILT:\n",
    "    filt_data, _ = delay_filter(inpainted, freq_filt_wgts, dly_filter_centers, dly_filter_half_widths, DLY_FILT_EIGENVAL_CUTOFF, zeros_where_zero_wgt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c052a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute time filter flags, averaging nsamples in subbands if desired (this also applies to further processing)\n",
    "if USE_BAND_AVG_NSAMPLES:\n",
    "    filt_nsamples = per_band_avg_nsamples(filt_nsamples, band_slices)\n",
    "    \n",
    "time_filt_wgts = build_weights(filt_data, filt_flags, filt_nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform deinterleaving\n",
    "deint_filt_data = deinterleave_datacontainer(filt_data, ninterleave=NINTERLEAVE, tslice=tslice)\n",
    "deint_flags = deinterleave_datacontainer(filt_flags, ninterleave=NINTERLEAVE, tslice=tslice)\n",
    "deint_nsamples = deinterleave_datacontainer(filt_nsamples, ninterleave=NINTERLEAVE, tslice=tslice)\n",
    "deint_wgts = deinterleave_datacontainer(time_filt_wgts, ninterleave=NINTERLEAVE, tslice=tslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c910a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precomputation for rephasing before coherent averaging, ensuring all interleaves are rephased to the same lst\n",
    "bl_vec = {bl: data.antpos[bl[0]] - data.antpos[bl[1]] for bl in [ap + (pol,) for ap in data.antpairs() \n",
    "                                                                 for pol in (utils._VISPOLS | set(utils.POL_STR2NUM_DICT))]}\n",
    "Navg = int(AVERAGING_TIME // (dt * NINTERLEAVE))\n",
    "n_avg_int = int(np.ceil(len(deint_filt_data[0].lsts) / Navg))\n",
    "target_lsts = [np.mean([np.unwrap(d.lsts)[i * Navg:(i+1) * Navg] for d in deint_filt_data]) for i in range(n_avg_int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays for storing intermediate and final results for each interleave\n",
    "deint_avg_data, deint_avg_flags, deint_avg_nsamples = [], [], []\n",
    "deint_xtalk_filt_data, deint_frf_data = [], []\n",
    "\n",
    "for d, f, n, w in zip(deint_filt_data, deint_flags, deint_nsamples, deint_wgts):\n",
    "    # Perform full time-filtering\n",
    "    if not SKIP_XTALK_AND_FRF:\n",
    "        # Crosstalk filtering of FR=0 mode\n",
    "        xtalk_filt_d = xtalk_filter(d, w, tslice=None)\n",
    "        deint_xtalk_filt_data.append(xtalk_filt_d)\n",
    "        \n",
    "        # Main beam FRF and forming pseduostokes\n",
    "        frf_d = main_beam_FR_filter(xtalk_filt_d, w, tslice=None)\n",
    "        deint_frf_data.append(frf_d)\n",
    "    else:\n",
    "        deint_xtalk_filt_data.append(d)\n",
    "        deint_frf_data.append(d)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Coherent time-averaging, rephasing to a set of lsts that's consistent across interleaves\n",
    "    dlst = [target_lsts[i] - l for i in range(n_avg_int) for l in np.unwrap(d.lsts)[i * Navg:(i+1) * Navg]]\n",
    "    rephased_frf_d = copy.deepcopy(deint_frf_data[-1])\n",
    "    utils.lst_rephase(rephased_frf_d, bl_vec, d.freqs, dlst, lat=hd.telescope_location_lat_lon_alt_degrees[0], inplace=True)\n",
    "\n",
    "    pstokes_pols = sorted([pol for pol in rephased_frf_d.pols() if utils.polstr2num(pol, x_orientation=hd.x_orientation) > 0])\n",
    "    avg_d, avg_f, avg_n = timeavg_data(rephased_frf_d, f, n, Navg=int(AVERAGING_TIME // (dt * NINTERLEAVE)), \n",
    "                                       pols=[\"ee\", \"nn\", \"ne\", \"en\"], rephase=False)\n",
    "    \n",
    "    # Form pseudo-Stokes I and Q from ee and nn\n",
    "    form_pseudostokes(avg_d, avg_f, avg_n)\n",
    "    # Store Results\n",
    "    deint_avg_data.append(avg_d)\n",
    "    deint_avg_flags.append(avg_f)\n",
    "    deint_avg_nsamples.append(avg_n)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560e664",
   "metadata": {},
   "source": [
    "# Calculate FRF noise covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae5075",
   "metadata": {},
   "source": [
    "## First check that the alternate FRF operator doesn't do something insane by comparing a few streams at a given spectral window to the pipeline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_rad_to_hours(lsts_rad, tslice=slice(None)):\n",
    "    lsts_hrs = np.where(lsts_rad > lsts_rad[-1], lsts_rad - 2 * np.pi, lsts_rad)[tslice] * 12 / np.pi\n",
    "    \n",
    "    return lsts_hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36b1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def get_frop_wrapper(pol=\"nn\", stream_ind=0, band_ind=0, t_avg=AVERAGING_TIME, \n",
    "                     rephase=True, wgt_tavg_by_nsample=True, nsamples=None, bl_vec=None,\n",
    "                     dlst=None, coherent_avg=True):\n",
    "    \n",
    "    bl=(ANTPAIR[0], ANTPAIR[1], pol)\n",
    "    band = bands[band_ind]\n",
    "    band_slice = band_slices[band_ind]\n",
    "    Nfreqs = band_slice.stop - band_slice.start\n",
    "\n",
    "    weights=deint_wgts[stream_ind][bl][:, band_slice]\n",
    "    times = np.modf(single_bl_times[tslice][stream_ind::4])[0] * 24 * 3600\n",
    "    times = times - times[0]\n",
    "\n",
    "\n",
    "    \n",
    "    frop = FRF_cov_calc.get_frop(times, filter_cent_use=[np.mean(fr_ranges[band]) / 1000], \n",
    "                                 filter_half_wid_use=[np.diff(fr_ranges[band]) / 2 / 1000], \n",
    "                                 freqs=data.freqs[band_slice], t_avg=t_avg,\n",
    "                                 cutoff=FR_EIGENVAL_CUTOFF, weights=weights,\n",
    "                                 rephase=rephase, wgt_tavg_by_nsample=wgt_tavg_by_nsample,\n",
    "                                 nsamples=nsamples, bl_vec=bl_vec, dlst=dlst,\n",
    "                                 coherent_avg=coherent_avg)\n",
    "    return frop\n",
    "\n",
    "def get_alt_frf_dat(pol=\"nn\", stream_ind=0, band_ind=0, t_avg=AVERAGING_TIME, \n",
    "                    rephase=True, wgt_tavg_by_nsample=True, nsamples=None, bl_vec=None,\n",
    "                    dlst=None, coherent_avg=True):\n",
    "    \n",
    "    bl=(ANTPAIR[0], ANTPAIR[1], pol)\n",
    "    band = bands[band_ind]\n",
    "    band_slice = band_slices[band_ind]\n",
    "    \n",
    "    frop = get_frop_wrapper(pol=pol, stream_ind=stream_ind, band_ind=band_ind, t_avg=t_avg,\n",
    "                            rephase=rephase, wgt_tavg_by_nsample=wgt_tavg_by_nsample,\n",
    "                            nsamples=nsamples, bl_vec=bl_vec, dlst=dlst, coherent_avg=coherent_avg)\n",
    "\n",
    "    deint_xtalk_filt_data_test = deint_xtalk_filt_data[stream_ind][bl][:, band_slice]\n",
    "    deint_frf_data_test = deint_frf_data[stream_ind][bl][:, band_slice]\n",
    "    alt_frf_data = (frop * deint_xtalk_filt_data_test).sum(axis=1)\n",
    "    \n",
    "    return deint_frf_data_test, alt_frf_data\n",
    "\n",
    "def plot_streams(test_data, alt_data, band_ind=0, amp=True, linthresh=1e-6):\n",
    "    band_slice = band_slices[band_ind]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=[12, 8])\n",
    "    \n",
    "    \n",
    "\n",
    "    for stream_ind in range(4):\n",
    "        if amp:\n",
    "            dat_plot = np.abs(alt_data[stream_ind] / test_data[stream_ind]) - 1\n",
    "        else:\n",
    "            dat_plot = np.angle(alt_data[stream_ind] / test_data[stream_ind])\n",
    "\n",
    "        \n",
    "        lst_use = lst_rad_to_hours(deint_frf_data[stream_ind].lsts)\n",
    "        freq_low, freq_high = bands[band_ind]\n",
    "        \n",
    "        im = ax[stream_ind].matshow(dat_plot, norm=matplotlib.colors.SymLogNorm(linthresh=linthresh),\n",
    "                                    aspect=\"auto\", extent=(freq_low, freq_high, lst_use[-1], lst_use[0]),\n",
    "                                    cmap=\"coolwarm\",)\n",
    "        ax[stream_ind].set_title(f\"Stream {stream_ind}\")\n",
    "        ax[stream_ind].set_xlabel(\"Frequency (MHz)\")\n",
    "        ax[stream_ind].set_ylabel(\"LST (hours)\")\n",
    "        \n",
    "        divider = make_axes_locatable(ax[stream_ind])\n",
    "        axBar = divider.append_axes(\"bottom\", '5%', pad='7%')\n",
    "        axHist = divider.append_axes(\"bottom\", '30%', pad='14%')\n",
    "        \n",
    "        cbar = plt.colorbar(im, cax=axBar, orientation='horizontal')\n",
    "        amin = np.log10(np.nanmin(np.abs(dat_plot)))\n",
    "        amax = np.log10(np.nanmax(np.abs(dat_plot)))\n",
    "        axHist.hist(np.abs(dat_plot).flatten(), bins=np.logspace(amin, amax, num=100), histtype=\"step\", log=True)\n",
    "        axHist.set_xscale(\"log\")\n",
    "        if amp:\n",
    "            label = r\"$|\\frac{|V|_\\mathrm{alt}}{|V|_\\mathrm{pipe}} - 1|$\"\n",
    "        else:\n",
    "            label = r\"$|\\Delta\\phi|$ (rad)\"\n",
    "        axHist.set_xlabel(label, fontsize=12)\n",
    "        \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70063cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_ind = 0\n",
    "\n",
    "deint_frf_data_test = []\n",
    "alt_frf_data = []\n",
    "for stream_ind in range(4):\n",
    "\n",
    "    deint_frf_data_test_stream, alt_frf_data_stream = get_alt_frf_dat(stream_ind=stream_ind, band_ind=band_ind,\n",
    "                                                                      t_avg=40., rephase=False, \n",
    "                                                                      wgt_tavg_by_nsample=False,\n",
    "                                                                      coherent_avg=True)\n",
    "    deint_frf_data_test.append(deint_frf_data_test_stream)\n",
    "    alt_frf_data.append(alt_frf_data_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740ec6c",
   "metadata": {},
   "source": [
    "### Amplitude fractional error, no coherent averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562df6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_streams(deint_frf_data_test, alt_frf_data, amp=True, linthresh=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e88aa5",
   "metadata": {},
   "source": [
    "### Absolute phase errors, no coherent averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafdcc8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_streams(deint_frf_data_test, alt_frf_data, amp=False, linthresh=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alt_coavg_dat(stream_ind=0, band_ind=0):\n",
    "\n",
    "    dlst = [target_lsts[i] - l for i in range(n_avg_int) for l in np.unwrap(deint_filt_data[stream_ind].lsts)[i * Navg:(i+1) * Navg]]\n",
    "    dlst = np.array(dlst).flatten()\n",
    "\n",
    "    _, alt_frf_nn = get_alt_frf_dat(t_avg=AVERAGING_TIME, \n",
    "                                    nsamples=deint_nsamples[0][(0, 4, \"nn\")][:, band_slices[band_ind]],\n",
    "                                    bl_vec=bl_vec[(0, 4, \"nn\")], dlst=dlst,)\n",
    "    _, alt_frf_ee = get_alt_frf_dat(pol=\"ee\", t_avg=AVERAGING_TIME, \n",
    "                                    nsamples=deint_nsamples[0][(0, 4, \"ee\")][:, band_slices[band_ind]],\n",
    "                                    bl_vec=bl_vec[(0, 4, \"ee\")], dlst=dlst,)\n",
    "\n",
    "    alt_frf_pI = (alt_frf_nn + alt_frf_ee)\n",
    "    \n",
    "    return alt_frf_pI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_frf_pI = get_alt_coavg_dat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffaaeda",
   "metadata": {},
   "source": [
    "# Fractional error after FRF + coherent average + convert to pI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd761f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "dat_plot = np.abs(alt_frf_pI/deint_avg_data[0][(0, 4, \"pI\")][:, band_slices[0]] - 1)\n",
    "coherent_lsts = lst_rad_to_hours(deint_avg_data[0].lsts)\n",
    "\n",
    "\n",
    "extent = [bands[0][0], bands[0][1], coherent_lsts[-1], coherent_lsts[0]]\n",
    "im = plt.matshow(dat_plot, norm=matplotlib.colors.LogNorm(), extent=extent)\n",
    "plt.gca().xaxis.set_label_position('top')\n",
    "plt.xlabel(\"Frequency (MHz)\")\n",
    "plt.ylabel(\"LST(hours)\")\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "axBar = divider.append_axes(\"bottom\", '5%', pad='7%')\n",
    "axHist = divider.append_axes(\"bottom\", '30%', pad='10%')\n",
    "        \n",
    "cbar = plt.colorbar(im, cax=axBar, orientation='horizontal')\n",
    "amin = np.log10(np.nanmin(np.abs(dat_plot)))\n",
    "amax = np.log10(np.nanmax(np.abs(dat_plot)))\n",
    "axHist.hist(dat_plot.flatten(), bins=np.logspace(amin, amax, num=100), histtype=\"step\", log=True)\n",
    "axHist.set_xscale(\"log\")\n",
    "axHist.set_xlabel(\"Fractional Error\")\n",
    "axHist.set_xlim([10**amin, 10**amax])\n",
    "axHist.axvline(np.median(dat_plot), linestyle=\"--\", color=\"black\")\n",
    "axHist.axvline(np.quantile(dat_plot, norm.cdf(-2)), linestyle=\":\", color=\"black\")\n",
    "axHist.axvline(np.quantile(dat_plot, norm.cdf(2)), linestyle=\":\", color=\"black\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79980689",
   "metadata": {},
   "source": [
    "# Close enough for now. Let's press on to covariance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_varis(pol=\"ee\", band_ind=0, stream_ind=0):\n",
    "    auto_bl = (0, 0, pol)\n",
    "    cross_bl = (ANTPAIR[0], ANTPAIR[1], pol)\n",
    "    band_slice = band_slices[band_ind]\n",
    "    df = data.freqs[1] - data.freqs[0] # Hz\n",
    "    dt = (data.times[1] - data.times[0]) * 24 * 60 * 60 # s at integration cadence not interleave cadence\n",
    "\n",
    "\n",
    "    # Only have the (0,0) autos due to red_avg. so square the (0, 0)\n",
    "    varis_num = np.abs(deint_filt_data[stream_ind][auto_bl][:, band_slice])**2 # No inpainting/delay filter so this is the right auto\n",
    "    varis_den =  deint_nsamples[stream_ind][cross_bl][:, band_slice] * dt * df\n",
    "\n",
    "    varis = varis_num / varis_den\n",
    "    \n",
    "    default_value = 0\n",
    "\n",
    "    # Check all the infs are weighted to zero and replace with default value\n",
    "    all_infs_zero = np.all(deint_wgts[stream_ind][cross_bl][:, band_slice][np.isinf(varis)]) == 0\n",
    "    print(f\"Are all infinite variance locations of zero weight?: {all_infs_zero}\")\n",
    "\n",
    "    varis[np.isinf(varis)] = default_value\n",
    "    \n",
    "    return varis\n",
    "\n",
    "def get_pI_cov(band_ind, stream_ind=0):\n",
    "\n",
    "    varis_ee = get_varis(band_ind=band_ind, stream_ind=stream_ind)\n",
    "    varis_nn = get_varis(\"nn\",  band_ind=band_ind, stream_ind=stream_ind)\n",
    "    \n",
    "    frop_ee = get_frop_wrapper(pol=\"ee\", stream_ind=stream_ind, band_ind=band_ind, t_avg=AVERAGING_TIME, \n",
    "                               rephase=True, wgt_tavg_by_nsample=True, \n",
    "                               nsamples=deint_nsamples[stream_ind][(ANTPAIR[0], ANTPAIR[1], \"ee\")][:, band_slices[band_ind]],\n",
    "                               bl_vec=bl_vec[(ANTPAIR[0], ANTPAIR[1], \"ee\")],\n",
    "                               dlst=dlst)\n",
    "    frop_nn = get_frop_wrapper(pol=\"nn\", stream_ind=stream_ind, band_ind=band_ind, t_avg=AVERAGING_TIME, \n",
    "                               rephase=True, wgt_tavg_by_nsample=True, \n",
    "                               nsamples=deint_nsamples[stream_ind][(ANTPAIR[0], ANTPAIR[1], \"nn\")][:, band_slices[band_ind]],\n",
    "                               bl_vec=bl_vec[(ANTPAIR[0], ANTPAIR[1], \"nn\")],\n",
    "                               dlst=dlst)\n",
    "    Nfreqs = frop_ee.shape[2]\n",
    "    cov = np.zeros([Nfreqs, frop.shape[0], frop.shape[0]], dtype=complex)\n",
    "    for freq_ind in range(Nfreqs):\n",
    "        cov_ee_freq = np.tensordot((frop_ee[:, :, freq_ind] * varis_ee[:, freq_ind]), frop_ee[:, :, freq_ind].T.conj(), axes=1)\n",
    "        cov_nn_freq = np.tensordot((frop_nn[:, :, freq_ind] * varis_nn[:, freq_ind]), frop_nn[:, :, freq_ind].T.conj(), axes=1)\n",
    "        cov[freq_ind] = (cov_ee_freq + cov_nn_freq) # Doing the pI cov\n",
    "        if hd.pol_convention == \"avg\":\n",
    "            cov *= 0.25\n",
    "            \n",
    "    return cov\n",
    "\n",
    "\n",
    "def get_corr(cov):\n",
    "    Ntimes = cov.shape[1]\n",
    "    diags = cov[:, np.arange(Ntimes), np.arange(Ntimes)]\n",
    "    corr = cov / np.sqrt(diags[:, None] * diags[:, :, None])\n",
    "    \n",
    "    return corr\n",
    "\n",
    "\n",
    "def get_correction_factor_from_cov(band_ind, stream_ind=0, tslc=None):\n",
    "    cov = get_pI_cov(band_ind, stream_ind=stream_ind)\n",
    "    corr = get_corr(cov)\n",
    "    \n",
    "    if tslc is None:\n",
    "        Ncotimes = corr.shape[1]\n",
    "        Neff = Ncotimes**2 / np.sum(np.abs(corr)**2, axis=(1, 2))\n",
    "    else:\n",
    "        Ncotimes = tslc.stop - tslc.start\n",
    "        Neff = Ncotimes**2 / np.sum(np.abs(corr[:, tslc, tslc])**2, axis=(1, 2))\n",
    "    correction_factor = Ncotimes / Neff\n",
    "    \n",
    "    return correction_factor\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8776d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_cov = get_pI_cov(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9af198",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_lst_extent = [coherent_lsts[0], coherent_lsts[-1], coherent_lsts[-1], coherent_lsts[0]]\n",
    "cov_freq_ind = 50\n",
    "\n",
    "plt.matshow(np.abs(example_cov[cov_freq_ind, :, :]), norm=matplotlib.colors.LogNorm(), \n",
    "            extent=co_lst_extent)\n",
    "plt.colorbar(label=r\"abs(cov) (Jy$^2$)\")\n",
    "plt.gca().xaxis.set_label_position('top')\n",
    "plt.xlabel(\"LST (hours)\")\n",
    "plt.ylabel(\"LST (hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f77cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = get_corr(example_cov)\n",
    "\n",
    "\n",
    "plt.matshow(np.abs(corr[cov_freq_ind]), norm=matplotlib.colors.LogNorm(), extent=co_lst_extent)\n",
    "plt.colorbar(label=\"abs(Corr. Coeff.)\")\n",
    "plt.gca().xaxis.set_label_position('top')\n",
    "plt.xlabel(\"LST (hours)\")\n",
    "plt.ylabel(\"LST (hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e671606",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ind = 68\n",
    "\n",
    "\n",
    "plt.title(f\"Correlation at %.1f MHz with LST=%.2f Hours\" % (data.freqs[band_slices[0]][cov_freq_ind] * 1e-6, coherent_lsts[lst_ind]))\n",
    "plt.plot(coherent_lsts, np.abs(corr[cov_freq_ind, lst_ind, :]))\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"LST (hours)\")\n",
    "plt.ylabel(\"Correlation Amplitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38675d8",
   "metadata": {},
   "source": [
    "### Noise correction factor as a function of frequency for the lowest spectral window\n",
    "\n",
    "This calculation basically takes the correlation matrix above and computes an effective number of degrees of\n",
    "freedom from it. The total number of data points divided by this is the correction factor. This makes a visible\n",
    "improvement in the noise-only histograms when only the central LSTs are used (the calculation below uses all LSTs,\n",
    "but the edge times have funny statistics)\n",
    "\n",
    "TODO: link to a memo that I think Danny will post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.freqs[band_slices[0]] * 1e-6, get_correction_factor_from_cov(band_ind))\n",
    "plt.xlabel(\"Frequency (MHz)\")\n",
    "plt.ylabel(\"Correction factor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046d482",
   "metadata": {},
   "source": [
    "# For the PS covariance (TODO: implement this if desired):\n",
    "\n",
    "$p^{ij}_{\\tau t t'} = x^{i}_{\\tau t} (x^{j}_{\\tau t'})^*$\n",
    "\n",
    "$K^{ijkl}_{\\tau\\tau' t t' t'' t'''}=\\langle p^{ij}_{\\tau t t'}(p^{kl}_{\\tau' t'' t'''})^*\\rangle=\\langle x^{i}_{\\tau t} (x^{j}_{\\tau t'})^*(x^{k}_{\\tau' t''})^*x^{l}_{\\tau't'''}\\rangle = \\delta^{ij}\\delta^{kl}C^{(i)}_{\\tau\\tau t t'}C^{(k)}_{\\tau'\\tau' t'' t'''} + \\delta^{ik}\\delta^{jl}C^{(i)}_{\\tau\\tau' t t''}C^{(j)}_{\\tau\\tau' t' t'''}$ \n",
    "\n",
    "Note that there is also a pseudocovariance...\n",
    "\n",
    "$\\Gamma^{ijkl}_{\\tau\\tau' t t' t'' t'''}=\\langle p^{ij}_{\\tau t t'}p^{kl}_{\\tau' t'' t'''}\\rangle=\\langle x^{i}_{\\tau t} (x^{j}_{\\tau t'})^*x^{k}_{\\tau' t''}(x^{l}_{\\tau't'''})^*\\rangle = \\delta^{ij}\\delta^{kl}C^{(i)}_{\\tau\\tau t t'}C^{(k)}_{\\tau'\\tau' t'' t'''} + \\delta^{il}\\delta^{jk}C^{(i)}_{\\tau\\tau' t t'''}C^{(j)}_{\\tau\\tau' t' t''}$ \n",
    "\n",
    "The first term for both tensors is the \"multiplying the same stream by itself\" term (it's the term with the noise bias) that we are avoiding. The second term in each pair is asking whether the contributing pairs of streams are the same b/w the two delay spectra. For example, if we are asking about the delay spectra formed between streams (0, 1) and (1,2), we will get 0.\n",
    "\n",
    "We often separate the real and imaginary part of the power spectrum. The complex (pseudo)-covariances above can be used to easily express the covariances of the real and imaginary parts of the power spectra, which I have derived in a separate note (but is also just a well-known result). The result for the real-real PS covariance is\n",
    "\n",
    "$\\kappa_{\\Re, \\Re} = \\frac{1}{2}\\Re(K + \\Gamma)$ \n",
    "\n",
    "and for the imaginary-imaginary:\n",
    "\n",
    "$\\kappa_{\\Im, \\Im} = \\frac{1}{2}\\Re(K - \\Gamma)$ \n",
    "\n",
    "To inspect the variance, note that we cannot simultaneously have \n",
    "\n",
    "$i=k$, $j=l$ and $i=l$, $j=k$ without being in a noise-bias case, meaning we need to isolate either the covariance or pseudocovariance term. For this to be a variance of a particular (stream-time)-pair, we must have \n",
    "\n",
    "$t=t''$, $t'=t'''$ AND $i=k$, $j=l$\n",
    "\n",
    "OR\n",
    "\n",
    "$t=t'''$, $t'=t''$ AND $i=l$, $j=k$\n",
    "\n",
    "and no matter what we need $\\tau=\\tau'$. The reason for the OR condition above is that we need to respect that $x$ has both a stream and time index, and we can't swap which time is associated with which stream by just imposing a complex conjugate for example. In math:\n",
    "\n",
    "$p^{ij}_{\\tau t t'} \\neq (p^{ij}_{\\tau t' t})^*$\n",
    "\n",
    "but it is true that\n",
    "\n",
    "$p^{ij}_{\\tau t t'} = (p^{ji}_{\\tau t' t})^*$\n",
    "\n",
    "Respecting this, we find that the variance of the real part is just given equivalently by either term above\n",
    "\n",
    "$Var[\\Re(p^{ij}_{\\tau t t'})] = \\frac{1}{2}\\Re(C^{(i)}_{\\tau\\tau tt}C^{(j)}_{\\tau\\tau t't'})$ which is half the the variance of stream $i$ at time $t$ times the variance of stream $j$ at time $t'$.\n",
    "\n",
    "Done out more explicitly:\n",
    "\n",
    "\n",
    "$Var[\\Re(p^{ij}_{\\tau t t'})] = \\frac{1}{4}\\langle(p^{ij}_{\\tau t t'} + (p^{ij}_{\\tau t t'})^*)^2\\rangle = \\frac{1}{4}(2\\Re(\\Gamma^{ijij}_{\\tau\\tau tt'tt'}) + 2\\Re(K^{ijij}_{\\tau\\tau tt'tt'})) = \\frac{1}{2}\\Re(C^{(i)}_{\\tau\\tau tt}C^{(j)}_{\\tau\\tau t't'})$\n",
    "\n",
    "where we made use of the kronecker deltas to get rid of the pseudocovariance terms and then plugged in the nonzero covariance term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51813f91",
   "metadata": {},
   "source": [
    "# *Figure 2: Waterfalls Before Delay Filtering and/or Inpainting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot_waterfall(data, flags=flags)\n",
    "    plot_real_delay_vs_lst(data, flags=flags, xlim=[-3999, 3999], clim=[-1e4, 1e4])\n",
    "    plot_dly_vs_fr(data, xlim=[-1999, 1999], clim=[1e0, 1e5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e1acd",
   "metadata": {},
   "source": [
    "# *Figure 3: Waterfalls After Delay Filtering and/or Inpainting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc20a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT and (PERFORM_DLY_FILT or PERFORM_INPAINT):\n",
    "    plot_waterfall(filt_data, flags=filt_flags, nsamples=nsamples)\n",
    "    plot_real_delay_vs_lst(filt_data, flags=filt_flags, xlim=[-3999, 3999], clim=[-1e4, 1e4])\n",
    "    plot_dly_vs_fr(filt_data, xlim=[-1999, 1999], clim=[1e0, 1e5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8876ff40",
   "metadata": {},
   "source": [
    "# *Figure 4: First Set of De-Interleaved Waterfalls after Cross-Talk Filtering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcce5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT and not SKIP_XTALK_AND_FRF:\n",
    "    plot_waterfall(deint_xtalk_filt_data[0], flags=deint_flags[0], nsamples=deint_nsamples[0], tslice=None)\n",
    "    plot_real_delay_vs_lst(deint_xtalk_filt_data[0], flags=deint_flags[0], xlim=[-3999, 3999], clim=[-1e4, 1e4], tslice=None)\n",
    "    plot_dly_vs_fr(deint_xtalk_filt_data[0], xlim=[-1999, 1999], clim=[1e0, 1e5], tslice=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a580750",
   "metadata": {},
   "source": [
    "# *Figure 5: First Set of De-Interleaved Waterfalls after Main-Beam Fringe-Rate Filtering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578729b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT and not SKIP_XTALK_AND_FRF:\n",
    "    plot_waterfall(deint_frf_data[0], flags=deint_flags[0], nsamples=deint_nsamples[0], tslice=None)\n",
    "    plot_real_delay_vs_lst(deint_frf_data[0], flags=deint_flags[0], xlim=[-3999, 3999], clim=[-2e2, 2e2], linthresh=1, tslice=None)\n",
    "    plot_dly_vs_fr(deint_frf_data[0], xlim=[-1999, 1999], clim=[1e0, 1e5], tslice=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52232ecf",
   "metadata": {},
   "source": [
    "# *Figure 6: First Set of De-Interleaved Waterfalls after Forming Pseudo-Stokes I*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: The deint_frf_data no longer has pI since we go to pI after coherent average\n",
    "\n",
    "if PLOT:\n",
    "    plot_waterfall(deint_frf_data[0], bl=(ANTPAIR + ('pI',)), flags=deint_flags[0], nsamples=deint_nsamples[0], tslice=None)\n",
    "    plot_real_delay_vs_lst(deint_frf_data[0], bl=(ANTPAIR + ('pI',)), flags=deint_flags[0], xlim=[-3999, 3999], clim=[-2e2, 2e2], linthresh=1, tslice=None)\n",
    "    plot_dly_vs_fr(deint_frf_data[0], bl=(ANTPAIR + ('pI',)),  xlim=[-1999, 1999], clim=[1e0, 1e5], tslice=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89de03e",
   "metadata": {},
   "source": [
    "# *Figure 7: First Set of De-Interleaved Waterfalls after Coherent Time Averaging*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot_waterfall(deint_avg_data[0], bl=(ANTPAIR + ('pI',)), flags=deint_avg_flags[0], nsamples=deint_avg_nsamples[0], tslice=None)\n",
    "    plot_real_delay_vs_lst(deint_avg_data[0], bl=(ANTPAIR + ('pI',)), flags=deint_avg_flags[0], xlim=[-3999, 3999], clim=[-2e2, 2e2], linthresh=1, tslice=None)\n",
    "    plot_dly_vs_fr(deint_avg_data[0], bl=(ANTPAIR + ('pI',)), xlim=[-1999, 1999], clim=[1e0, 1e5], tslice=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652667c",
   "metadata": {},
   "source": [
    "## Prepare for power spectrum estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f07f2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# put results back into HERAData objects for use in hera_pspec (which works with UVData objects)\n",
    "hds = []\n",
    "for avg_data, avg_flags, avg_nsamples in zip(deint_avg_data, deint_avg_flags, deint_avg_nsamples):\n",
    "    avg_hd = copy.deepcopy(hd)\n",
    "    \n",
    "    # select the right number of times and update time and lst arrays\n",
    "    avg_hd.select(times=np.unique(avg_hd.time_array)[:len(avg_data.times)])\n",
    "    for ap in avg_hd.get_antpairs():\n",
    "        blt_slice = avg_hd._blt_slices[ap]\n",
    "        avg_hd.time_array[blt_slice] = avg_data.times\n",
    "        avg_hd.lst_array[blt_slice] = avg_data.lsts\n",
    "\n",
    "    # update polarizations\n",
    "    pstokes_pols = sorted([pol for pol in avg_data.pols() if utils.polstr2num(pol, x_orientation=hd.x_orientation) > 0])\n",
    "    avg_hd.polarization_array = np.array([utils.polstr2num(pol) for pol in pstokes_pols])\n",
    "    avg_hd._determine_pol_indexing()\n",
    "    \n",
    "    avg_data_copy = copy.deepcopy(avg_data)\n",
    "    avg_flags_copy = copy.deepcopy(avg_flags)\n",
    "    avg_nsamples_copy = copy.deepcopy(avg_nsamples)\n",
    "    nonpstokes_pols = [\"ee\", \"nn\", \"ne\", \"en\"]\n",
    "    for ob in [avg_data_copy,avg_flags_copy,avg_nsamples_copy]:\n",
    "        bad_keys = []\n",
    "        for key in ob:\n",
    "            if key[2] in nonpstokes_pols:\n",
    "                bad_keys.append(key)\n",
    "        for key in bad_keys:\n",
    "            del ob[key]\n",
    "    # put data into avg_hd\n",
    "    avg_hd.update(data=avg_data_copy, flags=avg_flags_copy, nsamples=avg_nsamples_copy)\n",
    "\n",
    "    \n",
    "    # add in autocorrelations copies for all antennas for use in noise calculations\n",
    "    auto_aps = [ap for ap in avg_hd.get_antpairs() if ap[0] == ap[1]]\n",
    "    for ant in ANTPAIR:\n",
    "        if (ant, ant) not in auto_aps:\n",
    "            avg_hd_copy = copy.deepcopy(avg_hd)\n",
    "            avg_hd_copy.select(bls=[auto_aps][0])\n",
    "            avg_hd_copy.ant_1_array = np.full_like(avg_hd_copy.ant_1_array, ant)\n",
    "            avg_hd_copy.ant_2_array = np.full_like(avg_hd_copy.ant_2_array, ant)\n",
    "            avg_hd_copy.baseline_array = uvutils.antnums_to_baseline(avg_hd_copy.ant_1_array, avg_hd_copy.ant_2_array, Nants_telescope=avg_hd_copy.Nants_telescope)\n",
    "            avg_hd.fast_concat(avg_hd_copy, 'blt', inplace=True)\n",
    "    \n",
    "    hds.append(avg_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uvbeam file\n",
    "uvb = UVBeam()\n",
    "uvb.read(EFIELD_HEALPIX_BEAM_FILE)\n",
    "uvb.use_future_array_shapes()\n",
    "\n",
    "# convert to pstokes and peak-normalized power beam\n",
    "uvb_ps = uvb.efield_to_pstokes(inplace=False)\n",
    "uvb_ps.peak_normalize()\n",
    "uvb.efield_to_power()\n",
    "uvb.peak_normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9bc7f",
   "metadata": {},
   "source": [
    "## Estimate power spectra for all unique interleaved pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959125d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate power spectrum\n",
    "cosmo = hp.conversions.Cosmo_Conversions()\n",
    "pspecbeam = hp.pspecbeam.PSpecBeamUV(uvb_ps, cosmo=cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942fe2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "band = bands[0]\n",
    "time_in_seconds = (deint_filt_data[0].times - deint_filt_data[0].times.min()) * 60 * 60 * 24  # time array in seconds\n",
    "time_filters = dspec.dpss_operator(time_in_seconds, [np.mean(fr_ranges[band]) / 1000], [np.diff(fr_ranges[band]) / 2 / 1000], eigenval_cutoff=[FR_EIGENVAL_CUTOFF])[0].real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this function should probably be graduated into hera_pspec\n",
    "\n",
    "def dpss_coherent_avg_correction(spw):\n",
    "    '''This function computes an approximate correction to the noise calculation after fringe-rate filtering. It assumes the that number of integrations\n",
    "    that are coherently averaged together is equal the ratio of the number of integrations per interleave divided by the number of FR modes kept. This\n",
    "    is then used to correct the calculation done in hera_pspec, which doesn't know about the FRF. The actual noise power spectrum is reduced by this factor\n",
    "    compared to what naively comes out of hera_pspec. However, when performing incoherent averaging of power spectra, one needs to raise noise power spectrum\n",
    "    by the square-root of this factor to account for the correlations between coherently-averaged power spectrum bins.'''\n",
    "    if SKIP_XTALK_AND_FRF:\n",
    "        coherent_avg_correction_factor = 1.0\n",
    "    else: \n",
    "        band = bands[spw]\n",
    "        time_in_seconds = (deint_filt_data[0].times - deint_filt_data[0].times.min()) * 60 * 60 * 24  # time array in seconds\n",
    "        time_filters = dspec.dpss_operator(time_in_seconds, [np.mean(fr_ranges[band]) / 1000], \n",
    "                                           [np.diff(fr_ranges[band]) / 2 / 1000], eigenval_cutoff=[FR_EIGENVAL_CUTOFF])[0].real\n",
    "\n",
    "        # count the effective number of integrations that go into each coherent average, accounting for overlap with the xtalk filter\n",
    "        if xtalk_overlaps[band] is None:\n",
    "            actual_integrations_per_coherent_avg = time_filters.shape[0] / time_filters.shape[1]  # ratio of total number of DPSS FR modes to modes kept after filtering\n",
    "        else:\n",
    "            overlap_filters = dspec.dpss_operator(time_in_seconds, [np.mean(xtalk_overlaps[band]) / 1000], \n",
    "                                                  [np.diff(xtalk_overlaps[band]) / 2 / 1000], eigenval_cutoff=[FR_EIGENVAL_CUTOFF])[0].real\n",
    "            actual_integrations_per_coherent_avg = time_filters.shape[0] / (time_filters.shape[1]  - overlap_filters.shape[1])\n",
    "        \n",
    "        integrations_per_coherent_avg = int(AVERAGING_TIME // (dt * NINTERLEAVE))\n",
    "        coherent_avg_correction_factor = actual_integrations_per_coherent_avg / integrations_per_coherent_avg\n",
    "    return coherent_avg_correction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12144642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute power spectra for all unique pairs of interleaves\n",
    "uvps = []\n",
    "for ind1, hd1 in enumerate(hds):\n",
    "    for ind2, hd2 in enumerate((hds[ind1:] if INCLUDE_INTERLEAVE_AUTO_PS else hds[ind1 + 1:])):\n",
    "        # Compute power spectrum\n",
    "        ds = hp.PSpecData(dsets=[copy.deepcopy(hd1), copy.deepcopy(hd2)], beam=pspecbeam)\n",
    "        ds.Jy_to_mK()\n",
    "        uvp = ds.pspec([ANTPAIR], [ANTPAIR], dsets=(0, 1), \n",
    "                       pols=[utils.polnum2str(pol) for pol in hd1.polarization_array], \n",
    "                       spw_ranges=[(bs.start, bs.stop) for bs in band_slices],\n",
    "                       taper=TAPER, store_window=STORE_WINDOW_FUNCTIONS, verbose=False)\n",
    "        \n",
    "        # Figure out error bars using autocorrelations\n",
    "        auto_Tsys = hp.utils.uvd_to_Tsys((hd1 + hd2), pspecbeam)\n",
    "        hp.utils.uvp_noise_error(uvp, auto_Tsys, err_type=['P_N'])\n",
    "        \n",
    "        # append to list of power spectra\n",
    "        uvps.append(uvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: graduate this code into hera_pspec\n",
    "\n",
    "# Whether or not to use the correlation matrix to do the noise statistics correction factor\n",
    "USE_CORR_MATRIX = True\n",
    "\n",
    "# Apply coherent_avg_correction_factor and compute P_SN\n",
    "coherent_avg_correction_factors = []\n",
    "for spw, band in enumerate(bands):\n",
    "    if USE_CORR_MATRIX:\n",
    "        # Streams are similar, no need to do this more than once per spw\n",
    "        # Tiny variation over frequency, just average to get one number\n",
    "        coherent_avg_correction_factor = np.mean(get_correction_factor_from_cov(spw, stream_ind=0)\n",
    "    else:\n",
    "        coherent_avg_correction_factor = dpss_coherent_avg_correction(spw)\n",
    "    coherent_avg_correction_factors.append(coherent_avg_correction_factor)\n",
    "    for i, uvp in enumerate(uvps):\n",
    "        # loop over all pols, but only this spw\n",
    "        for key in uvp.get_all_keys():\n",
    "            if key[0] != spw:\n",
    "                continue\n",
    "        \n",
    "            # apply coherent average correction due to integrations not being independent after FRF\n",
    "            P_N = uvp.get_stats('P_N', key) / coherent_avg_correction_factor\n",
    "            uvp.set_stats('P_N', key, P_N)\n",
    "            \n",
    "            # use other interleaves to estimate P_S\n",
    "            P_S = np.mean([uvp2.get_data(key).real for j, uvp2 in enumerate(uvps) if i != j], axis=0)\n",
    "            P_SN = np.sqrt((np.sqrt(2) * np.where(P_S > 0, P_S, 0) * P_N + P_N**2))        \n",
    "            # Apply P_SN Correction for Laplacian statistics\n",
    "            P_SN = (P_SN**2 - .5 / (len(uvps) - 1) * P_N**2)**.5 \n",
    "            P_SN[~np.isfinite(P_SN)] = np.inf\n",
    "            uvp.set_stats('P_SN', key, P_SN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d284b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: graduate this code into hera_pspec\n",
    "\n",
    "# Perform incoherent time average and correct for FRF\n",
    "uvps_time_avg = [uvp.average_spectra(time_avg=True, error_weights='P_N', error_field=['P_N', 'P_SN'], inplace=False) for uvp in uvps]\n",
    "\n",
    "for spw, band in enumerate(bands):\n",
    "    #coherent_avg_correction_factor = dpss_coherent_avg_correction(spw)\n",
    "    coherent_avg_correction_factor = coherent_avg_correction_factors[spw]\n",
    "    for i, uvp in enumerate(uvps_time_avg):   \n",
    "        # loop over all pols, but only this spw\n",
    "        for key in uvp.get_all_keys():\n",
    "            if key[0] != spw:\n",
    "                continue\n",
    "            \n",
    "            # Update P_N and P_SN for incoherent time average\n",
    "            P_N = uvp.get_stats('P_N', key) * (coherent_avg_correction_factor)**.5\n",
    "            uvp.set_stats('P_N', key, P_N)\n",
    "            P_SN = uvp.get_stats('P_SN', key) * (coherent_avg_correction_factor)**.5\n",
    "            uvp.set_stats('P_SN', key, P_SN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a65bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform incoherent time-averaging across interleaves\n",
    "uvp_interleave = reduce(lambda x, y: x + y, uvps_time_avg)\n",
    "uvp_avg_all = uvp_interleave.average_spectra(time_avg=True, error_weights='P_N', error_field=['P_N', 'P_SN'], inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f13dfe",
   "metadata": {},
   "source": [
    "## Power Spectrum Plotting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3070425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average all interleaved LSTs together for plotting\n",
    "all_lsts = []\n",
    "for uvp in uvps:\n",
    "    if np.mean(np.unwrap(uvp.lst_avg_array)) - np.mean(np.unwrap(uvps[0].lst_avg_array)) > np.pi:\n",
    "        all_lsts.append(np.unwrap(uvp.lst_avg_array) - 2 * np.pi)\n",
    "    elif np.mean(np.unwrap(uvp.lst_avg_array)) - np.mean(np.unwrap(uvps[0].lst_avg_array)) < -np.pi:        \n",
    "        all_lsts.append(np.unwrap(uvp.lst_avg_array) + 2 * np.pi)\n",
    "    else:\n",
    "        all_lsts.append(np.unwrap(uvp.lst_avg_array))\n",
    "avg_pspec_lsts = (np.mean(all_lsts, axis=0) % (2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d280ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SNRs for plotting\n",
    "SNRs = []\n",
    "tavg_SNRs = []\n",
    "for spw, band in enumerate(bands):\n",
    "    key = (spw, (ANTPAIR, ANTPAIR), ('pI', 'pI')) \n",
    "    for i, uvp in enumerate(uvps):\n",
    "        high_dlys = np.abs(uvp.get_dlys(key[0]) * 1e9) > 1000\n",
    "        SNRs.append(np.ravel((uvp.get_data(key) / uvp.get_stats('P_N', key).real)[:, high_dlys]))\n",
    "        #print((uvp.get_data(key) / uvp.get_stats('P_N', key).real)[:, high_dlys].shape)\n",
    "    for i, uvp in enumerate(uvps_time_avg):\n",
    "        high_dlys = np.abs(uvp.get_dlys(key[0]) * 1e9) > 1000\n",
    "        tavg_SNRs.append(np.ravel((uvp.get_data(key) / uvp.get_stats('P_N', key).real)[:, high_dlys]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Pk_vs_LST(clim=None, xlim=[-2999, 2999], pol='pI'):\n",
    "    '''Plots the real part of the power spectrum from each band as a function of LST and delay for each band.'''\n",
    "    \n",
    "    lsts = np.where(avg_pspec_lsts > avg_pspec_lsts[-1], avg_pspec_lsts - 2 * np.pi, avg_pspec_lsts) * 12 / np.pi\n",
    "    fig, axes = plt.subplots(1, len(bands), figsize=(28, 12), sharex=True, sharey=True, gridspec_kw={'wspace': .03}, dpi=100)\n",
    "    for spw, (ax, band, band_slice) in enumerate(zip(axes, bands, band_slices)):\n",
    "\n",
    "        key = (spw, (ANTPAIR, ANTPAIR), (pol, pol))  \n",
    "        pk_avg = np.mean([uvp.get_data(key) for uvp in uvps], axis=0).real\n",
    "        delays = uvps[0].get_dlys(key[0]) * 1e9\n",
    "\n",
    "        if spw == 0:\n",
    "            _to_plot = copy.deepcopy(np.where(np.isfinite(pk_avg), pk_avg, np.nan))\n",
    "            _to_plot = np.where(_to_plot == 0, np.nan, _to_plot)\n",
    "        im = ax.imshow(np.abs(np.where(np.isfinite(pk_avg), pk_avg, np.nan)), \n",
    "                       interpolation='none', aspect='auto', cmap='inferno', \n",
    "                       norm=matplotlib.colors.LogNorm(vmin=(clim[0] if clim is not None else np.nanmin(np.abs(_to_plot))), \n",
    "                                                      vmax=(clim[1] if clim is not None else np.nanmax(np.abs(_to_plot)))),\n",
    "                       extent=[delays[0], delays[-1], lsts[-1], lsts[0]])\n",
    "\n",
    "        for multiple in [1, -1]:\n",
    "            ax.axvline(multiple * dly_filter_half_widths[0] * 1e9, ls='--', color='k')\n",
    "            ax.axvline(multiple * inpaint_filter_half_widths[0] * 1e9, ls=':', color='k')\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_title(f'Band {spw+1}:\\n{band[0]}—{band[1]} MHz', fontsize=10)\n",
    "        ax.set_xlabel('Delay (ns)')\n",
    "        if spw == 0:\n",
    "            ax.set_ylabel('LST (Hours)')\n",
    "            ax.set_yticklabels([f'{(int(val) if np.isclose(val, int(val)) else val) % 24}' for val in ax.get_yticks()])\n",
    "\n",
    "    plt.colorbar(im, ax=axes, pad=.02, aspect=40, extend='both', label=f'{pol} ' + r'|Re[$P(k)$]| (mK$^2$ $h^{-3}$ Mpc$^3$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Pk_SNR_vs_LST(clim=[-5, 5], xlim = [-2999, 2999], func=np.real):\n",
    "    '''Plots the real power spectrum SNR (normalized by P_N, not P_SN) as a function of LST and delay for each band.'''\n",
    "    \n",
    "    lsts = np.where(data.lsts[tslice] > data.lsts[tslice][-1], data.lsts[tslice] - 2 * np.pi, data.lsts[tslice]) * 12 / np.pi\n",
    "    fig, axes = plt.subplots(1, len(bands), figsize=(28, 12), sharex=True, sharey=True, gridspec_kw={'wspace': .03}, dpi=100)\n",
    "    for spw, (ax, band, band_slice) in enumerate(zip(axes, bands, band_slices)):\n",
    "\n",
    "        key = (spw, (ANTPAIR, ANTPAIR), ('pI', 'pI'))  \n",
    "        pk_avg = func(np.mean([uvp.get_data(key) for uvp in uvps], axis=0))\n",
    "        delays = uvps[0].get_dlys(key[0]) * 1e9\n",
    "        P_N = np.mean([np.abs(uvp.get_stats('P_N', key)) for uvp in uvps], axis=0)\n",
    "\n",
    "        SNR = pk_avg / (P_N / np.sqrt(len(uvps)))\n",
    "\n",
    "        im = ax.imshow(SNR, interpolation='none', aspect='auto', cmap='bwr', \n",
    "                       vmin=clim[0], vmax=clim[1],\n",
    "                       extent=[delays[0], delays[-1], lsts[-1], lsts[0]])\n",
    "        for multiple in [1, -1]:\n",
    "            ax.axvline(multiple * dly_filter_half_widths[0] * 1e9, ls='--', color='k')\n",
    "            ax.axvline(multiple * inpaint_filter_half_widths[0] * 1e9, ls=':', color='k')\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_title(f'Band {spw+1}:\\n{band[0]}—{band[1]} MHz', fontsize=10)\n",
    "        ax.set_xlabel('Delay (ns)')\n",
    "        if spw == 0:\n",
    "            ax.set_ylabel('LST (Hours)')\n",
    "            ax.set_yticklabels([f'{(int(val) if np.isclose(val, int(val)) else val) % 24}' for val in ax.get_yticks()])\n",
    "\n",
    "    plt.colorbar(im, ax=axes, pad=.02, aspect=40, extend='both', label=f'{\"Re\" if func == np.real else \"Im\"}' + r'[$P(k) / P_N(k)$] (unitless)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83715ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_SNR_hist(to_hist, theory='laplace', leg_title='All Bands, $|\\\\tau| > 1000$ ns', bins=None,\n",
    "                  denom_label='$P_N$'):\n",
    "    '''Plots the histogram of power spectrum SNR values (both real and imaginary) and compares them to a theoretical distribution.'''\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    if bins is None:\n",
    "        bins = np.linspace(-15,15,200)        \n",
    "\n",
    "    for ax, func, c in zip(axes, [np.real, np.imag], ['C0', 'C1']):\n",
    "        ax.hist(func(to_hist), bins=bins, density=True, color=c, edgecolor='k', linewidth=.1, \n",
    "                label=f'{\"Re\" if func == np.real else \"Im\"}[$P(k)$] / {denom_label}')\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "        if theory == 'laplace':\n",
    "            b = 2**-.5\n",
    "            laplace = np.exp(-np.abs(bins) / b) / 2 / b\n",
    "            ax.plot(bins, laplace, 'k--', label='Laplace Distribution')\n",
    "        elif theory == 'gauss':\n",
    "            gauss = np.exp(-bins**2/2) / np.sqrt(2*np.pi)\n",
    "            ax.plot(bins, gauss, 'k--', label='Gaussian Distribution')\n",
    "\n",
    "        ax.legend(title=leg_title)\n",
    "        ax.set_xlabel('SNR')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_ylim([10**np.floor(np.log10(1 / len(to_hist))), 1])\n",
    "\n",
    "        text = f'Observed Mean: {np.nanmean(func(to_hist)).real:.3f}'\n",
    "        text += f'\\nObserved Median: {np.nanmedian(func(to_hist)).real:.3f}'\n",
    "        if theory == 'laplace':\n",
    "            text += f'\\nObserved/Expected Std: {np.nanstd(func(to_hist)) / 2**.5 / b:.3f}'\n",
    "            text += f'\\nObserved/Expected MAD: {np.median(np.abs(func(to_hist) - np.median(func(to_hist)))) / b / np.log(2):.3f}'\n",
    "        elif theory == 'gauss':\n",
    "            text += f'\\nObserved/Expected Std: {np.nanstd(func(to_hist)):.3f}'\n",
    "            text += f'\\nObserved/Expected MAD: {np.median(np.abs(func(to_hist) - np.median(func(to_hist)))) / (2**.5 * special.erfinv(.5)):.3f}'\n",
    "\n",
    "        ax.set_title(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tavg_pspec():\n",
    "    '''This plots the time-averaged power spectrum over the whole range of LSTs, including 2 sigma errors'''\n",
    "    \n",
    "    fig, axes = plt.subplots(int(np.ceil(len(bands) / 2)), 2, figsize=(18, 12), sharex=True, sharey=True, gridspec_kw={'wspace': .03, 'hspace': .0}, dpi=100)\n",
    "    for spw, (ax, band, band_slice) in enumerate(zip(np.ravel(axes), bands, band_slices)):\n",
    "\n",
    "        key = (spw, (ANTPAIR, ANTPAIR), ('pI', 'pI'))\n",
    "\n",
    "        pk_avg = np.squeeze(uvp_avg_all.get_data(key).real)\n",
    "        delays = uvp_avg_all.get_dlys(key[0]) * 1e9\n",
    "        P_N = np.squeeze(uvp_avg_all.get_stats('P_N', key))\n",
    "        P_SN = np.squeeze(uvp_avg_all.get_stats('P_SN', key))        \n",
    "        ax.errorbar(delays, pk_avg, marker='o', ls='', yerr=2*P_SN, label='$Re[P(k)]$ with 2$\\sigma$ $P_{SN}$ errors')\n",
    "        ax.plot(delays, P_N, 'k--', label='$P_{N}$')\n",
    "        ax.plot(delays, P_SN, 'k-', label='$P_{SN}$')\n",
    "        ax.set_yscale('log')    \n",
    "        ax.set_xlim([-2500, 2500])\n",
    "        ax.set_ylim([1e3, 1e14])\n",
    "        ax.set_xlabel('Delay (ns)')\n",
    "        ax.tick_params(axis='x', direction='in')\n",
    "        for multiple in [1, -1]:\n",
    "            ax.axvline(multiple * dly_filter_half_widths[0] * 1e9, ls='--', color='k', lw=.5, label=(r'Filtering $\\tau_{max}$' if multiple == 1 else None))\n",
    "            ax.axvline(multiple * inpaint_filter_half_widths[0] * 1e9, ls=':', color='k', lw=.5, label=(r'Inpainting $\\tau_{max}$' if multiple == 1 else None))\n",
    "        if spw % 2 == 0:\n",
    "            ax.set_ylabel('Re[$P(k)$]\\n(mK$^2$ $h^{-3}$ Mpc$^3$)')    \n",
    "\n",
    "        ax.text(.02, .93, f'Band {spw + 1}:\\n{band[0]}—{band[1]} MHz', transform=ax.transAxes, fontsize=12,\n",
    "                va='top', ha='left', bbox=dict(boxstyle='round', facecolor='w', alpha=0.8))\n",
    "    \n",
    "    handles, labels = axes[-1, -1].get_legend_handles_labels()    \n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, .92), ncol=len(labels))\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ab9c3c",
   "metadata": {},
   "source": [
    "# *Figure 8: Interleave-Averaged Power Spectra (Pseudo-Stokes I, Q, U, & V) vs. LST*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Pk_vs_LST(pol='pI')\n",
    "plot_Pk_vs_LST(pol='pQ')\n",
    "plot_Pk_vs_LST(pol='pU')\n",
    "plot_Pk_vs_LST(pol='pV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb558c",
   "metadata": {},
   "source": [
    "# *Figure 9: Interleave-Averaged Power Spectrum SNR vs. LST (Real and Imaginary for pI)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93240fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Pk_SNR_vs_LST(func=np.real)\n",
    "plot_Pk_SNR_vs_LST(func=np.imag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638078a7",
   "metadata": {},
   "source": [
    "# *Figure 10: High Delay Power Spectrum SNR Histograms Before and After Incoherent Averaging*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb8bba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_SNR_hist(np.array([snr for interleave_band in SNRs for snr in interleave_band]), theory='laplace')\n",
    "plot_SNR_hist(np.array([snr for interleave_band in tavg_SNRs for snr in interleave_band]), theory='gauss', bins=np.linspace(-10,10,100),\n",
    "              leg_title='All Bands, Time-Averaged,\\n$|\\\\tau| > 1000$ ns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97725a",
   "metadata": {},
   "source": [
    "# *Figure 11: Incoherently Averaged Power Spectrum with Error Bars*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ace6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tavg_pspec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9297e18-eacf-4624-ab3c-809b89504956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:43:58.332071Z",
     "iopub.status.busy": "2024-02-12T19:43:58.330858Z",
     "iopub.status.idle": "2024-02-12T19:43:58.340649Z",
     "shell.execute_reply": "2024-02-12T19:43:58.338846Z",
     "shell.execute_reply.started": "2024-02-12T19:43:58.332014Z"
    }
   },
   "source": [
    "## Average Over Interleaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559f5ef-4998-4d0f-bf1f-c9cf69377614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_add_pspec(objects):\n",
    "    '''Method for faster combination of UVPSpec objects.'''\n",
    "    if len(objects) == 0:\n",
    "        raise ValueError('Cannot run recursive_add on length-0 objects.')\n",
    "    if len(objects) == 1:\n",
    "        # Base case: only one object left, return it\n",
    "        return objects[0]\n",
    "    elif len(objects) == 2:\n",
    "        # Base case: two objects, add them together\n",
    "        return hp.uvpspec.combine_uvpspec(objects, merge_history=False, verbose=False)\n",
    "    else:\n",
    "        # Recursive case: split the list in half and add each half\n",
    "        midpoint = len(objects) // 2\n",
    "        left_sum = recursive_add_pspec(objects[:midpoint])\n",
    "        right_sum = recursive_add_pspec(objects[midpoint:])\n",
    "        return hp.uvpspec.combine_uvpspec([left_sum, right_sum], merge_history=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d383559-4ffc-48e1-b890-77c4fbc1ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all interleaves into UVPSpec object\n",
    "interleaved_uvp = recursive_add_pspec(uvps)\n",
    "\n",
    "# select each individual time and average interleaves together incoherently\n",
    "to_recombine = []\n",
    "for times in interleaved_uvp.time_avg_array.reshape(-1, len(uvps)):\n",
    "    to_recombine.append(interleaved_uvp.select(times=times, inplace=False))\n",
    "    to_recombine[-1].average_spectra(time_avg=True, error_weights='P_N', error_field=['P_N', 'P_SN'])\n",
    "\n",
    "# combine all single-integration UVPSpec objects\n",
    "interleaved_uvp = recursive_add_pspec(to_recombine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef3628",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_RESULTS:\n",
    "    # Create pspec container and write all interleaves to it\n",
    "    psc = hp.PSpecContainer(OUT_PSPEC_FILE, mode='rw', keep_open=False)\n",
    "    psc.set_pspec('stokespol', 'interleave_averaged', interleaved_uvp, overwrite=True)\n",
    "\n",
    "    # write ancillary data products directly to header attributes\n",
    "    with h5py.File(OUT_PSPEC_FILE, 'r+') as f:\n",
    "        f['header'].attrs['dpss_coherent_avg_corrections'] = [dpss_coherent_avg_correction(spw) for spw in range(len(bands))]\n",
    "        f['header'].attrs['frf_losses'] = [frf_losses[band] for band in bands]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdff354",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a61c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['numpy', 'scipy', 'astropy', 'hera_cal', 'hera_qm', 'hera_filters', 'hera_pspec', 'hera_notebook_templates', 'pyuvdata']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b00b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3872206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003ca93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canary",
   "language": "python",
   "name": "canary"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

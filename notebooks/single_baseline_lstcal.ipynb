{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9118075-181e-4d79-ba39-c443c27bf56a",
   "metadata": {},
   "source": [
    "# Single Baseline LST-binned Calibration Notebook\n",
    "\n",
    "**by Tyler Cox**, last updated on Aug 25th, 2025\n",
    "\n",
    "This notebook performs LST-binned Calibration on single-baseline files. Here, we select a subset of baselines per night to keep the total memory footprint of the notebook within the memory requested by a given process, then compute the redundant-calibration degenerate parameters that bring a single night into better alignment with the LST-average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c4381-70cb-4340-acaf-a1c0a5094130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu') # Force jax to use CPU if GPU available\n",
    "\n",
    "import re\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import glob\n",
    "import toml\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pyuvdata import UVData\n",
    "from hera_cal.lst_stack import LSTConfig\n",
    "from hera_cal import lst_stack, io, flag_utils, abscal, datacontainer, redcal, utils, smooth_cal, red_groups\n",
    "from hera_qm.time_series_metrics import true_stretches\n",
    "from hera_filters.dspec import fourier_filter, dpss_operator\n",
    "from hera_cal.lst_stack.calibration import _expand_degeneracies_to_ant_gains\n",
    "from hera_cal.lst_stack.config import LSTBinConfiguratorSingleBaseline, make_lst_grid\n",
    "from hera_cal.lst_stack.binning import SingleBaselineStacker, _get_freqs_chans, adjust_lst_bin_edges, _allocate_dfn, get_lst_bins\n",
    "\n",
    "from hera_qm.metrics_io import read_a_priori_ant_flags\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"hera_cal\")\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc57a03-7f15-4d3c-b7f5-9d4c2c13763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_file = os.environ.get(\n",
    "    'TOML_FILE', '/lustre/aoc/projects/hera/tcox/Software/hera_pipelines/pipelines/h6c/idr3/v1/lstbin/single_bl_lst_stack.toml'\n",
    ")\n",
    "print(f'toml_file = \"{toml_file}\"')\n",
    "\n",
    "baseline_string = os.environ.get('BASELINE_STRING', \"0_4\")\n",
    "print(f'baseline_string = \"{baseline_string}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7644b04-7e83-48e7-adf2-90c75fc2ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get options from toml file, print them out, and update globals\n",
    "toml_options = toml.load(toml_file)\n",
    "\n",
    "print(f\"Now setting the following global variables from {toml_file}:\\n\")\n",
    "\n",
    "globals().update({'lst_branch_cut': toml_options['FILE_CFG']['lst_branch_cut']})\n",
    "print(f\"lst_branch_cut = {lst_branch_cut}\")\n",
    "\n",
    "globals().update({'where_inpainted_file_rules': toml_options['FILE_CFG']['where_inpainted_file_rules']})\n",
    "print(f\"where_inpainted_file_rules = {where_inpainted_file_rules}\")\n",
    "\n",
    "# this is used for an initial stacking of a handful of baselines, which are then used for LSTCal\n",
    "toml_options['LST_STACK_OPTS']['FNAME_FORMAT'] = toml_options['LST_STACK_OPTS']['FNAME_FORMAT'].replace('.sum.uvh5', '.preliminary.sum.uvh5')\n",
    "\n",
    "for key, val in toml_options['LSTCAL_OPTS'].items():\n",
    "    if isinstance(val, str):\n",
    "        print(f'{key} = \"{val}\"')\n",
    "    else:\n",
    "        print(f'{key} = {val}')\n",
    "globals().update(toml_options['LSTCAL_OPTS'])\n",
    "        \n",
    "for key, val in toml_options['LST_STACK_OPTS'].items():\n",
    "    if isinstance(val, str):\n",
    "        print(f'{key} = \"{val}\"')\n",
    "    else:\n",
    "        print(f'{key} = {val}')\n",
    "globals().update(toml_options['LST_STACK_OPTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22dfb3-c538-4118-af40-88eaf087c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline configurator\n",
    "configurator = lst_stack.config.LSTBinConfiguratorSingleBaseline.from_toml(toml_file)\n",
    "auto_baseline_string = [s for s in configurator.bl_to_file_map if (p := s.split('_'))[0] == p[1]][0]\n",
    "\n",
    "# Get metadata for LST-stacking\n",
    "hd = io.HERAData(\n",
    "    configurator.bl_to_file_map[baseline_string][-1]\n",
    ")\n",
    "df = np.median(np.diff(hd.freqs))\n",
    "dlst = np.median(np.diff(hd.lsts))\n",
    "lst_grid = lst_stack.config.make_lst_grid(dlst, begin_lst=0, lst_width=(2 * np.pi)) # _fix_dlst function making the grid the wrong size\n",
    "lst_bin_edges =  np.concatenate([lst_grid - dlst / 2, (lst_grid[-1] + dlst / 2)[None]])\n",
    "\n",
    "# Julian dates for LST-calibration\n",
    "jds = [int(night) for night in configurator.nights]\n",
    "filepath = toml_options['FILE_CFG']['datafiles']['datadir']\n",
    "aposteriori_yamls = {jd: filepath + f'/{jd}/{jd}_aposteriori_flags.yaml' for jd in jds}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba176262-78e2-48ae-9dbd-4d06a5520eb7",
   "metadata": {},
   "source": [
    "# 1. Load Single Night Data and Rephase to Correct LST-bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7317c6-cb9d-48c8-8d3e-aaeffe358217",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bl_strings = sorted(list(configurator.bl_to_file_map.keys()))\n",
    "\n",
    "bl_string_to_jd_map = {\n",
    "    bl_string: night\n",
    "    for night, bl_string in zip(sorted(configurator.nights), all_bl_strings)\n",
    "}\n",
    "\n",
    "#HERE_OUTDIR = \"/lustre/aoc/projects/hera/tcox/LST_AVG_FILE_CACHE/*uvh5\"\n",
    "# Get baseline keys from the files that have been previously saved by the stacking notebook\n",
    "single_bl_files = glob.glob(\n",
    "    os.path.join(OUTDIR, FNAME_FORMAT.format(bl_str=\"*\"))\n",
    "    # HERE_OUTDIR\n",
    ")\n",
    "\n",
    "baselines = []\n",
    "baseline_strings = []\n",
    "for file in single_bl_files:\n",
    "    match = re.search(\n",
    "        r'baseline\\.(\\d+)_(\\d+)\\.sum\\.uvh5', \n",
    "        file\n",
    "    )\n",
    "    i, j = map(int, match.groups())\n",
    "    baselines.append((i, j))\n",
    "    baseline_strings.append(\"{}_{}\".format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a911e43-7d3a-45fe-97b3-b8614c7b3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the JD for this particular file\n",
    "# baseline_string = \"0_11\" # TODO: remove this later\n",
    "RUN_CALIBRATION = baseline_string in bl_string_to_jd_map\n",
    "\n",
    "if RUN_CALIBRATION:\n",
    "    jd_here = bl_string_to_jd_map[baseline_string]\n",
    "    \n",
    "    # Now load good baselines for a single day\n",
    "    single_day_config = deepcopy(configurator)\n",
    "    single_day_config.nights = [str(jd_here)]\n",
    "    single_day_config.bl_to_file_map = single_day_config.build_bl_to_file_map()\n",
    "    \n",
    "    # Set up dictionaries to store \n",
    "    data_for_cal = {}\n",
    "    wgts = {}\n",
    "    model = {}\n",
    "    where_inpainted = {}\n",
    "    all_flagged = {}\n",
    "    \n",
    "    if RUN_CROSS_POL_PHASE_CAL:\n",
    "        cross_pol_model = {}\n",
    "        cross_pol_data = {}\n",
    "    \n",
    "    # Loop through baseline strings\n",
    "    for bl_string in tqdm(baseline_strings):\n",
    "        crosses = SingleBaselineStacker.from_configurator(\n",
    "            single_day_config,\n",
    "            bl_string,\n",
    "            lst_bin_edges,\n",
    "            lst_branch_cut=lst_branch_cut, \n",
    "            where_inpainted_file_rules=where_inpainted_file_rules\n",
    "        )\n",
    "    \n",
    "        # Get antennas that make up the baseline\n",
    "        ai, aj = list(map(int, bl_string.split('_')))\n",
    "    \n",
    "        # Load the corresponding LST-binned baseline\n",
    "        bl_to_load = os.path.join(OUTDIR, FNAME_FORMAT.format(bl_str=bl_string))\n",
    "        # bl_to_load = f\"/lustre/aoc/projects/hera/tcox/LST_AVG_FILE_CACHE/zen.LST.baseline.{bl_string}.sum.uvh5\"\n",
    "        \n",
    "        polarizations = crosses.hd.pols if RUN_CROSS_POL_PHASE_CAL else crosses.hd.pols[:2]\n",
    "        hd = io.HERAData(bl_to_load)\n",
    "        single_bl_stacked_data, lst_avg_flags, _ = hd.read(polarizations=polarizations)\n",
    "    \n",
    "        # Match lst-averaged to data and handle precision loss from converting to times to LSTs\n",
    "        lst_grid = hd.lsts.copy()\n",
    "        lst_grid[lst_grid[0] > lst_grid] += 2 * np.pi\n",
    "        lst_grid_rounding_factor = np.abs(np.floor(np.log10(dlst) - 2)).astype(int)\n",
    "        indices = np.searchsorted(\n",
    "            np.round(lst_grid, lst_grid_rounding_factor), \n",
    "            np.round(crosses.bin_lst, lst_grid_rounding_factor)\n",
    "        )\n",
    "    \n",
    "        \n",
    "        for pi, pol in enumerate(polarizations):\n",
    "            # Set the weights\n",
    "            nsamples = np.concatenate([_nsamples[..., pi] for _nsamples in crosses.nsamples], axis=0)\n",
    "            flags = np.concatenate([_flags[..., pi] for _flags in crosses.flags], axis=0)\n",
    "            model_flags = np.concatenate([\n",
    "                np.repeat(lst_avg_flags[(ai, aj, pol)][[idx]], len(tinb), axis=0)\n",
    "                for idx, tinb in zip(indices, crosses.times_in_bins)\n",
    "            ], axis=0)\n",
    "            flags |= model_flags\n",
    "            \n",
    "            wgts[(ai, aj, pol)] = nsamples * (~flags).astype(float)\n",
    "            \n",
    "            if pol in flags:\n",
    "                all_flagged[pol] &= flags\n",
    "            else:\n",
    "                all_flagged[pol] = flags\n",
    "    \n",
    "            if pol in where_inpainted:\n",
    "                where_inpainted[pol] &= np.concatenate([winp[..., pi] for winp in crosses.where_inpainted], axis=0)\n",
    "            else:\n",
    "                where_inpainted[pol] = np.concatenate([winp[..., pi] for winp in crosses.where_inpainted], axis=0)\n",
    "            \n",
    "            if pol[0] == pol[1]:\n",
    "                data_for_cal[(ai, aj, pol)] = np.concatenate([_data[..., pi] for _data in crosses.data], axis=0)\n",
    "                model[(ai, aj, pol)] = np.concatenate([\n",
    "                    single_bl_stacked_data[(ai, aj, pol)][[idx]] * np.ones((len(tinb), 1))\n",
    "                    for idx, tinb in zip(indices, crosses.times_in_bins)\n",
    "                ], axis=0)\n",
    "            else:\n",
    "                cross_pol_data[(ai, aj, pol)] = np.concatenate([_data[..., pi] for _data in crosses.data], axis=0)\n",
    "                cross_pol_model[(ai, aj, pol)] = np.concatenate([\n",
    "                    single_bl_stacked_data[(ai, aj, pol)][[idx]] * np.ones((len(tinb), 1))\n",
    "                    for idx, tinb in zip(indices, crosses.times_in_bins)\n",
    "                ], axis=0)\n",
    "    \n",
    "            \n",
    "    \n",
    "    # Get the frequencies and times of the data\n",
    "    freqs = crosses.hd.freqs\n",
    "    times = np.concatenate(crosses.times_in_bins)\n",
    "\n",
    "    # Get the original time grid\n",
    "    single_jd_hd = io.HERAData(single_day_config.bl_to_file_map[bl_string])\n",
    "    single_jd_times = single_jd_hd.times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db07a485-18d8-48a3-91e6-4e6705ddff00",
   "metadata": {},
   "source": [
    "# 3. Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837e04a-7083-4e44-90df-65a46f242942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_phase_abscal(data, model, reds, data_bls, model_bls, transformed_antpos=None, newton_maxiter=50):\n",
    "    \"\"\"\n",
    "    Stripped down version of hera_cal.abscal.complex_phase_abscal that assumes the tip-tilt solution is close to zero. \n",
    "    Calculates gains that would absolute calibrate the phase of already redundantly-calibrated data. \n",
    "    Only operates one polarization at a time.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : DataContainer or RedDataContainer\n",
    "        Dictionary-like container mapping baselines to data visibilities to abscal\n",
    "    model : DataContainer or RedDataContainer\n",
    "        Dictionary-like container mapping baselines to model visibilities\n",
    "    reds : list of lists\n",
    "        List of lists of redundant baselines tuples like (0, 1, 'ee'). Ignored if transformed_antpos is not None.\n",
    "    data_bls : list of tuples\n",
    "        List of baseline tuples in data to use.\n",
    "    model_bls : list of tuples\n",
    "        List of baseline tuples in model to use. Must correspond the same physical separations as data_bls.\n",
    "    transformed_antpos : dict\n",
    "        Dictionary of abstracted antenna positions that you'd normally get from redcal.reds_to_antpos().\n",
    "        If None, will be inferred from reds.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    meta : dictionary\n",
    "        Contains keys for\n",
    "            'Lambda_sol' : phase gradient solutions,\n",
    "            'Z_sol' : value of the objective function at the solution,\n",
    "            'newton_iterations' : number of iterations completed by the Newton's method solver\n",
    "    delta_gains : dictionary\n",
    "        Dictionary mapping antenna keys like (0, 'Jee') to gains of the same shape of the data\n",
    "    \"\"\"\n",
    "    # Check that baselines selected are for the same polarization\n",
    "    pols = list(set([bl[2] for bls in (data_bls, model_bls) for bl in bls]))\n",
    "    assert len(pols) == 1, 'complex_phase_abscal() can only solve for one polarization at a time.'\n",
    "\n",
    "    # Get transformed antenna positions and baselines\n",
    "    if transformed_antpos is None:\n",
    "        transformed_antpos = redcal.reds_to_antpos(reds)\n",
    "    abscal._put_transformed_array_on_integer_grid(transformed_antpos)\n",
    "    transformed_b_vecs = np.rint([transformed_antpos[jj] - transformed_antpos[ii] for (ii, jj, pol) in data_bls]).astype(int)\n",
    "\n",
    "    # Get number of baselines and times/freqs\n",
    "    Ngroups = len(data_bls)\n",
    "    Ntimes, Nfreqs = data[data_bls[0]].shape\n",
    "\n",
    "    # Build up array of Fourier coefficients of the objective function\n",
    "    Z_coefficients = np.zeros((Ntimes, Nfreqs, Ngroups), dtype=complex)\n",
    "    for nn in range(Ngroups):\n",
    "\n",
    "        Vhat_n = data[data_bls[nn]]\n",
    "        Vbar_n = model[model_bls[nn]]\n",
    "        Z_coefficients[:, :, nn] = Vhat_n * np.conj(Vbar_n)\n",
    "\n",
    "    # Get solution for degenerate phase gradient vectors\n",
    "    Ntimes, Nfreqs, Ngroups = Z_coefficients.shape\n",
    "    Ndims = transformed_b_vecs.shape[1]\n",
    "\n",
    "    Lambda_sol = np.zeros((Ntimes, Nfreqs, Ndims), dtype=float)\n",
    "\n",
    "    for i_t in range(Ntimes):\n",
    "        for i_f in range(Nfreqs):\n",
    "            Z_coeffs_t_f = Z_coefficients[i_t, i_f]\n",
    "            Lambda_t_f, niter_t_f = abscal._newton_solve(np.zeros(Ndims), transformed_b_vecs, Z_coeffs_t_f, 1e-8, maxiter=newton_maxiter)\n",
    "            Lambda_sol[i_t, i_f] = -Lambda_t_f\n",
    "        \n",
    "    # turn solution into per-antenna gains\n",
    "    meta = {\n",
    "        'Lambda_sol': Lambda_sol, \n",
    "        'transformed_antpos': transformed_antpos\n",
    "    }\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c0847-0e24-48ae-a62b-adace2b549d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_CALIBRATION:\n",
    "    # Amplitude Calibration\n",
    "    if RUN_AMPLITUDE_CAL:\n",
    "        amplitude_solutions = abscal.abs_amp_lincal(\n",
    "            model=model,\n",
    "            data=data_for_cal,\n",
    "            wgts=wgts,\n",
    "            verbose=False,\n",
    "        )\n",
    "    else:\n",
    "        data_shape = data_for_cal[list(data_for_cal.keys())[0]].shape\n",
    "        # TODO: More robust\n",
    "        amplitude_solutions['ee'] = np.ones(data_shape)\n",
    "        amplitude_solutions['nn'] = np.ones(data_shape)\n",
    "    \n",
    "    # Tip-tilt Phase Calibration\n",
    "    if RUN_TIP_TILT_PHASE_CAL:\n",
    "        # Get the redundancies\n",
    "        all_reds = red_groups.RedundantGroups.from_antpos(\n",
    "            antpos=hd.antpos, \n",
    "            pols=('nn', 'ee'), \n",
    "            include_autos=False\n",
    "        )\n",
    "    \n",
    "        # Fit the tip-tilt for both pols\n",
    "        phase_solutions = {}\n",
    "        for pol in ['ee', 'nn']:\n",
    "            phase_fit = complex_phase_abscal(\n",
    "                {k: data_for_cal[k][:] for k in data_for_cal if k[-1] == pol}, \n",
    "                {k: model[k][:] for k in model if k[-1] == pol}, \n",
    "                all_reds, \n",
    "                [k for k in data_for_cal if k[-1] == pol], \n",
    "                [k for k in model if k[-1] == pol], \n",
    "            )\n",
    "            phase_solutions[pol] = phase_fit['Lambda_sol']\n",
    "    \n",
    "        transformed_antpos = phase_fit['transformed_antpos']   \n",
    "    else:\n",
    "        data_shape = data_for_cal[list(data_for_cal.keys())[0]].shape\n",
    "        phase_solutions = {}\n",
    "        for pol in ['ee', 'nn']:\n",
    "            phase_fit = np.zeros(data_shape + (2,))\n",
    "            phase_solutions[pol] = phase_fit\n",
    "    \n",
    "        transformed_antpos = hd.antpos\n",
    "        \n",
    "    if RUN_CROSS_POL_PHASE_CAL:\n",
    "        cross_pol_phase = abscal.cross_pol_phase_cal(\n",
    "            model=cross_pol_model,\n",
    "            data=cross_pol_data,\n",
    "            model_bls=list(cross_pol_model.keys()),\n",
    "            data_bls=list(cross_pol_data.keys()),\n",
    "            wgts=wgts,\n",
    "        )\n",
    "    else:\n",
    "        data_shape = data_for_cal[list(data_for_cal.keys())[0]].shape\n",
    "        cross_pol_phase = np.zeros(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1edb474-6514-4b11-b033-e0a6a0bf15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    # Check blacklisting in amplitude calibration (harder to do in phase)\n",
    "    blacklist_wgts = {}\n",
    "    \n",
    "    avg_wgts = {\n",
    "        pol: np.mean([wgts[key] for key in wgts if pol in key], axis=0)\n",
    "        for pol in polarizations\n",
    "    }\n",
    "    \n",
    "    for pol in ['ee', 'nn']:\n",
    "        if RUN_AMPLITUDE_CAL:\n",
    "            gains = np.where(\n",
    "                np.isfinite(amplitude_solutions[f\"A_J{pol}\"]), \n",
    "                amplitude_solutions[f\"A_J{pol}\"], \n",
    "                1.0\n",
    "            )\n",
    "            wgts_here = np.where(np.isfinite(amplitude_solutions[f\"A_J{pol}\"]), avg_wgts[pol], 0.0)\n",
    "            wgts_here = np.where(where_inpainted[pol], WHERE_INPAINTED_WGTS, wgts_here)\n",
    "            smoothed_amp, _ = smooth_cal.time_freq_2D_filter(\n",
    "                gains=gains.astype(complex),\n",
    "                wgts=wgts_here,\n",
    "                freqs=freqs,\n",
    "                times=times,\n",
    "                freq_scale=FREQ_SMOOTHING_SCALE,\n",
    "                time_scale=TIME_SMOOTHING_SCALE * BLACKLIST_TIMESCALE_FACTOR,\n",
    "                eigenval_cutoff=EIGENVAL_CUTOFF,\n",
    "                method='DPSS', \n",
    "                fit_method='lu_solve', \n",
    "                fix_phase_flips=False, \n",
    "                flag_phase_flip_ints=False,\n",
    "                skip_flagged_edges=True, \n",
    "                freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6],\n",
    "            ) \n",
    "            blacklist_wgts[pol] = np.where(\n",
    "                (np.abs(gains - smoothed_amp) / np.abs(smoothed_amp)) > BLACKLIST_RELATIVE_ERROR_THRESH,\n",
    "                0.0,\n",
    "                1.0\n",
    "            )\n",
    "        else:\n",
    "            blacklist_wgts[pol] = np.ones_like(amplitude_solutions[f\"A_J{pol}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d2fa1-ef96-4cd7-8a04-23bdb7304d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    smoothed_tip_tilt = {}\n",
    "    smoothed_amplitude = {}\n",
    "    \n",
    "    for pol in ['ee', 'nn']:\n",
    "        if RUN_AMPLITUDE_CAL:\n",
    "            gains = np.where(\n",
    "                np.isfinite(amplitude_solutions[f\"A_J{pol}\"]), \n",
    "                amplitude_solutions[f\"A_J{pol}\"], \n",
    "                1.0\n",
    "            )\n",
    "            wgts_here = np.where(np.isfinite(amplitude_solutions[f\"A_J{pol}\"]), avg_wgts[pol], 0.0)\n",
    "            wgts_here = np.where(where_inpainted[pol], WHERE_INPAINTED_WGTS, wgts_here)\n",
    "            wgts_here *= blacklist_wgts[pol]\n",
    "            smoothed_amp, _ = smooth_cal.time_freq_2D_filter(\n",
    "                gains=gains.astype(complex),\n",
    "                wgts=wgts_here,\n",
    "                freqs=freqs,\n",
    "                times=times,\n",
    "                freq_scale=FREQ_SMOOTHING_SCALE,\n",
    "                time_scale=TIME_SMOOTHING_SCALE * 0.5,\n",
    "                eigenval_cutoff=EIGENVAL_CUTOFF,\n",
    "                method='DPSS', \n",
    "                fit_method='lu_solve', \n",
    "                fix_phase_flips=False, \n",
    "                flag_phase_flip_ints=False,\n",
    "                skip_flagged_edges=True, \n",
    "                freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6],\n",
    "            ) \n",
    "            smoothed_amplitude[pol] = smoothed_amp.real\n",
    "        else:\n",
    "            smoothed_amplitude[pol] = np.ones_like(amplitude_solutions[pol])\n",
    "            \n",
    "        if RUN_TIP_TILT_PHASE_CAL:\n",
    "            smoothed_solutions = []\n",
    "            for i in range(2):\n",
    "                tip_tilt = phase_solutions[pol][..., i].astype(complex)\n",
    "                gains = np.where(np.isfinite(tip_tilt), tip_tilt, 0.0)\n",
    "                wgts_here = np.where(np.isfinite(tip_tilt), avg_wgts[pol], 0.0)\n",
    "                wgts_here = np.where(where_inpainted[pol], WHERE_INPAINTED_WGTS, wgts_here)\n",
    "                wgts_here *= blacklist_wgts[pol]\n",
    "                \n",
    "                tip_tilt_smoothed, _ = smooth_cal.time_freq_2D_filter(\n",
    "                    gains=gains,\n",
    "                    wgts=wgts_here,\n",
    "                    freqs=freqs,\n",
    "                    times=times,\n",
    "                    freq_scale=FREQ_SMOOTHING_SCALE,\n",
    "                    time_scale=TIME_SMOOTHING_SCALE * 0.5,\n",
    "                    eigenval_cutoff=EIGENVAL_CUTOFF,\n",
    "                    method='DPSS', \n",
    "                    fit_method='lu_solve', \n",
    "                    fix_phase_flips=False, \n",
    "                    flag_phase_flip_ints=False,\n",
    "                    skip_flagged_edges=True, \n",
    "                    freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6],\n",
    "                ) \n",
    "                smoothed_solutions.append(tip_tilt_smoothed.real)\n",
    "            \n",
    "            smoothed_tip_tilt[pol] = np.transpose(smoothed_solutions, (1, 2, 0))\n",
    "        else:\n",
    "            smoothed_tip_tilt[pol] = np.zeros(wgts[(0, 1, pol)].shape + (2,))\n",
    "    \n",
    "    if RUN_CROSS_POL_PHASE_CAL:\n",
    "        gains = np.where(np.isfinite(cross_pol_phase), cross_pol_phase, 0.0)\n",
    "        wgts_here = np.where(np.isfinite(cross_pol_phase), avg_wgts['en'] + avg_wgts['ne'], 0.0)\n",
    "        wgts_here = np.where(where_inpainted[pol], WHERE_INPAINTED_WGTS, wgts_here)\n",
    "        wgts_here *= blacklist_wgts[pol]\n",
    "        \n",
    "        cross_pol_smoothed, _ = smooth_cal.time_freq_2D_filter(\n",
    "            gains=gains.astype(complex),\n",
    "            wgts=wgts_here,\n",
    "            freqs=freqs,\n",
    "            times=times,\n",
    "            freq_scale=FREQ_SMOOTHING_SCALE,\n",
    "            time_scale=TIME_SMOOTHING_SCALE * 0.5,\n",
    "            eigenval_cutoff=EIGENVAL_CUTOFF,\n",
    "            method='DPSS', \n",
    "            fit_method='lu_solve', \n",
    "            fix_phase_flips=False, \n",
    "            flag_phase_flip_ints=False,\n",
    "            skip_flagged_edges=True, \n",
    "            freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6],\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47890fd1-7116-4659-9ae9-5289255bd11d",
   "metadata": {},
   "source": [
    "# Figure 1: Amplitude Parameters Before/After Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36fd92-6ca5-432e-a16e-ab439c176cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the local times for plotting\n",
    "if RUN_AMPLITUDE_CAL and RUN_CALIBRATION:\n",
    "    ai, aj = list(map(int, baseline_strings[0].split(\"_\")))\n",
    "    lsts = utils.JD2LST(times) * 12 / np.pi\n",
    "    wrap_point = (lsts[0] + lsts[-1]) / 2\n",
    "    lsts[wrap_point < lsts] -= 24\n",
    "    extent = [freqs.min() / 1e6, freqs.max() / 1e6, lsts.max(), lsts.min()]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 10), sharex=True, sharey=True)\n",
    "    for pi, pol in enumerate(['ee', 'nn']):\n",
    "        axs[pi, 0].imshow(\n",
    "            np.where(\n",
    "                where_inpainted[pol] | (all_flagged[pol]), \n",
    "                np.nan, \n",
    "                np.abs(amplitude_solutions[f'A_J{pol}'])\n",
    "            ), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            vmin=0.95, \n",
    "            vmax=1.05, \n",
    "            extent=extent, \n",
    "            cmap='turbo'\n",
    "        )\n",
    "        im = axs[pi, 1].imshow(\n",
    "            np.where(all_flagged[pol], np.nan, np.abs(smoothed_amplitude[pol])),\n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            vmin=0.95, \n",
    "            vmax=1.05, \n",
    "            extent=extent, \n",
    "            cmap='turbo'\n",
    "        )\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    axs[1, 0].set_xlabel(\"Frequency (MHz)\")\n",
    "    axs[1, 1].set_xlabel(\"Frequency (MHz)\")\n",
    "    axs[0, 0].set_ylabel(\"LST (hr)\")\n",
    "    axs[1, 0].set_ylabel(\"LST (hr)\")\n",
    "    cbar = plt.colorbar(im, ax=axs, fraction=0.05, pad=0.01)\n",
    "    cbar.set_label(\"Gain Amplitude\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c5048-3b56-43f7-a006-892a2a605049",
   "metadata": {},
   "source": [
    "# Figure 2: Tip/Tilt Parameters Before/After Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca91fb-3dd3-42cf-b304-35c7c0aaa081",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TIP_TILT_PHASE_CAL and RUN_CALIBRATION:\n",
    "    fig, axs = plt.subplots(4, 2, figsize=(15, 12), sharex=True, sharey=True)\n",
    "    ci = 0\n",
    "    for pi, pol in enumerate(['ee', 'nn']):\n",
    "        for ni in range(2):\n",
    "            axs[ci, 0].imshow(\n",
    "                np.where(\n",
    "                    where_inpainted[pol] | (all_flagged[pol]),\n",
    "                    np.nan,\n",
    "                    phase_solutions[pol][..., ni],\n",
    "                ),\n",
    "                aspect='auto', \n",
    "                interpolation='None', \n",
    "                vmin=-0.01, \n",
    "                vmax=0.01, \n",
    "                extent=extent, \n",
    "                cmap='turbo'\n",
    "            )\n",
    "            tip_tilt = smoothed_tip_tilt[pol][..., ni]\n",
    "            im = axs[ci, 1].imshow( \n",
    "                np.where(all_flagged[pol], np.nan, tip_tilt),\n",
    "                aspect='auto', \n",
    "                interpolation='None', \n",
    "                vmin=-0.01, \n",
    "                vmax=0.01, \n",
    "                extent=extent, \n",
    "                cmap='turbo'\n",
    "            )\n",
    "\n",
    "            # Labeling\n",
    "            axs[ci, 0].set_ylabel(r\"LST (hr)\")\n",
    "            \n",
    "            ci += 1\n",
    "        \n",
    "        axs[3, 0].set_xlabel(r\"Frequency (MHz)\")\n",
    "        axs[3, 1].set_xlabel(r\"Frequency (MHz)\")\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    cbar = plt.colorbar(im, ax=axs, fraction=0.04, pad=0.01)\n",
    "    cbar.set_label(\"Phase Gradient (rad/m)\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a170d-d5d0-441c-99ef-717bdb1e6e84",
   "metadata": {},
   "source": [
    "# Figure 3: Cross-Polarized Phase Before/After Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbcacc-8b51-4702-bc54-f6e037fa2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CROSS_POL_PHASE_CAL and RUN_CALIBRATION:\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6), sharex=True, sharey=True)\n",
    "    pol = 'ne'\n",
    "    axs[0].imshow(\n",
    "        np.where(\n",
    "            where_inpainted[pol] | (all_flagged[pol]),\n",
    "            np.nan,\n",
    "            cross_pol_phase,\n",
    "        ),\n",
    "        aspect='auto', \n",
    "        interpolation='None', \n",
    "        vmin=-0.1, \n",
    "        vmax=0.1, \n",
    "        extent=extent, \n",
    "        cmap='coolwarm'\n",
    "    )\n",
    "    im = axs[1].imshow( \n",
    "        np.where(all_flagged[pol], np.nan, cross_pol_smoothed.real),\n",
    "        aspect='auto', \n",
    "        interpolation='None', \n",
    "        vmin=-0.1, \n",
    "        vmax=0.1, \n",
    "        extent=extent, \n",
    "        cmap='coolwarm'\n",
    "    )\n",
    "\n",
    "    # Labeling\n",
    "    axs[0].set_ylabel(r\"LST (hr)\")    \n",
    "    axs[0].set_xlabel(r\"Frequency (MHz)\")\n",
    "    axs[1].set_xlabel(r\"Frequency (MHz)\")\n",
    "    plt.tight_layout()\n",
    "    cbar = plt.colorbar(im, ax=axs, fraction=0.05, pad=0.01)\n",
    "    cbar.set_label(\"Cross-Polarized Phase (rad)\", fontsize=14)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9d820-d1fb-4172-baaa-7ab70da92242",
   "metadata": {},
   "source": [
    "# Figure 4: Visibility/LST-Averaged Variance Before/After LST-Cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be5af2-09cd-4b00-88d9-cda214c10d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_degenerate_gains_single_baseline(key, all_calibration_parameters, transformed_antpos, use_cross_pol=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ant1pol, ant2pol = utils.split_bl(key)\n",
    "    blvec = transformed_antpos[ant2pol[0]] - transformed_antpos[ant1pol[0]]\n",
    "    gain = all_calibration_parameters[f\"amplitude_{ant1pol[1]}\"].astype(complex) * all_calibration_parameters[f\"amplitude_{ant1pol[1]}\"].astype(complex)\n",
    "    g1 = np.exp(\n",
    "        1j * np.einsum(\"tfc,c->tf\", all_calibration_parameters[f\"tip_tilt_{ant2pol[1]}\"], transformed_antpos[ant2pol[0]])\n",
    "    )\n",
    "    g2 = np.exp(\n",
    "        1j * np.einsum(\"tfc,c->tf\", all_calibration_parameters[f\"tip_tilt_{ant1pol[1]}\"], transformed_antpos[ant1pol[0]])\n",
    "    )\n",
    "    gain *= g1 * g2.conj()\n",
    "\n",
    "    if ant1pol[-1] != ant2pol[-1]: \n",
    "        if ant1pol[-1] == 'Jnn':\n",
    "            g1 = np.exp(1j * all_calibration_parameters['cross_pol'])\n",
    "            gain *= g1\n",
    "        elif ant2pol[-1] == 'Jnn':\n",
    "            g1 = np.exp(-1j * all_calibration_parameters['cross_pol'])\n",
    "            gain *= g1\n",
    "    \n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e40b0a-2e47-4152-a972-f56d9dee8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    all_calibration_parameters = {\n",
    "        \"amplitude_Jee\": smoothed_amplitude['ee'],\n",
    "        \"amplitude_Jnn\": smoothed_amplitude['nn'],\n",
    "        \"tip_tilt_Jee\": smoothed_tip_tilt['ee'],\n",
    "        \"tip_tilt_Jnn\": smoothed_tip_tilt['nn'],\n",
    "        \"cross_pol\": cross_pol_smoothed,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(4, 2, figsize=(15, 10), sharey=True, sharex=True)\n",
    "    \n",
    "    for pi, pol in enumerate(['ee', 'nn']):\n",
    "        excess_var = 0\n",
    "        excess_var_cal = 0\n",
    "        count = 0\n",
    "        weights = 0\n",
    "        for key in data_for_cal:\n",
    "            if pol in key:\n",
    "                zsquare = np.abs(data_for_cal[key] - model[key]) ** 2\n",
    "                excess_var += zsquare * wgts[key]\n",
    "                gain = expand_degenerate_gains_single_baseline(key, all_calibration_parameters, transformed_antpos, use_cross_pol=True)\n",
    "                data_cal = data_for_cal[key] / gain\n",
    "                zsquare = np.abs(data_cal - model[key]) ** 2\n",
    "                excess_var_cal += zsquare * wgts[key]\n",
    "                weights += wgts[key]\n",
    "    \n",
    "        im = axs[pi, 0].imshow(\n",
    "            np.log10(np.abs(excess_var) / weights), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            cmap='turbo', \n",
    "            vmin=-1, \n",
    "            vmax=4, \n",
    "            extent=extent\n",
    "        )\n",
    "        im = axs[pi, 1].imshow(\n",
    "            np.log10(np.abs(excess_var_cal) / weights), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            cmap='turbo', \n",
    "            vmin=-1, \n",
    "            vmax=4, \n",
    "            extent=extent\n",
    "        )\n",
    "    \n",
    "    for pi, pol in enumerate(['en', 'ne']):\n",
    "        excess_var = 0\n",
    "        excess_var_cal = 0\n",
    "        count = 0\n",
    "        weights = 0\n",
    "        for key in cross_pol_data:\n",
    "            if pol in key:\n",
    "                zsquare = np.abs(cross_pol_data[key] - cross_pol_model[key]) ** 2\n",
    "                excess_var += zsquare * wgts[key]\n",
    "                gain = expand_degenerate_gains_single_baseline(key, all_calibration_parameters, transformed_antpos, use_cross_pol=True)\n",
    "                data_cal = cross_pol_data[key] / gain\n",
    "                zsquare = np.abs(data_cal - cross_pol_model[key]) ** 2\n",
    "                excess_var_cal += zsquare * wgts[key]\n",
    "                weights += wgts[key]\n",
    "    \n",
    "        im = axs[pi + 2, 0].imshow(\n",
    "            np.log10(np.abs(excess_var) / weights), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            cmap='turbo', \n",
    "            vmin=-1, \n",
    "            vmax=4, \n",
    "            extent=extent\n",
    "        )\n",
    "        im = axs[pi + 2, 1].imshow(\n",
    "            np.log10(np.abs(excess_var_cal) / weights), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            cmap='turbo', \n",
    "            vmin=-1, \n",
    "            vmax=4, \n",
    "            extent=extent\n",
    "        )\n",
    "    \n",
    "    # Labeling\n",
    "    for i in range(4):\n",
    "        axs[i, 0].set_ylabel(r\"LST (hr)\")   \n",
    "    \n",
    "    axs[3, 0].set_xlabel(r\"Frequency (MHz)\")\n",
    "    axs[3, 1].set_xlabel(r\"Frequency (MHz)\")\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar(im, ax=axs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14aa6a3-9d93-41a1-8c8e-ba53336a4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    indices = np.searchsorted(single_jd_times, times)\n",
    "    \n",
    "    # Expand out tip/tilt to full data size\n",
    "    expanded_tip_tilt = {\n",
    "        pol: np.zeros((single_jd_times.size,) + smoothed_tip_tilt[pol].shape[1:])\n",
    "        for pol in smoothed_tip_tilt\n",
    "    }\n",
    "    expanded_amplitude = {\n",
    "        pol: np.ones((single_jd_times.size,) + smoothed_amplitude[pol].shape[1:])\n",
    "        for pol in smoothed_amplitude\n",
    "    }\n",
    "    for pol in expanded_tip_tilt:\n",
    "        expanded_tip_tilt[pol][indices] = smoothed_tip_tilt[pol]\n",
    "        expanded_amplitude[pol][indices] = np.where(\n",
    "            np.isclose(smoothed_amplitude[pol], 0.0),\n",
    "            1.0,\n",
    "            smoothed_amplitude[pol]\n",
    "        )\n",
    "    \n",
    "    # Expand out cross-polarized degeneracy to full data size\n",
    "    expanded_cross_pol = np.zeros((single_jd_times.size,) + cross_pol_smoothed.shape[1:])\n",
    "    expanded_cross_pol[indices] = cross_pol_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07872ed-d2ea-40f5-92cf-e8d9d696272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def write_single_baseline_lstcal_solutions(filename, all_calibration_parameters, flag_array, transformed_antpos, times, freqs, pols, compression=None, compression_opts=None):\n",
    "    \"\"\"\n",
    "    Write single-baseline LST calibration solutions and metadata to an HDF5 file.\n",
    "\n",
    "    This function creates an HDF5 file with two main groups: ``/data`` and ``/Header``.\n",
    "    The ``/data`` group stores the calibration parameters and flag array, while the\n",
    "    ``/Header`` group stores metadata such as version, times, frequencies, antenna\n",
    "    positions, and polarizations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the HDF5 file to create.\n",
    "    all_calibration_parameters : dict of {str: np.ndarray}\n",
    "        Dictionary mapping calibration parameter names (e.g., gains, delays) to\n",
    "        numpy arrays containing their values.\n",
    "    flag_array : np.ndarray\n",
    "        Boolean array indicating flagged (invalid) data samples.\n",
    "    transformed_antpos : dict of {int: array_like}\n",
    "        Dictionary mapping antenna numbers to their transformed positions (typically\n",
    "        in ENU or another projected coordinate system).\n",
    "    times : np.ndarray\n",
    "        Array of observation times corresponding to the calibration solutions.\n",
    "    freqs : np.ndarray\n",
    "        Array of frequencies corresponding to the calibration solutions.\n",
    "    pols : list of str\n",
    "        List of polarization strings (e.g., ``[\"ee\", \"nn\", \"en\", \"ne\"]``).\n",
    "\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'w') as file:\n",
    "        # /data group\n",
    "        dgrp = file.create_group(\"data\")\n",
    "        for pname in all_calibration_parameters:\n",
    "            dgrp.create_dataset(\n",
    "                pname,\n",
    "                data=all_calibration_parameters[pname],\n",
    "                compression=compression,\n",
    "                compression_opts=compression_opts,\n",
    "            )\n",
    "        dgrp.create_dataset(\n",
    "            \"flag_array\",\n",
    "            data=flag_array,\n",
    "            compression=compression,\n",
    "            compression_opts=compression_opts,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Create header for metadata\n",
    "        header = file.create_group(\"Header\")\n",
    "        header['times'] = times\n",
    "        header['freqs'] = freqs\n",
    "\n",
    "        # Extract antenna numbers (keys) and positions (values)\n",
    "        ant_nums = list(transformed_antpos.keys())\n",
    "        ant_positions = list(transformed_antpos.values())\n",
    "        header[\"antenna_numbers\"] = np.array(ant_nums, dtype=int)\n",
    "        header[\"antenna_positions\"] = np.array(ant_positions)\n",
    "\n",
    "        # Store polarizations\n",
    "        pols_encoded = [p.encode('utf-8') for p in pols]\n",
    "        header[\"polarization_array\"] = pols_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbb7a5-e5b8-40f0-a2aa-da13bcf660e9",
   "metadata": {},
   "source": [
    "# 4. Save Smoothed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e5c6a-c0a2-4319-999d-06ba425bbe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    # Store calibration parameters\n",
    "    all_calibration_parameters = {\n",
    "        \"amplitude_Jee\": expanded_amplitude['ee'],\n",
    "        \"amplitude_Jnn\": expanded_amplitude['nn'],\n",
    "        \"tip_tilt_Jee\": expanded_tip_tilt['ee'],\n",
    "        \"tip_tilt_Jnn\": expanded_tip_tilt['nn'],\n",
    "        \"cross_pol\": expanded_cross_pol,\n",
    "    }\n",
    "    \n",
    "    # Get the calibration filename\n",
    "    # _OUTDIR = \"/lustre/aoc/projects/hera/tcox/LST_AVG_FILE_CACHE\" # TODO: Remove\n",
    "    cal_fname = os.path.join(OUTDIR, LSTCAL_FNAME_FORMAT.format(night=jd_here))\n",
    "\n",
    "    # Make flag array\n",
    "    sub_flag_array = np.array([all_flagged[pol] for pol in polarizations])\n",
    "    \n",
    "    flag_array = np.ones((len(polarizations), single_jd_times.size, freqs.size), dtype=sub_flag_array.dtype)\n",
    "    flag_array[:, indices] = sub_flag_array\n",
    "\n",
    "    # Write LST-cal solutions to disk\n",
    "    write_single_baseline_lstcal_solutions(\n",
    "        filename=cal_fname, \n",
    "        all_calibration_parameters=all_calibration_parameters, \n",
    "        flag_array=flag_array,\n",
    "        transformed_antpos=transformed_antpos, \n",
    "        times=single_jd_times, \n",
    "        freqs=freqs, \n",
    "        pols=polarizations\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344a801-46f4-4a28-9719-a8b444ff9b0f",
   "metadata": {},
   "source": [
    "### FOR JOSH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587f07b-71ef-4556-81f3-4661891f9757",
   "metadata": {},
   "source": [
    "def load_single_baseline_lstcal_solutions(filename):\n",
    "    \"\"\"\n",
    "    Load single-baseline LST calibration solutions and metadata from an HDF5 file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_calibration_parameters : dict[str, np.ndarray]\n",
    "        Dict of parameter name -> array, from the /data group (all except 'flag_array').\n",
    "    flag_array : np.ndarray\n",
    "        Boolean array from /data/flag_array.\n",
    "    transformed_antpos : dict[int, np.ndarray]\n",
    "        Dict mapping antenna number -> position vector, from /Header.\n",
    "    times : np.ndarray\n",
    "        /Header/times dataset.\n",
    "    freqs : np.ndarray\n",
    "        /Header/freqs dataset.\n",
    "    pols : list[str]\n",
    "        List of polarization strings from /Header/polarization_array.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as file:\n",
    "        # --- data ---\n",
    "        dgrp = file[\"data\"]\n",
    "    \n",
    "        flag_array = np.asarray(dgrp[\"flag_array\"], dtype=bool)\n",
    "        all_calibration_parameters = {\n",
    "            name: np.asarray(ds) for name, ds in dgrp.items() if name != \"flag_array\"\n",
    "        }\n",
    "\n",
    "        # --- header ---\n",
    "        hdr = file[\"Header\"]\n",
    "        times = np.asarray(hdr[\"times\"])\n",
    "        freqs = np.asarray(hdr[\"freqs\"])\n",
    "\n",
    "        ant_nums = np.asarray(hdr[\"antenna_numbers\"], dtype=int)\n",
    "        ant_positions = np.asarray(hdr[\"antenna_positions\"])\n",
    "        transformed_antpos = {\n",
    "            int(a): pos for a, pos in zip(ant_nums, ant_positions)\n",
    "        }\n",
    "\n",
    "        pols = [p.decode(\"utf-8\") for p in hdr[\"polarization_array\"]]\n",
    "\n",
    "    return all_calibration_parameters, flag_array, transformed_antpos, times, freqs, pols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223439ea-08b2-47df-a90f-4c3fc1cf289b",
   "metadata": {},
   "source": [
    "_OUTDIR = \"/lustre/aoc/projects/hera/tcox/LST_AVG_FILE_CACHE\"\n",
    "cal_fname = os.path.join(_OUTDIR, LSTCAL_FNAME_FORMAT.format(night=jd_here))\n",
    "_all_calibration_parameters, _flag_array, _transformed_antpos, _times, _freqs, _pols = load_single_baseline_lstcal_solutions(cal_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec842a4e-a742-4c28-b877-c34195ece4ee",
   "metadata": {},
   "source": [
    "%%time\n",
    "all_days_crosses = SingleBaselineStacker.from_configurator(\n",
    "    configurator,\n",
    "    bl_string,\n",
    "    lst_bin_edges,\n",
    "    lst_branch_cut=lst_branch_cut, \n",
    "    where_inpainted_file_rules=where_inpainted_file_rules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d044f0-5c72-4f74-9a65-d4e967d17d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hera_mc_kernel",
   "language": "python",
   "name": "hera_mc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db259da5",
   "metadata": {},
   "source": [
    "# Antenna Classification Daily Summary\n",
    "\n",
    "**by Josh Dillon last updated October 17, 2022**\n",
    "\n",
    "This notebook parses and summarizes the output of the [`file_calibration`](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/file_calibration.ipynb) notebook to produce a report on per-antenna malfunctions on a daily basis.\n",
    "\n",
    "Quick links:\n",
    "# [• Summary of Per Antenna Issues](#Summary-of-Per-Antenna-Issues)\n",
    "# [• Figure 1: Per File Overall Antenna Classification Summary](#Figure-1:-Per-File-Overall-Antenna-Classification-Summary)\n",
    "# [• Figure 2: Per Classifier Antenna Flagging Summary](#Figure-2:-Per-Classifier-Antenna-Flagging-Summary)\n",
    "# [• Figure 3: Array Visualization of Overall Daily Classification](#Figure-3:-Array-Visualization-of-Overall-Daily-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49767db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from hera_cal import io, utils\n",
    "from hera_qm import ant_class\n",
    "from uvtools.plot import plot_antpos, plot_antclass\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a2a47",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36729e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse settings from environment\n",
    "ANT_CLASS_FOLDER = os.environ.get(\"ANT_CLASS_FOLDER\", \"./\")\n",
    "SUM_FILE = os.environ.get(\"SUM_FILE\", None)\n",
    "OC_SKIP_OUTRIGGERS = os.environ.get(\"OC_SKIP_OUTRIGGERS\", \"TRUE\").upper() == \"TRUE\"\n",
    "\n",
    "for param in ['ANT_CLASS_FOLDER', 'SUM_FILE', 'OC_SKIP_OUTRIGGERS']:\n",
    "    print(f\"{param} = '{eval(param)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01198371",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUM_FILE is not None:\n",
    "    from astropy.time import Time, TimeDelta\n",
    "    utc = Time(float(SUM_FILE.split('zen.')[-1].split('.sum.uvh5')[0]), format='jd').datetime\n",
    "    print(f'Date: {utc.month}-{utc.day}-{utc.year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set thresholds for fraction of the day\n",
    "overall_thresh = .1\n",
    "all_zero_thresh = .1\n",
    "eo_zeros_thresh = .1\n",
    "cross_pol_thresh = .1\n",
    "bad_fem_thresh = .1\n",
    "high_power_thresh = .1\n",
    "low_power_thresh = .1\n",
    "low_corr_thresh = .1\n",
    "bad_shape_thresh = .5\n",
    "excess_rfi_thresh = .1\n",
    "chisq_thresh = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d9e81",
   "metadata": {},
   "source": [
    "## Load classifications and other metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70511a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csvs\n",
    "csv_files = sorted(glob.glob(os.path.join(ANT_CLASS_FOLDER, '*.ant_class.csv')))\n",
    "jds = [float(f.split('/')[-1].split('zen.')[-1].split('.sum')[0]) for f in csv_files]\n",
    "tables = [pd.read_csv(f) for f in csv_files]\n",
    "table_cols = tables[0].columns[1::2]\n",
    "class_cols = tables[0].columns[2::2]\n",
    "print(f'Found {len(csv_files)} csv files starting with {csv_files[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse ant_strings\n",
    "ap_strs = np.array(tables[0]['Antenna'])\n",
    "ants = sorted(set(int(a[:-1]) for a in ap_strs))\n",
    "translator = ''.maketrans('e', 'n') | ''.maketrans('n', 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aaec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get node numbers\n",
    "node_dict = {ant: 'Unknown' for ant in ants}\n",
    "try:\n",
    "    from hera_mc import cm_hookup\n",
    "    hookup = cm_hookup.get_hookup('default')\n",
    "    for ant_name in hookup:\n",
    "        ant = int(\"\".join(filter(str.isdigit, ant_name)))\n",
    "        if ant in node_dict:\n",
    "            if hookup[ant_name].get_part_from_type('node')['E<ground'] is not None:\n",
    "                node_dict[ant] = int(hookup[ant_name].get_part_from_type('node')['E<ground'][1:])\n",
    "except:\n",
    "    pass\n",
    "nodes = sorted(set(node_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25dc0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_array(col):\n",
    "    class_array = np.vstack([t[col] for t in tables])\n",
    "    class_array[class_array == 'good'] = 1.7\n",
    "    class_array[class_array == 'suspect'] = 1\n",
    "    class_array[class_array == 'bad'] = 0\n",
    "    return class_array.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ece48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUM_FILE is not None:\n",
    "    hd = io.HERADataFastReader(SUM_FILE)\n",
    "    ap_tuples = [(int(ap[:-1]), {'e': 'Jee', 'n': 'Jnn'}[ap[-1]]) for ap in ap_strs]\n",
    "    bad_bools = np.mean(classification_array('Antenna Class') == 0, axis=0) > overall_thresh\n",
    "    bad_aps = [ap_tuples[i] for i in np.arange(len(ap_tuples))[bad_bools]]\n",
    "    suspect_bools = np.mean(classification_array('Antenna Class') == 1, axis=0) > overall_thresh\n",
    "    suspect_aps = [ap_tuples[i] for i in np.arange(len(ap_tuples))[suspect_bools] if ap_tuples[i] not in bad_aps]\n",
    "    good_aps = [ap for ap in ap_tuples if ap not in bad_aps and ap not in suspect_aps]\n",
    "    overall_class = ant_class.AntennaClassification(bad=bad_aps, suspect=suspect_aps, good=good_aps)\n",
    "    autos, _, _ = hd.read(bls=[bl for bl in hd.bls if utils.split_bl(bl)[0] == utils.split_bl(bl)[1]], read_flags=False, read_nsamples=False)\n",
    "    avg_unflagged_auto = {pol: np.mean([autos[bl] for bl in autos if bl[2] == pol and overall_class[utils.split_bl(bl)[0]] != 'bad'], axis=(0, 1)) for pol in ['ee', 'nn']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd455736",
   "metadata": {},
   "source": [
    "## Figure out and summarize per-antenna issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ebb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_issue_summary(bad_ant_strs, title, notes='', plot=False):\n",
    "    '''Print report for list of bad antenna polarizations strings'''\n",
    "    unique_bad_antnums = [int(ap[:-1]) for ap in bad_ant_strs]\n",
    "    display(HTML(f'<h2>{title}: ({len(bad_ant_strs)} antpols across {len(set([ba[:-1] for ba in bad_ant_strs]))} antennas)</h2>'))\n",
    "    if len(notes) > 0:\n",
    "        display(HTML(f'<h4>{notes}</h4>'))\n",
    "    if len(bad_ant_strs) > 0:\n",
    "        print(f'All Bad Antpols: {\", \".join(bad_ant_strs)}\\n')\n",
    "    for node in nodes:\n",
    "        if np.any([node == node_dict[a] for a in unique_bad_antnums]):\n",
    "            aps = [ap for ap in bad_ant_strs if node_dict[int(ap[:-1])] == node]\n",
    "            whole_ants = [str(wa) for wa in set([int(ap[:-1]) for ap in aps if ap.translate(translator) in bad_ant_strs])]\n",
    "            single_pols =  [ap for ap in aps if ap.translate(translator) not in bad_ant_strs]\n",
    "            print(f'Node {node}:')\n",
    "            print(f'\\tAntpols ({len(aps)} total): {\", \".join(aps)}')\n",
    "            print(f'\\tWhole Ants ({len(whole_ants)} total): {\", \".join(whole_ants)}')\n",
    "            print(f'\\tSingle Pols ({len(single_pols)} total): {\", \".join(single_pols)}')\n",
    "            if plot and SUM_FILE is not None:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(12,4), dpi=70, sharey=True, gridspec_kw={'wspace': 0})\n",
    "                for ax, pol in zip(axes, ['ee', 'nn']):                    \n",
    "                    ax.semilogy(autos.freqs / 1e6, avg_unflagged_auto[pol], 'k--', label='Average\\nUnflagged\\nAuto')\n",
    "                    for ap in aps:\n",
    "                        ant = int(ap[:-1]), utils.comply_pol(ap[-1])\n",
    "                        auto_bl = utils.join_bl(ant, ant)\n",
    "                        if auto_bl[2] == pol:\n",
    "                            ax.semilogy(autos.freqs / 1e6, np.mean(autos[auto_bl], axis=0), label=ap)\n",
    "                    ax.legend()\n",
    "                    ax.set_xlim([40, 299])\n",
    "                    ax.set_title(f'{title} on Node {node} ({pol}-antennas)')\n",
    "                    ax.set_xlabel('Frequency (MHz)')\n",
    "                axes[0].set_ylabel('Single File Raw Autocorrelation')\n",
    "                plt.tight_layout()\n",
    "                plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute various helpful quantities\n",
    "all_slopes = np.vstack([t['Autocorr Slope'] for t in tables])\n",
    "median_slope = np.median(all_slopes)\n",
    "bad_slopes = np.vstack([t['Autocorr Slope Class'] for t in tables]) == 'bad'\n",
    "suspect_slopes = np.vstack([t['Autocorr Slope Class'] for t in tables]) == 'suspect'\n",
    "bad_shapes = np.vstack([t['Autocorr Shape Class'] for t in tables]) == 'bad'\n",
    "suspect_shapes = np.vstack([t['Autocorr Shape Class'] for t in tables]) == 'suspect'\n",
    "all_powers = np.vstack([t['Autocorr Power'] for t in tables])\n",
    "median_power = np.median(all_powers)\n",
    "bad_powers = np.vstack([t['Autocorr Power Class'] for t in tables]) == 'bad'\n",
    "suspect_powers = np.vstack([t['Autocorr Power Class'] for t in tables]) == 'suspect'\n",
    "bad_rfi = np.vstack([t['RFI in Autos Class'] for t in tables]) == 'bad'\n",
    "suspect_rfi = np.vstack([t['RFI in Autos Class'] for t in tables]) == 'suspect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da98db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all zeros\n",
    "all_zeros_strs = ap_strs[np.mean(np.vstack([t['Dead? Class'] for t in tables]) == 'bad', axis=0) > all_zero_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfed7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find even/odd zeros\n",
    "eo_zeros_strs = ap_strs[np.mean(np.vstack([t['Even/Odd Zeros Class'] for t in tables]) == 'bad', axis=0) > eo_zeros_thresh]\n",
    "eo_zeros_strs = [ap for ap in eo_zeros_strs if ap not in all_zeros_strs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cross-polarized antennas\n",
    "cross_pol_strs = ap_strs[np.mean(np.vstack([t['Cross-Polarized Class'] for t in tables]) == 'bad', axis=0) > cross_pol_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7352facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find FEM power issues: must be low power, high slope, and bad or suspect in power, slope, rfi, and shape\n",
    "fem_off_prod = (bad_powers + .5 * suspect_powers) * (bad_slopes + .5 * suspect_slopes)\n",
    "fem_off_prod *= (bad_rfi + .5 * suspect_rfi) * (bad_shapes + .5 * suspect_shapes)\n",
    "fem_off_strs = ap_strs[np.mean(fem_off_prod * (all_powers < median_power) * (all_slopes > median_slope), axis=0) > .1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf573c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find high power issues\n",
    "high_power_strs = ap_strs[np.mean(bad_powers & (all_powers > median_power), axis=0) > high_power_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a74dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find other low power issues\n",
    "low_power_strs = ap_strs[np.mean(bad_powers & (all_powers < median_power), axis=0) > low_power_thresh]\n",
    "low_power_strs = [ap for ap in low_power_strs if ap not in all_zeros_strs and ap not in fem_off_strs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a97e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find low correlation (but not low power)\n",
    "low_corr_strs = ap_strs[np.mean(np.vstack([t['Low Correlation Class'] for t in tables]) == 'bad', axis=0) > low_corr_thresh]\n",
    "low_corr_strs = [ap for ap in low_corr_strs if ap not in (set(low_power_strs) | set(all_zeros_strs) | set(fem_off_strs))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find bad bandpasses\n",
    "bad_bandpass_strs = ap_strs[np.mean(bad_shapes, axis=0) > bad_shape_thresh]\n",
    "bad_bandpass_strs = [ap for ap in bad_bandpass_strs if ap not in (set(low_power_strs) | set(all_zeros_strs) | set(high_power_strs) | set(fem_off_strs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a712c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find antennas with excess RFI\n",
    "excess_rfi_strs = ap_strs[np.mean(np.vstack([t['RFI in Autos Class'] for t in tables]) == 'bad', axis=0) > excess_rfi_thresh]\n",
    "excess_rfi_strs = [ap for ap in excess_rfi_strs if ap not in (set(low_power_strs) | set(all_zeros_strs) |  set(fem_off_strs) |\n",
    "                                                              set(bad_bandpass_strs) | set(high_power_strs))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf488b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find antennas with high redcal chi^2\n",
    "chisq_strs = ap_strs[np.mean(np.vstack([t['Redcal chi^2 Class'] for t in tables]) == 'bad', axis=0) > chisq_thresh]\n",
    "chisq_strs = [ap for ap in chisq_strs if ap not in (set(bad_bandpass_strs) | set(low_power_strs) | set(excess_rfi_strs) | set(low_corr_strs) |\n",
    "                                                    set(all_zeros_strs) | set(high_power_strs) | set(fem_off_strs) | set(eo_zeros_strs))]\n",
    "if OC_SKIP_OUTRIGGERS:\n",
    "    chisq_strs = [ap for ap in chisq_strs if int(ap[:-1]) < 320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all results\n",
    "to_print = [(all_zeros_strs, 'All-Zeros', 'These antennas have visibilities that are more than half zeros.'),\n",
    "            (eo_zeros_strs, 'Excess Zeros in Either Even or Odd Spectra', \n",
    "             'These antennas are showing evidence of packet loss or X-engine failure.', True),\n",
    "            (cross_pol_strs, 'Cross-Polarized', 'These antennas have their east and north cables swapped.'),\n",
    "            (fem_off_strs, 'Likely FEM Power Issue', 'These antennas have low power, anomolously high slopes, and extra channels identified as RFI.', True),\n",
    "            (high_power_strs, 'High Power', 'These antennas have high median power.', True),\n",
    "            (low_power_strs, 'Other Low Power Issues', 'These antennas have low power, but are not all-zeros and not FEM off.', True),\n",
    "            (low_corr_strs, 'Low Correlation, But Not Low Power', 'These antennas are low correlation, but their autocorrelation power levels look OK.'),\n",
    "            (bad_bandpass_strs, 'Bad Bandpass Shapes, But Not Bad Power', \n",
    "             'These antennas have unusual bandpass shapes, but are not all-zeros, high power, low power, or FEM off.', True),\n",
    "            (excess_rfi_strs, 'Excess RFI', 'These antennas have excess strucutre (identified as possible RFI) in their bandpassed relative to the ' + \\\n",
    "             'median antenna, but not low or high power or a bad bandpass.', True),\n",
    "            (chisq_strs, 'Redcal chi^2', 'These antennas have been idenfied as not redundantly calibrating well, even after passing the above checks.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_high_level_summary():\n",
    "    for tp in sorted(to_print, key=lambda x: len(x[0]), reverse=True):\n",
    "        print(f'{len(tp[0])} antpols (on {len(set([ap[:-1] for ap in tp[0]]))} antennas) frequently flagged for {tp[1]}.')\n",
    "        \n",
    "def print_all_issue_summaries():\n",
    "    for tp in to_print:\n",
    "        print_issue_summary(*tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d1e66",
   "metadata": {},
   "source": [
    "# Summary of Per-Antenna Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee229c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_high_level_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a66e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_all_issue_summaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942437b1",
   "metadata": {},
   "source": [
    "## Full-Day Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b64f06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def classification_plot(col):\n",
    "    class_array = classification_array(col)\n",
    "    plt.figure(figsize=(12, len(ants) / 10), dpi=100)\n",
    "    plt.imshow(class_array.T, aspect='auto', interpolation='none', cmap='RdYlGn', vmin=0, vmax=2,\n",
    "               extent=[jds[0] - np.floor(jds[0]), jds[-1] - np.floor(jds[0]), len(ants), 0])\n",
    "    plt.xlabel(f'JD - {int(jds[0])}')\n",
    "    plt.yticks(ticks=np.arange(.5, len(ants)+.5), labels=[ant for ant in ants], fontsize=6)\n",
    "    plt.ylabel('Antenna Number (East First, Then North)')\n",
    "    plt.gca().tick_params(right=True, top=True, labelright=True, labeltop=True)\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'{col}: Green is \"good\", Yellow is \"suspect\", Red is \"bad\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc71609f",
   "metadata": {},
   "source": [
    "# *Figure 1: Per-File Overall Antenna Classification Summary*\n",
    "\n",
    "This \"big green board\" shows the overall (i.e. after redundant calibration) classification of antennas on a per-file basis. This is useful for looking at time-dependent effects across the array. While only antenna numbers are labeled, both polarizations are shown, first East then North going down, above and below the antenna's tick mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf2007",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classification_plot('Antenna Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3fc9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute flag fractions for all classifiers and antennas\n",
    "frac_flagged = []\n",
    "for col in class_cols[1:]:\n",
    "    class_array = np.vstack([t[col] for t in tables])\n",
    "    class_array[class_array == 'good'] = False\n",
    "    class_array[class_array == 'suspect'] = False\n",
    "    class_array[class_array == 'bad'] = True\n",
    "    frac_flagged.append(np.sum(class_array, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a989aac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_flag_frac_all_classifiers():\n",
    "    ticks = []\n",
    "    for i, col in enumerate(list(class_cols[1:])):\n",
    "        ticks.append(f'{col} ({np.nanmean(np.array(frac_flagged).astype(float)[i]) / len(csv_files):.2%})')\n",
    "    plt.figure(figsize=(8, len(ants) / 10), dpi=100)\n",
    "    plt.imshow(np.array(frac_flagged).astype(float).T, aspect='auto', interpolation='none', cmap='viridis')\n",
    "    plt.xticks(ticks=np.arange(len(list(class_cols[1:]))), labels=ticks, rotation=-45, ha='left')\n",
    "    plt.yticks(ticks=np.arange(.5, len(ap_strs)+.5, 2), labels=[ant for ant in ants], fontsize=6)\n",
    "    plt.ylabel('Antenna Number (East First, Then North)')\n",
    "    plt.gca().tick_params(right=True, labelright=True,)\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.set_xticks(ticks=np.arange(len(list(class_cols[1:]))), labels=ticks, rotation=45, ha='left')\n",
    "    plt.colorbar(ax=plt.gca(), label=f'Number of Files Flagged Out of {len(csv_files)}', aspect=50)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99cbcb",
   "metadata": {},
   "source": [
    "# *Figure 2: Per-Classifier Antenna Flagging Summary*\n",
    "\n",
    "This plot shows the fraction of files flagged for each reason for each antenna. It's useful for seeing which problems are transitory and which ones are more common. Note that not all flags are independent and in particular redcal chi^2 takes an OR of other classifications as an input. Also note that only antenna numbers are labeled, both polarizations are shown, first East then North going down, above and below the antenna's tick mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d84577",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_flag_frac_all_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d827ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_class_plot():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=100, gridspec_kw={'width_ratios': [2, 1]})\n",
    "    plot_antclass(hd.antpos, overall_class, ax=axes[0], ants=[ant for ant in hd.data_ants if ant < 320], legend=False, \n",
    "                  title=f'HERA Core: Overall Flagging Based on {overall_thresh:.1%} Daily Threshold')\n",
    "    plot_antclass(hd.antpos, overall_class, ax=axes[1], ants=[ant for ant in hd.data_ants if ant >= 320], radius=50, title='Outriggers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f8591",
   "metadata": {},
   "source": [
    "# *Figure 3: Array Visualization of Overall Daily Classification*\n",
    "\n",
    "Overall classification of antenna-polarizations shown on the array layout. If any antenna is marked bad for any reason more than the threshold (default 10%), it is marked bad here. Likewise, if any antenna is marked suspect for more than 10% of the night (but not bad), it's suspect here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4607bb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if SUM_FILE is not None: array_class_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

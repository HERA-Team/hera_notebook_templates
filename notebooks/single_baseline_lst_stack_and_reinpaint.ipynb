{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78296e3",
   "metadata": {},
   "source": [
    "# Single Baseline LST-Stacker and Re-Inpainter\n",
    "\n",
    "**by Josh Dillon**, last updated August 15, 2025\n",
    "\n",
    "This notebook performs LST-stacking (a.k.a. LST-binning) of whole-JD, single baseline, all pol files. Most parameters are controlled by a toml config file, [such as this one](https://github.com/HERA-Team/hera_pipelines/blob/main/pipelines/h6c/idr3/v1/lstbin/single_bl_lst_stack_config.toml). In addition al single-baseline files, this notebook also requires UVFlag-compatible `where_inpainted` files which tell us where inpainting was previously done.\n",
    "\n",
    "In addition to LST-stacking, which includes rephasing to a common grid, this notebook also performs re-inpainting. Data that are outliers among the other nights (in terms of a high modified $z$-score) and had previously been inpainted are now re-inpainted (on a whole band, single integration basis) using information from other nights, as well as feathering to prevent discontinuities. Next, a bit of \"ex-painting\" is done to ensure that all nights span the same frequency range (or are completely flagged). This is again informed by what's going on on other nights. Despite the potentially large amount of inpainting, inpainted data are considered to have Nsamples=0 in the final LST-stacked data products.\n",
    "\n",
    "Finally, this notebook performs an optional per-night FR=0 filter, under the theory that per-night FR=0 systematics might vary from night to night in a way that can be mitigated with per-night filtering. This data product is saved separately.\n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "# [• Figure 1: East-Polarized LST-Stacked Amplitude, Phase, and Nsamples after Re-Inpainting](#Figure-1:-East-Polarized-LST-Stacked-Amplitude,-Phase,-and-Nsamples-after-Re-Inpainting)\n",
    "# [• Figure 2: North-Polarized LST-Stacked Amplitude, Phase, and Nsamples after Re-Inpainting](#Figure-2:-North-Polarized-LST-Stacked-Amplitude,-Phase,-and-Nsamples-after-Re-Inpainting)\n",
    "# [• Figure 3: Modified z-Score Across Nights, Before and After Re-Inpainting](#Figure-3:-Modified-z-Score-Across-Nights,-Before-and-After-Re-Inpainting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489012e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a13604-50e7-48e2-a4e4-24418e7a2b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import scipy\n",
    "import copy\n",
    "import toml\n",
    "from astropy import units\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "from pyuvdata import UVData\n",
    "from hera_cal import lst_stack, utils, io, flag_utils\n",
    "from hera_cal.lst_stack import calibration\n",
    "from hera_cal.frf import sky_frates, get_FR_buffer_from_spectra\n",
    "from hera_cal.lst_stack.binning import SingleBaselineStacker\n",
    "from hera_qm.time_series_metrics import true_stretches\n",
    "from hera_filters.dspec import fourier_filter, dpss_operator, sparse_linear_fit_2D\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "_ = np.seterr(all='ignore')  # get rid of red warnings\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4dcdc",
   "metadata": {},
   "source": [
    "## Parse Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272beeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_file = os.environ.get('TOML_FILE', '/lustre/aoc/projects/hera/h6c-analysis/IDR3/src/hera_pipelines/pipelines/h6c/idr3/v1/lstbin/single_bl_lst_stack.toml')\n",
    "print(f'toml_file = \"{toml_file}\"')\n",
    "\n",
    "baseline_string = os.environ.get('BASELINE_STRING', None)\n",
    "print(f'baseline_string = \"{baseline_string}\"')\n",
    "\n",
    "PRELIMINARY = (os.environ.get('PRELIMINARY', \"FALSE\").upper() == \"TRUE\")\n",
    "print(f'PRELIMINARY = {PRELIMINARY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6cd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get options from toml file, print them out, and update globals\n",
    "toml_options = toml.load(toml_file)\n",
    "\n",
    "print(f\"Now setting the following global variables from {toml_file}:\\n\")\n",
    "\n",
    "globals().update({'lst_branch_cut': toml_options['FILE_CFG']['lst_branch_cut']})\n",
    "print(f\"lst_branch_cut = {lst_branch_cut}\")\n",
    "\n",
    "globals().update({'where_inpainted_file_rules': toml_options['FILE_CFG']['where_inpainted_file_rules']})\n",
    "print(f\"where_inpainted_file_rules = {where_inpainted_file_rules}\")\n",
    "\n",
    "if PRELIMINARY:\n",
    "    # this is used for an initial stacking of a handful of baselines, which are then used for LSTCal\n",
    "    toml_options['LST_STACK_OPTS']['FNAME_FORMAT'] = toml_options['LST_STACK_OPTS']['FNAME_FORMAT'].replace('.sum.uvh5', '.preliminary.sum.uvh5')\n",
    "\n",
    "for key, val in toml_options['LSTCAL_OPTS'].items():\n",
    "    if isinstance(val, str):\n",
    "        print(f'{key} = \"{val}\"')\n",
    "    else:\n",
    "        print(f'{key} = {val}')\n",
    "globals().update(toml_options['LSTCAL_OPTS'])\n",
    "\n",
    "for key, val in toml_options['LST_STACK_OPTS'].items():\n",
    "    if isinstance(val, str):\n",
    "        print(f'{key} = \"{val}\"')\n",
    "    else:\n",
    "        print(f'{key} = {val}')\n",
    "globals().update(toml_options['LST_STACK_OPTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120710d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out outfiles\n",
    "OUTFILE = os.path.join(OUTDIR, FNAME_FORMAT.replace('{bl_str}', baseline_string))\n",
    "print(f'OUTFILE = \"{OUTFILE}\"')\n",
    "if FR0_FILTER:\n",
    "    FR0_FILT_OUTFILE = OUTFILE.replace('.uvh5', '.FR0filt.uvh5')\n",
    "    print(f'FR0_FILT_OUTFILE = \"{FR0_FILT_OUTFILE}\"')\n",
    "\n",
    "# if necessary, create the output directory\n",
    "if not os.path.exists(os.path.dirname(OUTFILE)):\n",
    "    os.makedirs(os.path.dirname(OUTFILE), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0d2f3f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d244a4-c274-4638-b534-cb7133d22196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build configurator from toml file\n",
    "configurator = lst_stack.config.LSTBinConfiguratorSingleBaseline.from_toml(toml_file)\n",
    "\n",
    "if not PRELIMINARY and USE_LSTCAL_GAINS:\n",
    "    configurator.build_visfile_to_calfile_map(\n",
    "        os.path.join(OUTDIR, LSTCAL_FNAME_FORMAT)\n",
    "    )\n",
    "    \n",
    "auto_baseline_string = [s for s in configurator.bl_to_file_map if (p := s.split('_'))[0] == p[1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0519fbab-bc5f-4679-8c32-cd740f5059c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get key data properties from a singe file\n",
    "hd = io.HERAData(configurator.bl_to_file_map[baseline_string][-1])\n",
    "\n",
    "df = np.median(np.diff(hd.freqs))\n",
    "dlst = np.median(np.diff(hd.lsts))\n",
    "lst_grid = lst_stack.config.make_lst_grid(dlst, begin_lst=0, lst_width=(2 * np.pi))\n",
    "lst_bin_edges =  np.concatenate([lst_grid - dlst / 2, (lst_grid[-1] + dlst / 2)[None]])\n",
    "\n",
    "low_band = slice(0, np.searchsorted(hd.freqs, FM_LOW_FREQ * 1e6))\n",
    "high_band = slice(np.searchsorted(hd.freqs, FM_HIGH_FREQ * 1e6), len(hd.freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load baseline we want to stack\n",
    "if not PRELIMINARY and USE_LSTCAL_GAINS:\n",
    "    cal_file_loader = calibration.load_single_baseline_lstcal_gains\n",
    "else:\n",
    "    cal_file_loader = None\n",
    "    \n",
    "crosses = SingleBaselineStacker.from_configurator(configurator,\n",
    "                                                  baseline_string,\n",
    "                                                  lst_bin_edges,\n",
    "                                                  lst_branch_cut=lst_branch_cut, \n",
    "                                                  where_inpainted_file_rules=where_inpainted_file_rules,\n",
    "                                                  cal_file_loader=cal_file_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffaea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load autocorrelations for weights\n",
    "autos = SingleBaselineStacker.from_configurator(configurator,\n",
    "                                                auto_baseline_string,\n",
    "                                                lst_bin_edges,\n",
    "                                                lst_branch_cut=lst_branch_cut,\n",
    "                                                to_keep_slice=crosses.slice_kept,\n",
    "                                                where_inpainted_file_rules=where_inpainted_file_rules,\n",
    "                                                cal_file_loader=cal_file_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bin_lsts to JD, starting with the first day \n",
    "lat, lon, alt = hd.telescope.location_lat_lon_alt_degrees\n",
    "bin_times = utils.LST2JD(crosses.bin_lst, int(crosses.times_in_bins[0][0]), allow_other_jd=True, latitude=lat, longitude=lon, altitude=alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5518dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average autocorrelations across nights\n",
    "avg_autos = [np.nanmean(np.where(af, np.nan, np.abs(ad)), axis=0) for af, ad in zip(autos.flags, autos.data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561b499",
   "metadata": {},
   "source": [
    "## Perform re-inpainting of data with high modified z-score relative to other nights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50751565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute modified z-scores across nights for each night \n",
    "mod_zs = []\n",
    "modz_const = 2**.5 * scipy.special.erfinv(.5)\n",
    "for d, f in list(zip(crosses.data, crosses.flags)):\n",
    "    ma = np.ma.array(d, mask=f)\n",
    "    med = np.ma.median(ma, axis=0, keepdims=True)\n",
    "    MAD = np.ma.median(np.abs(ma - med), axis=0, keepdims=True)\n",
    "    mod_zs.append(modz_const * (ma - med) / MAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2abd7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfrom fourier filtering with cached DPSS operators\n",
    "CACHE = {}\n",
    "def freq_filter(freqs, data, wgts, filter_half_widths=[INPAINT_DELAY * 1e-9], eigenval_cutoff=[EIGENVAL_CUTOFF]):\n",
    "    '''Thin wrapper around hera_filters.dspec.fourier_filter'''\n",
    "    return fourier_filter(freqs,\n",
    "                          data,\n",
    "                          wgts=wgts,\n",
    "                          filter_centers=[0],\n",
    "                          filter_half_widths=filter_half_widths,\n",
    "                          mode='dpss_solve',\n",
    "                          eigenval_cutoff=eigenval_cutoff,\n",
    "                          suppression_factors=eigenval_cutoff,\n",
    "                          max_contiguous_edge_flags=len(hd.freqs),\n",
    "                          filter_dims=1,\n",
    "                          cache_solver_products=False,\n",
    "                          cache=CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25235d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-inpaint inpainted data with high z-scores \n",
    "for d, f, n, aa, mod_z, wip in list(zip(crosses.data, crosses.flags, crosses.nsamples, avg_autos, mod_zs, crosses.where_inpainted)):\n",
    "    enough_nights = np.sum(~f, axis=0) >= MIN_NIGHTS_PER_BIN\n",
    "    f[:, ~enough_nights] = True  # flag bins with not enough nights\n",
    "    to_reip = np.zeros_like(f)\n",
    "    for pol in crosses.hd.pols:\n",
    "        pidx = crosses.hd.pols.index(pol)\n",
    "        # get indices for indexing into autocorrelations for weights\n",
    "        p1, p2 = utils.split_pol(pol)\n",
    "        pidx1 = crosses.hd.pols.index(utils.join_pol(p1, p1))\n",
    "        pidx2 = crosses.hd.pols.index(utils.join_pol(p2, p2))\n",
    "\n",
    "        for band in [low_band, high_band]:\n",
    "            for tidx in range(mod_z.shape[0]):\n",
    "                if np.any(wip[tidx, band, pidx] & \n",
    "                          (~f[tidx, band, pidx]) & \n",
    "                          enough_nights[band, pidx] &\n",
    "                          (np.abs(mod_z.data[tidx, band, pidx]) > MOD_Z_TO_REINPAINT)):\n",
    "                    to_reip[tidx, band, pidx] = True\n",
    "            if np.any(to_reip[:, band, pidx]):\n",
    "                # weighted average data across nights, excluding nights that are to be reinpainted\n",
    "                nights_with_reip = np.any(to_reip[:, band, pidx], axis=1)\n",
    "                if np.all(f[~nights_with_reip, band, pidx]):\n",
    "                    f[:, band, pidx] = True # there are no unflagged nights with consistently good z-scores, so flag the whole integration\n",
    "                    continue\n",
    "\n",
    "                avg_data_here = np.nansum(np.where(f[~nights_with_reip, band, pidx],  np.nan, \n",
    "                                                   d[~nights_with_reip, band, pidx] * n[~nights_with_reip, band, pidx]), axis=0)\n",
    "                avg_data_here /= np.sum(np.where(f[~nights_with_reip, band, pidx], 0, \n",
    "                                                 n[~nights_with_reip, band, pidx]), axis=0)\n",
    "\n",
    "                # fit that average with DPSS\n",
    "                samples_here = np.sum([n[tidx, band, pidx] * ~f[tidx, band, pidx] \n",
    "                                       for tidx in range(n.shape[0])], axis=0)\n",
    "                \n",
    "                wgts = np.where(~np.isfinite(avg_data_here), 0, aa[band, pidx1]**-1 * aa[band, pidx2]**-1 * samples_here)\n",
    "                avg_mdl, *_ = freq_filter(hd.freqs[band], np.where(~np.isfinite(avg_data_here), 0, avg_data_here), wgts=wgts)\n",
    "                \n",
    "                # perform re-inpainting with feathered weights\n",
    "                for tidx in range(d.shape[0]):\n",
    "                    if np.any(to_reip[tidx, band, pidx]):\n",
    "                        # figure out feathered weights\n",
    "                        distances = flag_utils.distance_to_nearest_nonzero(~wip[tidx, band, pidx])\n",
    "                        width = (1e-9 * INPAINT_DELAY)**-1 / df * INPAINT_WIDTH_FACTOR\n",
    "                        rel_weights = (1 + np.exp(-np.log(INPAINT_ZERO_DIST_WEIGHT**-1 - 1) / width * (distances - width)))**-1\n",
    "                        wgts_here = np.where(wip[tidx, band, pidx], wgts * rel_weights, wgts)\n",
    "                        \n",
    "                        # re-inpaint with DPSS\n",
    "                        to_fit = np.where(wip[tidx, band, pidx] | f[tidx, band, pidx], \n",
    "                                          avg_mdl, d[tidx, band, pidx])\n",
    "                        ts = true_stretches(wgts_here > 0)[0]\n",
    "                        assert len(true_stretches(wgts_here > 0)) == 1, \"Expected only one stretch of non-zero wgts_here\"\n",
    "                        reip_mdl = np.zeros_like(to_fit)\n",
    "                        reip_mdl[ts], *_ = freq_filter(hd.freqs[band][ts], to_fit[ts], wgts=wgts_here[ts])\n",
    "                        d[tidx, band, pidx] = np.where(wip[tidx, band, pidx], reip_mdl, d[tidx, band, pidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag channels that are too often flagged across nights\n",
    "fully_flagged = np.array([np.all(f, axis=0) for f in crosses.flags])\n",
    "for pidx in range(fully_flagged.shape[-1]):\n",
    "    for band in [low_band, high_band]:    \n",
    "        tslice = flag_utils.get_minimal_slices(fully_flagged[:, band, pidx])[0][0]\n",
    "        if tslice is not None:\n",
    "            too_often_flagged_chans = np.mean(fully_flagged[tslice, band, pidx], axis=0) > MAX_CHANNEL_NIGHTLY_FLAG_FRAC\n",
    "            for f in crosses.flags:\n",
    "                f[:, band, pidx] |= too_often_flagged_chans\n",
    "\n",
    "            # if the vast majority of the waterfall (typically defined by other pols) is flagged\n",
    "            if np.mean(fully_flagged[:, band, pidx]) > 0.95:\n",
    "                for f in crosses.flags:\n",
    "                    f[:, band, pidx] = True\n",
    "\n",
    "all_flagged = np.array([np.all(f, axis=0) for f in crosses.flags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35fa562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute summary statistics for modified z-scores, then delete them to save memory\n",
    "max_mod_z_before = np.where(all_flagged, np.nan, np.array([np.max(np.abs(mz), axis=0) for mz in mod_zs]))\n",
    "\n",
    "del mod_zs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaabd9bc",
   "metadata": {},
   "source": [
    "# Expaint band edges (i.e. use other nights to extrapolate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, f, n, aa, wip in list(zip(crosses.data, crosses.flags, crosses.nsamples, avg_autos, crosses.where_inpainted)):\n",
    "\n",
    "    for pol in crosses.hd.pols:\n",
    "        pidx = crosses.hd.pols.index(pol)\n",
    "        # get indices for indexing into autocorrelations for weights\n",
    "        p1, p2 = utils.split_pol(pol)\n",
    "        pidx1 = crosses.hd.pols.index(utils.join_pol(p1, p1))\n",
    "        pidx2 = crosses.hd.pols.index(utils.join_pol(p2, p2))\n",
    "\n",
    "        for band in [low_band, high_band]:\n",
    "            d_here, f_here, n_here = d[:, band, pidx], f[:, band, pidx], n[:, band, pidx]\n",
    "            if np.all(f_here):\n",
    "                continue\n",
    "\n",
    "            night_to_last_unflagged = {}\n",
    "            night_to_first_unflagged = {}\n",
    "            for tidx in range(f.shape[0]):\n",
    "                # if np.all(f[tidx, band, pidx]) or not np.any(f[tidx, band, pidx]):\n",
    "                if np.all(f[tidx, band, pidx]):\n",
    "                    continue\n",
    "                \n",
    "                # find the first and last unflagged channels on this night, for this band and pol\n",
    "                unflagged_here = ~f[tidx, band, pidx]\n",
    "                night_to_first_unflagged[tidx] = unflagged_here.argmax()\n",
    "                night_to_last_unflagged[tidx] = len(unflagged_here) - 1 - unflagged_here[::-1].argmax(axis=-1)\n",
    "\n",
    "            def _expaint_edge(to_fit_slice, nights_to_avg, tidx):\n",
    "                # average over nights with more data \n",
    "                avg_data = np.nansum(d_here[nights_to_avg, to_fit_slice] * n_here[nights_to_avg, to_fit_slice], axis=0)\n",
    "                avg_data /= np.sum(n_here[nights_to_avg, to_fit_slice], axis=0)\n",
    "                wgts = (aa[band, pidx1]**-1 * aa[band, pidx2]**-1)[to_fit_slice] # don't need nsamples, because it's flat\n",
    "                avg_mdl, *_ = freq_filter(hd.freqs[band][to_fit_slice], avg_data, wgts=wgts)\n",
    "\n",
    "                # perform re-inpainting with feathered weights\n",
    "                distances = flag_utils.distance_to_nearest_nonzero(~f_here[tidx, to_fit_slice])\n",
    "                width = (1e-9 * INPAINT_DELAY)**-1 / df * INPAINT_WIDTH_FACTOR\n",
    "                rel_weights = (1 + np.exp(-np.log(INPAINT_ZERO_DIST_WEIGHT**-1 - 1) / width * (distances - width)))**-1\n",
    "                wgts_here = np.where(f_here[tidx, to_fit_slice], wgts * rel_weights, wgts)\n",
    "\n",
    "                # re-inpaint with DPSS\n",
    "                to_fit = np.where(f_here[tidx, to_fit_slice], avg_mdl, d_here[tidx, to_fit_slice])\n",
    "                xp_mdl, *_ = freq_filter(hd.freqs[band][to_fit_slice], to_fit, wgts=wgts_here)\n",
    "                \n",
    "                # modify data, flags, and where_inpainted arrays in place\n",
    "                freq_indices = np.arange(len(hd.freqs))[band][to_fit_slice]\n",
    "                d[tidx, freq_indices, pidx] = np.where(f_here[tidx, to_fit_slice], xp_mdl, d_here[tidx, to_fit_slice])\n",
    "                f[tidx, freq_indices, pidx] = False\n",
    "                wip[tidx, freq_indices, pidx] = True\n",
    "\n",
    "            # first, perform ex-painting on the bottom of the band\n",
    "            sorted_nights = sorted(night_to_last_unflagged.keys(), key=lambda x: night_to_last_unflagged[x], reverse=True)\n",
    "            target_last_unflagged = night_to_last_unflagged[sorted_nights[0]]\n",
    "            for i, tidx in enumerate(sorted_nights):\n",
    "                if night_to_last_unflagged[tidx] == target_last_unflagged:\n",
    "                    continue  # no additional extrapolation necessary\n",
    "                \n",
    "                # figure out which channels to fit on this particular night to get a good model to expaint with\n",
    "                Nchans_to_fit = (target_last_unflagged - night_to_last_unflagged[tidx])\n",
    "                if Nchans_to_fit < (2 / (INPAINT_DELAY * 1e-9) / df):\n",
    "                    Nchans_to_fit += int(np.ceil(2 / (INPAINT_DELAY * 1e-9) / df))\n",
    "                else:\n",
    "                    Nchans_to_fit *= 2\n",
    "                to_fit_slice = slice(target_last_unflagged - Nchans_to_fit + 1, target_last_unflagged + 1)\n",
    "                \n",
    "                _expaint_edge(to_fit_slice, sorted_nights[:i], tidx)\n",
    "\n",
    "            # now, perform ex-painting on the top of the band\n",
    "            sorted_nights = sorted(night_to_first_unflagged.keys(), key=lambda x: night_to_first_unflagged[x])\n",
    "            target_first_unflagged = night_to_first_unflagged[sorted_nights[0]]\n",
    "            for i, tidx in enumerate(sorted_nights):\n",
    "                if night_to_first_unflagged[tidx] == target_first_unflagged:\n",
    "                    continue  # no additional extrapolation necessary\n",
    "                \n",
    "                # figure out which channels to fit on this particular night to get a good model to expaint with\n",
    "                Nchans_to_fit = (night_to_first_unflagged[tidx] - target_first_unflagged)\n",
    "                if Nchans_to_fit < (2 / (INPAINT_DELAY * 1e-9) / df):\n",
    "                    Nchans_to_fit += int(np.ceil(2 / (INPAINT_DELAY * 1e-9) / df))\n",
    "                else:\n",
    "                    Nchans_to_fit *= 2\n",
    "                to_fit_slice = slice(target_first_unflagged, target_first_unflagged + Nchans_to_fit)\n",
    "                \n",
    "                _expaint_edge(to_fit_slice, sorted_nights[:i], tidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e2213",
   "metadata": {},
   "source": [
    "# 2D-informed expainting to get even band edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FR_CENTER_AND_HW_CACHE = {}\n",
    "\n",
    "def cache_fr_center_and_hw(hd, antpair, tslice, band):\n",
    "    '''Figure out the range of FRs in Hz spanned for a given band and tslice, buffered by the size of the autocorrelation FR kernel,\n",
    "    and stores the value in FR_CENTER_AND_HW_CACHE (if it hasn't already been computed.'''\n",
    "    if (tslice is not None) and (band is not None) and ((antpair, tslice, band) not in FR_CENTER_AND_HW_CACHE):\n",
    "        # calculate fringe rate center and half-width and then update cache\n",
    "        fr_buffer = get_FR_buffer_from_spectra(AUTO_FR_SPECTRUM_FILE, hd.times[tslice], hd.freqs[band],\n",
    "                                               gauss_fit_buffer_cut=GAUSS_FIT_BUFFER_CUT)\n",
    "        hd_here = hd.select(inplace=False, frequencies=hd.freqs[band])\n",
    "        fr_center = list(sky_frates(hd_here)[0].values())[0] / 1e3  # converts to Hz\n",
    "        fr_hw = (list(sky_frates(hd_here)[1].values())[0] + fr_buffer) / 1e3\n",
    "        FR_CENTER_AND_HW_CACHE[(antpair, tslice, band)] = fr_center, fr_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_2D_DPSS(data, weights, filter_delay, tslices, bands, **kwargs):\n",
    "    '''Fit a 2D DPSS model to all the baselines in data. The time-dimension is based on sky FRs\n",
    "    and the FR spectrum of the autos. fr_centers and fr_hws are drawn from FR_CENTER_AND_HW_CACHE.\n",
    "    \n",
    "    Arguments:\n",
    "        data: datacontainer mapping baselines to complex visibility waterfalls\n",
    "        weights: datacontainer mapping baselines to real weight waterfalls. \n",
    "        filter_delay: maximum delay in ns for the 2D filter\n",
    "        tslices: dictionary mapping bl to time slices corresponding to low and high bands\n",
    "        bands: dictionary mapping bl to low band and high band frequency slices\n",
    "        kwargs: kwargs to pass into sparse_linear_fit_2D()\n",
    "    \n",
    "    Returns:\n",
    "        dpss_fit: datacontainer mapping baselines to 2D DPSS models\n",
    "    '''\n",
    "    dpss_fit = copy.deepcopy(data)\n",
    "    for bl in data.keys():\n",
    "        # set to all nans by default\n",
    "        dpss_fit[bl] *= np.nan\n",
    "\n",
    "        for tslice, band in zip(tslices[bl], bands[bl]):\n",
    "            if (tslice is None) or (band is None) or np.all(weights[bl][tslice, band] == 0):\n",
    "                continue\n",
    "\n",
    "            # perform 2D DPSS filter\n",
    "            fr_center, fr_hw = FR_CENTER_AND_HW_CACHE[(bl[0:2], tslice, band)]\n",
    "            time_filters, _ = dpss_operator((data.times[tslice] - data.times[tslice][0]) * 3600 * 24, \n",
    "                                            [fr_center], [fr_hw], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            freq_filters, _ = dpss_operator(data.freqs[band], [0.0], [filter_delay / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            \n",
    "            fit, meta = sparse_linear_fit_2D(\n",
    "                data=data[bl][tslice, band],\n",
    "                weights=weights[bl][tslice, band],\n",
    "                axis_1_basis=time_filters,\n",
    "                axis_2_basis=freq_filters,\n",
    "                precondition_solver=True,\n",
    "                iter_lim=CG_ITER_LIM,\n",
    "                **kwargs,\n",
    "            )\n",
    "            dpss_fit[bl][tslice, band] = time_filters.dot(fit).dot(freq_filters.T)\n",
    "            \n",
    "    return dpss_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54883210",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnights_unflagged = np.array([np.sum((~f[:, :, :]).astype(float), axis=0) for f in crosses.flags])\n",
    "ntimes_unflagged = np.sum(nnights_unflagged, axis=0)\n",
    "\n",
    "# perfrom feathered ex-painting on all pols, bands (top and bottom), and nights\n",
    "for pol in crosses.hd.pols:\n",
    "    pidx = crosses.hd.pols.index(pol)\n",
    "    # get indices for indexing into autocorrelations for weights\n",
    "    p1, p2 = utils.split_pol(pol)\n",
    "    pidx1 = crosses.hd.pols.index(utils.join_pol(p1, p1))\n",
    "    pidx2 = crosses.hd.pols.index(utils.join_pol(p2, p2))\n",
    "\n",
    "    for band in [low_band, high_band]:\n",
    "        # find the range of frequencies that could need explainting\n",
    "        max_unflagged = np.max(ntimes_unflagged[band, pidx])\n",
    "        if max_unflagged == 0:\n",
    "            continue\n",
    "        first_unflagged_channel = np.where(ntimes_unflagged[band, pidx] > 0)[0][0]\n",
    "        first_minimally_flagged_channel = np.where(ntimes_unflagged[band, pidx] == max_unflagged)[0][0]\n",
    "        last_minimally_flagged_channel = np.where(ntimes_unflagged[band, pidx] == max_unflagged)[0][-1]\n",
    "        last_unflagged_channel = np.where(ntimes_unflagged[band, pidx] > 0)[0][-1]\n",
    "\n",
    "        tslice = flag_utils.get_minimal_slices(nnights_unflagged[:, band, pidx] == 0)[0][0]\n",
    "\n",
    "        def _expaint_2D(fslice):\n",
    "            '''Fits a 2D DPSS model to the data we do have, then performs feathered ex-painting'''\n",
    "            cache_fr_center_and_hw(hd, hd.antpairs[0], tslice, fslice)\n",
    "\n",
    "            data_here = np.array([np.nansum(np.where(f[:, fslice, pidx], np.nan, \n",
    "                                                    d[:, fslice, pidx] * n[:, fslice, pidx]), axis=0)\n",
    "                                            for d, f, n in zip(crosses.data, crosses.flags, crosses.nsamples)])[tslice]\n",
    "            nsamples_here = np.array([np.sum(n[:, fslice, pidx] * ~f[:, fslice, pidx], axis=0)\n",
    "                                    for f, n in zip(crosses.flags, crosses.nsamples)])[tslice]\n",
    "            data_here = np.where(nsamples_here > 0, data_here / nsamples_here, 0.0)\n",
    "            wgts_here = np.array([aa[fslice, pidx1]**-1 * aa[fslice, pidx2]**-1 for aa in avg_autos])[tslice] * nsamples_here\n",
    "            wgts_here = np.where(np.isfinite(wgts_here), wgts_here, 0.0)\n",
    "\n",
    "            # perform 2D DPSS filter\n",
    "            fr_center, fr_hw = FR_CENTER_AND_HW_CACHE[(hd.antpairs[0], tslice, fslice)]\n",
    "            time_filters, _ = dpss_operator((bin_times[tslice] - bin_times[tslice][0]) * 3600 * 24, \n",
    "                                            [fr_center], [fr_hw], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            freq_filters, _ = dpss_operator(hd.freqs[fslice], [0.0], [INPAINT_DELAY / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            fit, meta = sparse_linear_fit_2D(data=data_here, weights=wgts_here, precondition_solver=True,\n",
    "                                            axis_1_basis=time_filters, axis_2_basis=freq_filters,\n",
    "                                            iter_lim=CG_ITER_LIM, atol=CG_TOL, btol=CG_TOL)\n",
    "            dpss_fit = time_filters.dot(fit).dot(freq_filters.T)\n",
    "\n",
    "            # perform feathered expainting on a per LST and per night basis\n",
    "            for lidx, (d, f, aa, wip) in list(enumerate(zip(crosses.data, crosses.flags, avg_autos, crosses.where_inpainted)))[tslice]:\n",
    "                for tidx in range(d.shape[0]):\n",
    "                    if np.any(f[tidx, fslice, pidx]) and not np.all(f[tidx, fslice, pidx]):\n",
    "                        wgts = aa[fslice, pidx1]**-1 * aa[fslice, pidx2]**-1 # don't need nsamples, because it's flat\n",
    "                        wgts[~np.isfinite(wgts)] = np.min(wgts[np.isfinite(wgts)]) # handle case where we're expainting beyond autos\n",
    "                        distances = flag_utils.distance_to_nearest_nonzero(~f[tidx, fslice, pidx])\n",
    "                        width = (1e-9 * INPAINT_DELAY)**-1 / df * INPAINT_WIDTH_FACTOR\n",
    "                        rel_weights = (1 + np.exp(-np.log(INPAINT_ZERO_DIST_WEIGHT**-1 - 1) / width * (distances - width)))**-1\n",
    "\n",
    "                        to_fit = np.where(f[tidx, fslice, pidx], dpss_fit[lidx - tslice.start], d[tidx, fslice, pidx])\n",
    "                        wgts = np.where(f[tidx, fslice, pidx], wgts * rel_weights, wgts)\n",
    "                        xp_mdl, *_ = freq_filter(hd.freqs[fslice], to_fit, wgts=wgts)\n",
    "\n",
    "                        # modify data, flags, and where_inpainted arrays in place\n",
    "                        d[tidx, fslice, pidx] = np.where(f[tidx, fslice, pidx], xp_mdl, d[tidx, fslice, pidx])\n",
    "                        wip[tidx, fslice, pidx] = np.where(f[tidx, fslice, pidx], True, wip[tidx, fslice, pidx])\n",
    "                        f[tidx, fslice, pidx] = False\n",
    "            \n",
    "        if first_unflagged_channel < first_minimally_flagged_channel:\n",
    "            Nchans_to_fit = first_minimally_flagged_channel - first_unflagged_channel\n",
    "            if Nchans_to_fit < (2 / (INPAINT_DELAY * 1e-9) / df):\n",
    "                Nchans_to_fit += int(np.ceil(2 / (INPAINT_DELAY * 1e-9) / df))\n",
    "            else:\n",
    "                Nchans_to_fit *= 2\n",
    "            fslice = slice(band.start + first_unflagged_channel,\n",
    "                           min(band.start + first_unflagged_channel + Nchans_to_fit, band.stop))\n",
    "            _expaint_2D(fslice)\n",
    "\n",
    "        if last_minimally_flagged_channel < last_unflagged_channel:\n",
    "            Nchans_to_fit = last_unflagged_channel - last_minimally_flagged_channel\n",
    "            if Nchans_to_fit < (2 / (INPAINT_DELAY * 1e-9) / df):\n",
    "                Nchans_to_fit += int(np.ceil(2 / (INPAINT_DELAY * 1e-9) / df))\n",
    "            else:\n",
    "                Nchans_to_fit *= 2\n",
    "            fslice = slice(max(band.start + last_unflagged_channel + 1 - Nchans_to_fit, band.start),\n",
    "                                     band.start + last_unflagged_channel + 1)\n",
    "            _expaint_2D(fslice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64262b3",
   "metadata": {},
   "source": [
    "# Now Actually Average Over Nights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad880c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_avg_data, lst_avg_flags, lst_avg_nsamples = crosses.average_over_nights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1935c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_avg_auto_data, lst_avg_auto_flags, lst_avg_auto_nsamples = autos.average_over_nights(inpainted_data_are_samples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_zs_after = []\n",
    "modz_const = 2**.5 * scipy.special.erfinv(.5)\n",
    "for d, f in list(zip(crosses.data, crosses.flags)):\n",
    "    ma = np.ma.array(d, mask=f)\n",
    "    med = np.ma.median(ma, axis=0, keepdims=True)\n",
    "    MAD = np.ma.median(np.abs(ma - med), axis=0, keepdims=True)\n",
    "    mod_zs_after.append(modz_const * (ma - med) / MAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute summary statistics for modified z-scores after re-inpainting, then delete them to save memory\n",
    "max_mod_z_after = np.where(lst_avg_flags, np.nan, np.array([np.max(np.abs(mz), axis=0) for mz in mod_zs_after]))\n",
    "\n",
    "del mod_zs_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f38476",
   "metadata": {},
   "source": [
    "## FR=0 Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute 2D DPSS smooth autocorrelations to use for weighting without introducing spectral structure\n",
    "if FR0_FILTER:\n",
    "    filtered_autos = np.full_like(lst_avg_auto_data, np.nan)\n",
    "\n",
    "    for pol in ['ee', 'nn']:\n",
    "        pidx = autos.hd.pols.index(pol)\n",
    "        tslices, fslices = flag_utils.get_minimal_slices(lst_avg_flags[:, :, pidx], freqs=autos.hd.freqs, freq_cuts=[(FM_HIGH_FREQ + FM_LOW_FREQ) * .5e6])\n",
    "        for tslice, fslice in zip(tslices, fslices):\n",
    "            if (tslice is None) or (fslice is None):\n",
    "                continue\n",
    "            cache_fr_center_and_hw(autos.hd, autos.hd.antpairs[0], tslice, fslice)\n",
    "\n",
    "            autos_here = lst_avg_auto_data[tslice, fslice, pidx]\n",
    "            nsamples_here = lst_avg_auto_nsamples[tslice, fslice, pidx]\n",
    "            weights_here = autos_here**-2 * nsamples_here\n",
    "            fr_center, fr_hw = FR_CENTER_AND_HW_CACHE[(autos.hd.antpairs[0], tslice, fslice)]\n",
    "            time_filters, _ = dpss_operator((bin_times[tslice] - bin_times[tslice][0]) * 3600 * 24, \n",
    "                                            [fr_center], [fr_hw], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            freq_filters, _ = dpss_operator(autos.hd.freqs[fslice], [0.0], [AUTO_INPAINT_DELAY / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            fit, meta = sparse_linear_fit_2D(data=autos_here, weights=weights_here, precondition_solver=True,\n",
    "                                            axis_1_basis=time_filters, axis_2_basis=freq_filters,\n",
    "                                            iter_lim=CG_ITER_LIM, atol=CG_TOL, btol=CG_TOL)\n",
    "            dpss_fit = time_filters.dot(fit).dot(freq_filters.T)\n",
    "\n",
    "            filtered_autos[tslice, fslice, pidx] = np.abs(dpss_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform FR=0 filter on crosses on a per-night basis\n",
    "if FR0_FILTER:\n",
    "    for jd in [int(jd) for jd in crosses.configurator.nights]:\n",
    "        data_here, flags_here, nsamples_here, tindices = [], [], [], []  \n",
    "        for d, f, n, tib in zip(crosses.data, crosses.flags, crosses.nsamples, crosses.times_in_bins):\n",
    "            # find the indices of the times that are in this JD\n",
    "            tidx = np.argwhere(np.floor(tib).astype(int) == jd)\n",
    "            if len(tidx) > 0:\n",
    "                data_here.append(np.where(f[tidx[0][0]], np.nan, d[tidx[0][0]]))\n",
    "                flags_here.append(f[tidx[0][0]])\n",
    "                nsamples_here.append(n[tidx[0][0]])\n",
    "                tindices.append(tidx[0][0])\n",
    "            else:\n",
    "                data_here.append(np.full(d[0].shape, np.nan))\n",
    "                flags_here.append(np.full(f[0].shape, True))\n",
    "                nsamples_here.append(np.zeros_like(n[0]))\n",
    "                tindices.append(None)\n",
    "\n",
    "        data_here, flags_here, nsamples_here = np.array(data_here), np.array(flags_here), np.array(nsamples_here)\n",
    "\n",
    "        for pol in crosses.hd.pols:\n",
    "            pidx = crosses.hd.pols.index(pol)\n",
    "            # get indices for indexing into autocorrelations for weights\n",
    "            p1, p2 = utils.split_pol(pol)\n",
    "            pidx1 = crosses.hd.pols.index(utils.join_pol(p1, p1))\n",
    "            pidx2 = crosses.hd.pols.index(utils.join_pol(p2, p2))\n",
    "            weights_here = np.where(flags_here[:, :, pidx] | ~np.isfinite(filtered_autos[:, :, pidx1]) | ~np.isfinite(filtered_autos[:, :, pidx2]),\n",
    "                                    0, nsamples_here[:, :, pidx] * filtered_autos[:, :, pidx1]**-1 * filtered_autos[:, :, pidx2]**-1)\n",
    "\n",
    "            tslices, fslices = flag_utils.get_minimal_slices(flags_here[:, :, pidx], freqs=autos.hd.freqs, freq_cuts=[(FM_HIGH_FREQ + FM_LOW_FREQ) * .5e6])\n",
    "            for tslice, fslice in zip(tslices, fslices):\n",
    "                if (tslice is None) or (fslice is None):\n",
    "                    continue\n",
    "                d_mdl, _, info = fourier_filter(bin_times[tslice] * 24 * 60 * 60, \n",
    "                                                np.where(weights_here[tslice, fslice] == 0, 0, data_here[tslice, fslice, pidx]),\n",
    "                                                wgts=weights_here[tslice, fslice],\n",
    "                                                filter_centers=[0],\n",
    "                                                filter_half_widths=[FR0_HALFWIDTH / 1000],\n",
    "                                                mode='dpss_solve',\n",
    "                                                eigenval_cutoff=[EIGENVAL_CUTOFF],\n",
    "                                                suppression_factors=[EIGENVAL_CUTOFF],\n",
    "                                                max_contiguous_edge_flags=len(bin_times[tslice]),\n",
    "                                                filter_dims=0)\n",
    "                data_here[tslice, fslice, pidx] -= d_mdl\n",
    "        \n",
    "        # update data in crosses\n",
    "        for d, d_filt, tidx in zip(crosses.data, data_here, tindices):\n",
    "            if tidx is not None:\n",
    "                d[tidx, :, :] = d_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5353a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FR0_FILTER:\n",
    "    lst_avg_fr0_filt_data, _, _ = crosses.average_over_nights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10ae93",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waterfall(data, flags, nsamples, freqs, lsts, bl_label):\n",
    "    '''Plots data (amplitude and phase) as well as nsamples waterfalls for a baseline.'''\n",
    "\n",
    "    if np.all(flags):\n",
    "        print('This waterfall is entirely flagged. Nothing to plot.')\n",
    "        return\n",
    "    \n",
    "    lsts_in_hours = np.where(lsts > lsts[-1], lsts - 2 * np.pi, lsts * 12 / np.pi)\n",
    "    extent = [freqs[0]/1e6, freqs[-1]/1e6, lsts_in_hours[-1], lsts_in_hours[0]]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 12), sharex=True, sharey=True, gridspec_kw={'wspace': 0}, dpi=100)\n",
    "    im = axes[0].imshow(np.where(flags, np.nan, np.abs(data)), aspect='auto', norm=matplotlib.colors.LogNorm(), interpolation='none', cmap='inferno', extent=extent)\n",
    "    fig.colorbar(im, ax=axes[0], location='top', pad=.02).set_label(f'{bl_label}: Amplitude (Jy)', fontsize=16)\n",
    "\n",
    "    im = axes[1].imshow(np.where(flags, np.nan, np.angle(data)), aspect='auto', cmap='twilight', interpolation='none', extent=extent)\n",
    "    fig.colorbar(im, ax=axes[1], location='top', pad=.02).set_label(f'{bl_label}: Phase (Radians)', fontsize=16)\n",
    "\n",
    "    im = axes[2].imshow(np.where(flags, np.nan, nsamples), aspect='auto', interpolation='none', extent=extent)\n",
    "    fig.colorbar(im, ax=axes[2], location='top', pad=.02).set_label(f'{bl_label}: Number of Samples', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    axes[0].set_ylabel('LST (hours)')\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('Frequency (MHz)')\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            ax.set_yticklabels([f'{(int(val) if np.isclose(val, int(val)) else val) % 24:n}' for val in ax.get_yticks()])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb3951",
   "metadata": {},
   "source": [
    "# Figure 1: East-Polarized LST-Stacked Amplitude, Phase, and Nsamples after Re-Inpainting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1afbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pidx = hd.pols.index('ee')\n",
    "plot_waterfall(lst_avg_data[:, :, pidx], lst_avg_flags[:, :, pidx], lst_avg_nsamples[:, :, pidx], \n",
    "               hd.freqs, crosses.bin_lst, crosses.hd.antpairs[0] + ('ee',))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a833548",
   "metadata": {},
   "source": [
    "# Figure 2: North-Polarized LST-Stacked Amplitude, Phase, and Nsamples after Re-Inpainting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pidx = hd.pols.index('nn')\n",
    "plot_waterfall(lst_avg_data[:, :, pidx], lst_avg_flags[:, :, pidx], lst_avg_nsamples[:, :, pidx], \n",
    "               hd.freqs, crosses.bin_lst, crosses.hd.antpairs[0] + ('nn',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_max_mod_zs(max_mod_z_before, max_mod_z_after, hd, freqs, lsts, antpair):\n",
    "    '''Compares the maximum modified z-scores before and after re-inpainting for both polarizations.'''\n",
    "    lsts_in_hours = np.where(lsts > lsts[-1], lsts - 2 * np.pi, lsts * 12 / np.pi)\n",
    "    extent = [freqs[0]/1e6, freqs[-1]/1e6, lsts_in_hours[-1], lsts_in_hours[0]]\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 12), sharex=True, sharey=True, gridspec_kw={'wspace': 0}, dpi=100)\n",
    "    \n",
    "    for i, pol in enumerate(['ee', 'nn']):\n",
    "        pidx = hd.pols.index(pol)\n",
    "        im = axes[2 * i].imshow(max_mod_z_before[:, :, pidx], aspect='auto', interpolation='none', vmin=0, vmax=MOD_Z_TO_REINPAINT * 1.5, extent=extent)\n",
    "        axes[2 * i + 1].imshow(max_mod_z_after[:, :, pidx], aspect='auto', interpolation='none', vmin=0, vmax=MOD_Z_TO_REINPAINT * 1.5, extent=extent)\n",
    "    \n",
    "        # put label in top left corner that says polarization and before or after\n",
    "        axes[2 * i].text(0.02, 0.99, f'{pol} Before', transform=axes[2 * i].transAxes, ha='left', va='top', fontsize=12, bbox=dict(facecolor='white', alpha=0.5, boxstyle='round'))\n",
    "        axes[2 * i + 1].text(0.02, 0.99, f'{pol} After', transform=axes[2 * i + 1].transAxes, ha='left', va='top', fontsize=12, bbox=dict(facecolor='white', alpha=0.5, boxstyle='round'))\n",
    "\n",
    "    axes[0].set_ylabel('LST (Hours)')\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('Frequency (MHz)')\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            ax.set_yticklabels([f'{(int(val) if np.isclose(val, int(val)) else val) % 24:n}' for val in ax.get_yticks()])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # add colorbar with size 16 label\n",
    "    cbar = plt.colorbar(im, ax=axes, location='top', pad=.02, aspect=50, extend='max')\n",
    "    cbar.set_label(f'{antpair}: Maximum Modified z-Score Across Nights (unitless)', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6608a3",
   "metadata": {},
   "source": [
    "# Figure 3: Modified z-Score Across Nights, Before and After Re-Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ae349",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_max_mod_zs(max_mod_z_before, max_mod_z_after, crosses.hd, crosses.hd.freqs, crosses.bin_lst, crosses.hd.antpairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60217e",
   "metadata": {},
   "source": [
    "### TODO: Add additional visualizations, including:\n",
    "* Examine $z^2$ score across nights (not modified), then average along freq and/or time to look for outlier nights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5429b",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_history = 'This file was produced by single_baseline_lst_stack_and_reinpaint.ipynb notebook.\\n'\n",
    "add_to_history += 'The following conda environment was used:\\n' + '=' * 65 + '\\n' + os.popen('conda env export').read() + '=' * 65 + '\\n'\n",
    "add_to_history += f'The toml file {toml_file} was used:\\n' + '=' * 65 + '\\n' + toml.dumps(toml_options) + '=' * 65 + '\\n'\n",
    "add_to_history += 'The following files were stacked:\\n' + '=' * 65 + '\\n' + '\\n'.join(configurator.bl_to_file_map[baseline_string]) + '\\n' + '=' * 65 + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_lst_avg_data(outfile, data, flags, nsamples):\n",
    "    '''Create a new UVData object using metadata from the first night.'''\n",
    "    uvd = UVData.new(freq_array=crosses.hd.freq_array,\n",
    "                    polarization_array=[utils.polstr2num(p, x_orientation=crosses.hd.telescope.get_x_orientation_from_feeds())\n",
    "                                        for p in crosses.hd.pols],\n",
    "                    times=bin_times,\n",
    "                    telescope=crosses.hd.telescope,\n",
    "                    antpairs=crosses.hd.antpairs,\n",
    "                    vis_units=crosses.hd.vis_units,\n",
    "                    empty=True)\n",
    "    uvd.data_array = data\n",
    "    uvd.flag_array = flags\n",
    "    uvd.nsample_array = nsamples\n",
    "    uvd.history = add_to_history + uvd.history\n",
    "    uvd.write_uvh5(outfile, clobber=True)\n",
    "\n",
    "    return uvd\n",
    "\n",
    "# write the lst-stacked and averaged data to a uvh5 file\n",
    "uvd = _write_lst_avg_data(OUTFILE, lst_avg_data, lst_avg_flags, lst_avg_nsamples)\n",
    "if FR0_FILTER:\n",
    "    _write_lst_avg_data(FR0_FILT_OUTFILE, lst_avg_fr0_filt_data, lst_avg_flags, lst_avg_nsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682cee74",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e268c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata', 'numpy']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f3a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redundant Calibration Nightly Data Quality Notebook\n",
    "\n",
    "**Josh Dillon**, Last Revised 10/25/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:46:50.399862Z",
     "start_time": "2020-10-25T03:46:50.370944Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from hera_cal import io, redcal, apply_cal\n",
    "from hera_qm.metrics_io import load_metric_file\n",
    "import glob\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import inspect\n",
    "import h5py\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:46:50.541801Z",
     "start_time": "2020-10-25T03:46:50.536217Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you want to run this notebook locally, copy the output of the next cell into the first few lines of this cell.\n",
    "\n",
    "# JD = \"2459117\"\n",
    "# data_path = '/lustre/aoc/projects/hera/H4C/2459117'\n",
    "# ant_metrics_ext = \".maybe_good.ant_metrics.hdf5\"\n",
    "# prefix = \".maybe_good\"\n",
    "# os.environ[\"JULIANDATE\"] = JD\n",
    "# os.environ[\"DATA_PATH\"] = data_path\n",
    "# os.environ[\"ANT_METRICS_EXT\"] = ant_metrics_ext\n",
    "# os.environ[\"OMNI_PREFIX\"] = prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:46:50.704067Z",
     "start_time": "2020-10-25T03:46:50.697009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use environment variables to figure out path to data\n",
    "JD = os.environ['JULIANDATE']\n",
    "data_path = os.environ['DATA_PATH']\n",
    "ant_metrics_ext = os.environ['ANT_METRICS_EXT']\n",
    "try: \n",
    "    prefix = os.environ[\"OMNI_PREFIX\"]\n",
    "except:\n",
    "    prefix = ant_metrics_ext.replace('.ant_metrics.hdf5', '')\n",
    "print(f'JD = \"{JD}\"')\n",
    "print(f'data_path = \"{data_path}\"')\n",
    "print(f'ant_metrics_ext = \"{ant_metrics_ext}\"')\n",
    "print(f'prefix = \"{prefix}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:46:52.587417Z",
     "start_time": "2020-10-25T03:46:51.663274Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Looking for data in', data_path, 'on JD', JD)\n",
    "data_list = sorted(glob.glob(os.path.join(data_path, 'zen.{}.?????.sum.uvh5'.format(JD))))\n",
    "if len(data_list) == 0:\n",
    "    data_list = sorted(glob.glob(os.path.join(data_path, 'zen.{}.?????.uvh5'.format(JD))))\n",
    "print('Found {} data files.'.format(len(data_list)))\n",
    "\n",
    "# If only a subset of the data files have redcal run on them, then only look at those files\n",
    "data_list = [df for df in data_list if os.path.exists(df.replace('.uvh5', f'{prefix}.omni.calfits'))]\n",
    "print('Found {} data files with corresponding redcal solutions.'.format(len(data_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:46:54.481156Z",
     "start_time": "2020-10-25T03:46:54.475608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick middle of the night data file to examine\n",
    "example_file = data_list[len(data_list)//2]\n",
    "file_JD = '.'.join([s for s in example_file.split('.') if s.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:47:00.658715Z",
     "start_time": "2020-10-25T03:47:00.655163Z"
    }
   },
   "outputs": [],
   "source": [
    "# controls how many redundant baseline groups to plot. \n",
    "# 2 means the most common ee- and nn-polarized baseline.\n",
    "n_reds_to_plot = 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:47:05.784937Z",
     "start_time": "2020-10-25T03:47:01.553208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load omnical gains and determine ex_ants\n",
    "hc = io.HERACal(example_file.replace('.uvh5', f'{prefix}.omni.calfits'))\n",
    "gains, gain_flags, _, _ = hc.read()\n",
    "ex_ants = [ant for ant in gain_flags if np.all(gain_flags[ant])]\n",
    "\n",
    "# Load the most common redundant baselines and calibrate\n",
    "hd = io.HERAData(example_file)\n",
    "reds = redcal.get_reds({ant: hd.antpos[ant] for ant in hd.data_ants}, pols=['ee', 'nn'])\n",
    "red_bl_map = {bl: red[0] for red in reds for bl in red} \n",
    "reds = redcal.filter_reds(reds, ex_ants=ex_ants)\n",
    "reds = sorted(reds, key=len, reverse=True)\n",
    "data, flags, nsamples = hd.read(\n",
    "    bls=[bl for red in reds[0:n_reds_to_plot] for bl in red])\n",
    "apply_cal.calibrate_in_place(data, gains, data_flags=flags, cal_flags=gain_flags)\n",
    "\n",
    "# Load omnical visibility solutions\n",
    "hdo = io.HERAData(example_file.replace('.uvh5', f'{prefix}.omni_vis.uvh5'))\n",
    "omni_data, omni_flags, omni_nsamples = hdo.read(\n",
    "    bls=[red_bl_map[red[0]] for red in reds[0:n_reds_to_plot]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:47:08.266744Z",
     "start_time": "2020-10-25T03:47:07.382929Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(np.array([hd.antpos[ant][0] for ant in hd.data_ants]), \n",
    "            np.array([hd.antpos[ant][1] for ant in hd.data_ants]), c='w', s=0)\n",
    "for ant in hd.data_ants:\n",
    "    pos = hd.antpos[ant]\n",
    "    bad = ant in [ant[0] for ant in ex_ants]\n",
    "    plt.gca().add_artist(plt.Circle(tuple(pos[0:2]), radius=7, \n",
    "                                    fill=(~bad), color=['grey','r'][bad]))\n",
    "    plt.text(pos[0],pos[1],str(ant), va='center', ha='center', color='w')\n",
    "plt.xlabel(\"Antenna East-West Position (meters)\")\n",
    "plt.ylabel(\"Antenna North-South Position (meters)\")\n",
    "plt.title('Antenna Positions on {} (Red = Flagged)'.format(file_JD));\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: Array and Flagged Antennas\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Check that the array configuration looks reasonable.\n",
    "* Check that all flags expected to be flagged are actually flagged but also that not everything is getting flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:47:13.070357Z",
     "start_time": "2020-10-25T03:47:09.768380Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot redundant groups\n",
    "for red in reds[0:n_reds_to_plot]:\n",
    "    blvec = hd.antpos[red[0][1]] - hd.antpos[red[0][0]]\n",
    "    for func, plot, ylabel in zip([np.abs, np.angle], [plt.semilogy, plt.plot], ['Amplitude (Arbitrary Units)', 'Phase (Radians)']):\n",
    "        plt.figure(figsize=(16,4))\n",
    "        for bl in red:\n",
    "            plot(hd.freqs/1e6, func(np.median(data[bl], axis=0)))\n",
    "        plot(hd.freqs/1e6, func(np.median(omni_data[red_bl_map[red[0]]], axis=0)), 'k-', label='Omnical Visibility Solution')\n",
    "        plt.xlabel('Frequency (MHz)')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title('{}-Polarized, {:f} m East, {:f} m North Visibility on {}'.format(red[0][2], blvec[0], blvec[1], file_JD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: Example redundant baseline groups and omnical visibility solution for a single file.\n",
    "\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Check that that there actually is something plotted and the data isn't all flagged somehow.\n",
    "* Check whether most of the baselines cluster together and that the black line follows the cluster.\n",
    "* Check whether there are any significant outliers (though it won't be clear as yet which antennas those are attributable to, see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Whole Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:48:39.241020Z",
     "start_time": "2020-10-25T03:47:16.922374Z"
    }
   },
   "outputs": [],
   "source": [
    "# load all redcal metadata into dictionaries \n",
    "ee_iters_dict = {}\n",
    "nn_iters_dict = {}\n",
    "dlys_dict = {}\n",
    "flips_dict = {}\n",
    "times_dict = {}\n",
    "lsts_dict = {}\n",
    "histories_dict = {}\n",
    "ants = set([])\n",
    "apriori_exants = {df: set([]) for df in data_list}\n",
    "for df in data_list:\n",
    "    mf = df.replace('.uvh5', f'{prefix}.redcal_meta.hdf5')\n",
    "    (fc_meta, omni_meta, freqs, times_dict[mf], lsts_dict[mf], \n",
    "     antpos, histories_dict[mf]) = io.read_redcal_meta(mf)\n",
    "    ee_iters_dict[mf] = omni_meta['iter'][\"['ee']\"]\n",
    "    nn_iters_dict[mf] = omni_meta['iter'][\"['nn']\"]\n",
    "    flips_dict[mf] = fc_meta['polarity_flips']\n",
    "    dlys_dict[mf] = fc_meta['dlys']\n",
    "    ants |= set(fc_meta['dlys'].keys())\n",
    "    if '--ex_ants' in histories_dict[mf]:\n",
    "        for ant in histories_dict[mf].split('--ex_ants')[1].split('--')[0].strip().split():\n",
    "            apriori_exants[df].add(int(ant))\n",
    "\n",
    "ants = sorted(ants)\n",
    "times = np.array(list(times_dict.values())).flatten()\n",
    "lsts = np.array(list(lsts_dict.values())).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:50:18.794218Z",
     "start_time": "2020-10-25T03:48:39.245488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load xants/dead_ants/crossed_ants from ant metrics\n",
    "am_xants_dict = {}\n",
    "am_dead_ants_dict = {}\n",
    "am_crossed_ants_dict = {}\n",
    "for df in data_list:\n",
    "    amf = df.replace('.uvh5', ant_metrics_ext)\n",
    "    with h5py.File(amf, \"r\") as infile:\n",
    "        xants = infile['Metrics']['xants'][:]\n",
    "        dead_ants = infile['Metrics']['dead_ants'][:]\n",
    "        crossed_ants = infile['Metrics']['crossed_ants'][:]        \n",
    "        ex_ants_string = infile['Header']['history'][()].decode()\n",
    "        if '--apriori_xants' in ex_ants_string:\n",
    "            ex_ants_string = ex_ants_string.split('--apriori_xants')[1]\n",
    "            ex_ants_string = ex_ants_string.split('--')[0].strip()\n",
    "            for ant in ex_ants_string.split():\n",
    "                apriori_exants[df].add(int(ant))\n",
    "            \n",
    "    am_xants_dict[amf] = [(int(ant[0]), ant[1].decode()) for ant in xants]\n",
    "    am_dead_ants_dict[amf] = [(int(ant[0]), ant[1].decode()) for ant in dead_ants]\n",
    "    am_crossed_ants_dict[amf] = [(int(ant[0]), ant[1].decode()) for ant in crossed_ants]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load auto_metrics\n",
    "glob_str = os.path.join(data_path, f'zen.{JD}*.auto_metrics.h5')\n",
    "auto_metrics_file = sorted(glob.glob(glob_str))\n",
    "\n",
    "# if it exists, load and extract relevant information\n",
    "if len(auto_metrics_file) > 0:\n",
    "    auto_metrics_file = auto_metrics_file[0]\n",
    "    print(f'Found auto_metrics results file at {auto_metrics_file}.')\n",
    "    \n",
    "    auto_metrics = load_metric_file(auto_metrics_file)\n",
    "    auto_ex_ants = auto_metrics['ex_ants']['r2_ex_ants']\n",
    "else:\n",
    "    print(f'No files found matching glob {glob_str}. Skipping auto_metrics.')\n",
    "    auto_ex_ants = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:58:19.974713Z",
     "start_time": "2020-10-25T03:50:18.798827Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load chisq and flagging info from omnical gains\n",
    "cal_list = [df.replace('.uvh5', f'{prefix}.omni.calfits') for df in data_list]\n",
    "ant_flags_dict = {}\n",
    "chisq_ee_dict = {}\n",
    "chisq_nn_dict = {}\n",
    "cspa_med_dict = {}\n",
    "\n",
    "for cal in cal_list:\n",
    "    hc = io.HERACal(cal)\n",
    "    _, flags, cspa, chisq = hc.read()\n",
    "    \n",
    "    ant_flags_dict[cal] = {ant: np.all(flags[ant]) for ant in flags}\n",
    "    chisq_ee_dict[cal] = chisq['Jee']\n",
    "    chisq_nn_dict[cal] = chisq['Jnn']\n",
    "    cspa_med_dict[cal] = {ant: np.nanmedian(cspa[ant], axis=1) for ant in cspa}\n",
    "\n",
    "cspa = {ant: np.hstack([np.squeeze(cspa_med_dict[cal][ant]) / \\\n",
    "                        ~ant_flags_dict[cal][ant] for cal in cal_list]) for ant in ants}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T03:59:46.939793Z",
     "start_time": "2020-10-25T03:58:19.979391Z"
    }
   },
   "outputs": [],
   "source": [
    "# save middle-numbered ants with a minimal number of flags\n",
    "ants_to_save = {}\n",
    "for pol in ['Jee', 'Jnn']:\n",
    "    min_flags = np.min([np.sum(~np.isfinite(cspa[ant])) \n",
    "                        for ant in cspa if ant[1] == pol])\n",
    "    ant_candidates = sorted([ant for ant in cspa if ant[1] == pol and \n",
    "                             np.sum(~np.isfinite(cspa[ant])) == min_flags])\n",
    "    Nac = len(ant_candidates)\n",
    "    ants_to_save[pol] = ant_candidates[(Nac // 2 - 1):(Nac // 2 + 1)]\n",
    "\n",
    "# Reload omnical gains\n",
    "gain_dict = {}\n",
    "for cal in cal_list:\n",
    "    hc = io.HERACal(cal)\n",
    "    gains, _, _, _ = hc.read()\n",
    "    gain_dict[cal] = {ant: gains[ant] for pol in ants_to_save \n",
    "                      for ant in ants_to_save[pol]}\n",
    "\n",
    "gains = {ant: np.vstack([gain_dict[cal][ant] for cal in gain_dict]) \n",
    "         for pol in ants_to_save for ant in ants_to_save[pol]}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Whole Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:21:38.555950Z",
     "start_time": "2020-10-25T17:21:34.059523Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build up exants grid\n",
    "#0 = AM dead, 1 =  AM crossed, 2 = auto_metrics, 3 = apriori, 4 = redcal, 5 = no flags \n",
    "exants_grid = np.zeros((len(ants),len(cal_list))) + 5.0\n",
    "\n",
    "# if flagged for any reason, then it's at least a redcal flag\n",
    "for f, cal in enumerate(ant_flags_dict):\n",
    "    for i, ant in enumerate(ants):\n",
    "        if ant_flags_dict[cal][ant]:\n",
    "            exants_grid[i, f] = 4.0\n",
    "\n",
    "# next a priori flag, but override if necessary\n",
    "for f, df in enumerate(apriori_exants):\n",
    "    for i, ant in enumerate(ants):\n",
    "        if ant[0] in apriori_exants[df]:\n",
    "            exants_grid[i, f] = 0.0\n",
    "\n",
    "# next auto_metrics, but override with ant_metrics if also that\n",
    "for f in range(len(ant_flags_dict)):\n",
    "    for i, ant in enumerate(ants):\n",
    "        if ant[0] in auto_ex_ants:\n",
    "            exants_grid[i, f] = 2.0\n",
    "\n",
    "# ant_metrics\n",
    "for f, amf in enumerate(am_xants_dict):\n",
    "    for i, ant in enumerate(ants):\n",
    "        if ant in am_dead_ants_dict[amf]:\n",
    "            exants_grid[i, f] = 0.0                \n",
    "        elif ant in am_crossed_ants_dict[amf]:\n",
    "            exants_grid[i, f] = 1.0\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "color_order = ['magenta', 'cyan', 'red', 'gold', 'green', 'black']\n",
    "cmap = matplotlib.colors.ListedColormap(color_order)\n",
    "bounds=np.arange(len(color_order)+1)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "            \n",
    "fig = plt.figure(figsize=(14,len(ants)/4.625))\n",
    "im = plt.imshow(exants_grid, aspect='auto', cmap=cmap, norm=norm, interpolation='nearest',\n",
    "                extent=[times[0], times[-1], len(ants), 0])\n",
    "plt.yticks(np.arange(len(ants))+.5, \n",
    "           labels = ['{}{}'.format(ant[0], ant[1][-1]) for ant in ants]);\n",
    "plt.grid(color='w', linestyle='-', linewidth=1.5, axis='y')\n",
    "plt.xlabel('LST (Hours)')\n",
    "plt.gca().set_xticklabels(np.around(lsts[[min(max(np.searchsorted(times, t), 0), len(times) - 1) \n",
    "                                          for t in plt.gca().get_xticks()]] * 12 / np.pi, 2))\n",
    "\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.new_vertical(size=.4, pad=0.5, pack_start=False)\n",
    "fig.add_axes(cax)\n",
    "cbar = fig.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "cbar.set_ticks(.5 + np.arange(len(color_order)))\n",
    "cbar.set_ticklabels(['Ant_Metrics: Dead',\n",
    "                     'Ant_Metrics: Crossed',\n",
    "                     'Auto_Metrics Outlier',\n",
    "                     'A Priori Status Flag', \n",
    "                     'Redcal Flag',\n",
    "                     'No Flags', ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3: Antenna Flagging\n",
    "Shows progressive stages of flagging. Note that \"crossed\" means relatively low power in Vxx and Vyy compared to Vxy and Vyx. This may be because the antenna is broken and all 4 pols have similar power levels, in which case it would still be an outlier according to this metric. \n",
    "\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Check for new antennas that went bad but weren't in the a priori list. If these are consistently flagged, mark the antenna as \"calibration triage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:22:46.516704Z",
     "start_time": "2020-10-25T17:22:43.844419Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot delays\n",
    "dlys = {ant: np.hstack([dlys_dict[mf][ant] for mf in dlys_dict]) for ant in ants}\n",
    "dly_meds = {ant: np.nanmedian(dlys[ant]) for ant in dlys}\n",
    "plt.figure(figsize=(16,10))\n",
    "for ant in dlys:\n",
    "    plt.plot(times, (dlys[ant])*1e9)\n",
    "    if np.isfinite(dly_meds[ant]):\n",
    "        plt.text(np.min(times) - 20*np.median(np.diff(times)), \n",
    "                 1e9*dly_meds[ant], '{}{}'.format(ant[0], ant[1][-1]), \n",
    "                 va='center', ha='right', fontsize=8)    \n",
    "plt.gca().set_xticklabels(np.around(lsts[[min(max(np.searchsorted(times, t), 0), len(times) - 1) \n",
    "                                          for t in plt.gca().get_xticks()]] * 12 / np.pi, 2))\n",
    "\n",
    "plt.xlabel('LST (Hours)')\n",
    "plt.ylabel('Delay (ns)')\n",
    "plt.title('Firstcal Delays');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4: Firstcal Delays\n",
    "Shows solved firstcal delays. These will have an arbitrary tip/tilt and offset.\n",
    "\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Look for outliers. All antennas should be within a few hundred ns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:23:47.389714Z",
     "start_time": "2020-10-25T17:23:43.806851Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot offset delays\n",
    "plt.figure(figsize=(16, len(ants)/7.4))\n",
    "for n, ant in enumerate(dlys):\n",
    "    plt.plot(times, (dlys[ant]-dly_meds[ant])*1e9 + n, label=ant)\n",
    "    plt.text(np.min(times) - 20*np.median(np.diff(times)), \n",
    "             n, '{}{}'.format(ant[0], ant[1][-1]), \n",
    "             va='center', ha='right', fontsize=8)\n",
    "plt.gca().set_xticklabels(np.around(lsts[[min(max(np.searchsorted(times, t), 0), len(times) - 1) \n",
    "                                          for t in plt.gca().get_xticks()]] * 12 / np.pi, 2))\n",
    "plt.xlabel('LST (Hours)')\n",
    "plt.ylabel('Delay with Arbitrary Offset (ns)')\n",
    "plt.title('Firstcal Delays With Arbitrary Offset');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5: Offset Firstcal Delays\n",
    "Same as Figure 4, but with arbitrary offsets for each antenna.\n",
    "\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Look for antennas that exhibit wild swings (> 10 ns) in their delay over time, especially discontinuities that cannot be attributed to inconsistent antenna flagging (see Figure 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:24:10.427572Z",
     "start_time": "2020-10-25T17:24:10.417326Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Figure out oc_maxiter\n",
    "if np.all(['oc_maxiter' in history for history in histories_dict.values()]):\n",
    "    history = list(histories_dict.values())[0]\n",
    "    oc_maxiter = int(history.split('--oc_maxiter')[1].split('--')[0])\n",
    "else:\n",
    "    oc_maxiter = inspect.signature(redcal.redcal_run).parameters['oc_maxiter'].default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:24:41.435902Z",
     "start_time": "2020-10-25T17:24:38.601713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recast from dictionaries to one big array\n",
    "ee_iters = np.vstack(np.array(list(ee_iters_dict.values())))\n",
    "nn_iters = np.vstack(np.array(list(nn_iters_dict.values())))\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "my_cmap = deepcopy(matplotlib.cm.get_cmap('viridis'))\n",
    "my_cmap.set_under('w')\n",
    "my_cmap.set_over('r')\n",
    "\n",
    "for sp, iters, t in zip([121, 122], [ee_iters, nn_iters], \n",
    "                        ['ee-polarized', 'nn-polarized']):\n",
    "    plt.subplot(sp)\n",
    "    plt.imshow(iters, aspect='auto', cmap=my_cmap, vmin=1, vmax=oc_maxiter-1, interpolation='nearest',\n",
    "               extent=[freqs[0]/1e6, freqs[-1]/1e6, times[-1], times[0]])\n",
    "    plt.title('Number of Omnical Iterations: ' + t)\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel('LST (Hours)')    \n",
    "    plt.gca().set_yticklabels(np.around(lsts[[min(max(np.searchsorted(times, t), 0), len(times) - 1) \n",
    "                                              for t in plt.gca().get_yticks()]] * 12 / np.pi, 2))    \n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6: Number of omnical iterations per polarization\n",
    "Red indicates that omnical reached the maximum number of integrations. White indicates that omnical didn't run, likely because the data were flagged.\n",
    "\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Check that few-to-no data were flagged (white) before omnical and check that this matches\n",
    "* Check that few-to-no data hit the maximum number of iterations for omnical (red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:25:07.698275Z",
     "start_time": "2020-10-25T17:25:05.534578Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Make dictionary mapping antenna to the whole night of antenna flips\n",
    "flips = {ant: np.hstack([flips_dict[mf][ant] for mf in flips_dict]) for ant in ants}\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "my_cmap = matplotlib.cm.get_cmap('cool')\n",
    "for sp, jpol, t in zip([121, 122], ['Jee', 'Jnn'], ['ee-polarized ', 'nn-polarized']):\n",
    "    plt.subplot(sp)\n",
    "    plt.scatter(np.array(list(hd.data_antpos.values()))[:,0], \n",
    "                np.array(list(hd.data_antpos.values()))[:,1],\n",
    "                c='w', s=0)\n",
    "    for ant,pos in hd.data_antpos.items():\n",
    "        flip_frac = np.nanmean(flips[(ant, jpol)])\n",
    "        if np.isfinite(flip_frac):\n",
    "            color=my_cmap(flip_frac)\n",
    "        else:\n",
    "            color='w'\n",
    "        plt.gca().add_artist(plt.Circle(tuple(pos[0:2]), radius=7, \n",
    "                                        fill=(~bad), color=color, ec='k'))\n",
    "        plt.text(pos[0], pos[1],\n",
    "                 '{}:\\n{}%'.format(ant, np.round(100*flip_frac,0)), \n",
    "                 va='center', ha='center', color='k')\n",
    "    plt.xlabel(\"Antenna East-West Position (meters)\")\n",
    "    plt.ylabel(\"Antenna North-South Position (meters)\")\n",
    "    \n",
    "    # count the number of times a self-consistent polarity flip solution was found\n",
    "    all_flips_this_pol = [flips[ant] for ant in flips if ant[1] == jpol]\n",
    "    success = np.round(100*np.mean(np.any(np.isfinite(all_flips_this_pol), axis=0)), 2)\n",
    "    plt.title(t + ' Polarity Flips -- Solution Found {}% of the Time'.format(success))\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 7: Detection of polarity-flipped antennas\n",
    "Blue indicates nominal operation, pink indicates polarity flips. \n",
    "\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Check that all antennas are either nearly 100% flipped, nearly 0% flipped, or flagged.\n",
    "* Check that a solution for polarity flips was found a reasonable percentage of the time (ideally more than a few %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:25:37.706432Z",
     "start_time": "2020-10-25T17:25:35.226300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grid and plot overall chi^2 for each polarization\n",
    "ee_chisq = np.vstack(np.array(list(chisq_ee_dict.values())))\n",
    "nn_chisq = np.vstack(np.array(list(chisq_nn_dict.values())))\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "for sp, cs, t in zip([121, 122], [ee_chisq, nn_chisq], ['ee-polarized', 'nn-polarized']):\n",
    "    plt.subplot(sp)\n",
    "    plt.imshow(cs, aspect='auto', vmin=1, cmap='inferno', vmax=5, interpolation='nearest',\n",
    "               extent=[freqs[0]/1e6, freqs[-1]/1e6, times[-1], times[0]])\n",
    "    plt.title('Overall $\\chi^2$ / DoF: ' + t)\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel('LST (Hours)')        \n",
    "    plt.gca().set_yticklabels(np.around(lsts[[min(max(np.searchsorted(times, t), 0), len(times) - 1) \n",
    "                                          for t in plt.gca().get_yticks()]] * 12 / np.pi, 2))\n",
    "    plt.colorbar()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T01:22:42.634940Z",
     "start_time": "2020-03-05T01:22:42.627959Z"
    }
   },
   "source": [
    "### Figure 8: Overall $\\chi^2$ / DoF\n",
    "\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Looks for regions of large non-redundancy not directly attributable to RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:26:31.590406Z",
     "start_time": "2020-10-25T17:26:27.856422Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot all chi^2 per antenna, highlight antennas that get flagged but not always\n",
    "plt.figure(figsize=(20,10))\n",
    "for sp, pol, t in zip([121, 122], ['Jee', 'Jnn'], ['ee-polarized', 'nn-polarized']):\n",
    "    plt.subplot(sp)\n",
    "    for ant in ants:\n",
    "        if ant[1] == pol:\n",
    "            if not np.all([ant_flags_dict[cal][ant] for cal in cal_list]):\n",
    "                if np.any([ant_flags_dict[cal][ant] and \n",
    "                           not np.all(list(ant_flags_dict[cal].values())) \n",
    "                           for cal in cal_list]):\n",
    "                    plt.plot(times, cspa[ant], '.', label=ant)\n",
    "                else:\n",
    "                    plt.plot(times, cspa[ant], '-', c='grey', alpha=.5, lw=.25)\n",
    "    plt.ylabel('Normalized Median $\\chi^2$ per Antenna (unitless)')\n",
    "    plt.xlabel('LST (Hours)')\n",
    "    plt.gca().set_xticklabels(np.around(lsts[[min(max(np.searchsorted(times, t), 0), len(times) - 1) \n",
    "                                              for t in plt.gca().get_xticks()]] * 12 / np.pi, 2))    \n",
    "    plt.title(t + ' Antennas')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T02:00:57.870280Z",
     "start_time": "2020-03-05T02:00:57.863637Z"
    }
   },
   "source": [
    "### Figure 9: Normalized $\\chi^2$ per antenna\n",
    "Only unflagged data is shown, but antennas that were ever flagged are colored and shown in the legend. All other antennas are shown in grey.\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Look for outliers in the chi^2 per antenna distribution\n",
    "* Look for evidence that antenna that was sometimes flagged should have been always flagged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:26:58.660201Z",
     "start_time": "2020-10-25T17:26:55.884214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot example gain amplitudes\n",
    "plt.figure(figsize=(20,12))\n",
    "for sp, pol in zip([121, 122], ['Jee', 'Jnn']):\n",
    "    plt.subplot(sp)\n",
    "    ant = ants_to_save[pol][1]\n",
    "    plt.title(str(ant) + ' Gain Magnitude')\n",
    "    plt.imshow(np.abs(gains[ant]), aspect='auto', cmap='inferno', interpolation='nearest',\n",
    "               extent=[freqs[0]/1e6, freqs[-1]/1e6, times[-1], times[0]])\n",
    "    plt.clim([0,2])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel('LST (Hours)')    \n",
    "    plt.gca().set_yticklabels(np.around(lsts[[min(max(np.searchsorted(times, t), 0), len(times) - 1) \n",
    "                                              for t in plt.gca().get_yticks()]] * 12 / np.pi, 2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 10: Example Amplitudes\n",
    "\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Looks for large discontinuities or fuzziness not attributable to RFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T17:27:41.600602Z",
     "start_time": "2020-10-25T17:27:38.336692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot example gain relative phases\n",
    "plt.figure(figsize=(20,12))\n",
    "for sp, pol in zip([121, 122], ['Jee', 'Jnn']):\n",
    "    plt.subplot(sp)\n",
    "    ant0, ant1 = ants_to_save[pol]\n",
    "    plt.title('Angle of gains[{}] / gains[{}]'.format(ant0, ant1))\n",
    "    plt.imshow(np.angle(gains[ant0] / gains[ant1]), aspect='auto', cmap='twilight', interpolation='nearest',\n",
    "               extent=[freqs[0]/1e6, freqs[-1]/1e6, times[-1], times[0]])\n",
    "    plt.gca().set_yticklabels(np.around(lsts[[min(max(np.searchsorted(times, t), 0), len(times) - 1) \n",
    "                                              for t in plt.gca().get_yticks()]] * 12 / np.pi, 2))    \n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel('LST (Hours)')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 11: Example Gain Phases\n",
    "Relative gain phases of two example antennas.\n",
    "\n",
    "#### OBSERVER CHECKLIST:\n",
    "* Check that these gains are relatively stable in time and that there aren't huge phase discontinuities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(redcal.version.history_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

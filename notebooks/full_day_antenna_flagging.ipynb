{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a733cd",
   "metadata": {},
   "source": [
    "# Full Day Antenna Flagging\n",
    "\n",
    "**by Josh Dillon**, last updated July 26, 2025\n",
    "\n",
    "This notebook is designed to harmonize the potentially inconsistent per-antenna flagging coming out of [file_calibration](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/file_calibration.ipynb) notebook. It seeks to flag likely bad times between known bad times and to impose\n",
    "maximum flagging factions and maximum stretches of consecutive flags between otherwise good data (which can raise problems when smoothing or filtering later).\n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "\n",
    "\n",
    "# [• Figure 1: Flag Summary vs. JD](#Figure-1:-Flag-Summary-vs.-JD)\n",
    "# [• Figure 2: Array Flag Fraction Summary](#Figure-2:-Array-Flag-Fraction-Summary)\n",
    "# [• Figure 3: Flag Fraction vs. JD Summary](#Figure-3:-Flag-Fraction-vs.-JD-Summary)\n",
    "# [• Figure 4: Per-Antenna Flag Harmonization Summary](#Figure-4:-Per-Antenna-Flag-Harmonization-Summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0729ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a0651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pyuvdata import UVFlag, UVData, UVCal\n",
    "from hera_cal import io, utils\n",
    "from hera_qm.time_series_metrics import true_stretches, impose_max_flag_gap, metric_convolution_flagging\n",
    "from hera_qm.metrics_io import read_a_priori_int_flags\n",
    "from uvtools.plot import plot_antpos, plot_antclass\n",
    "from scipy.ndimage import convolve\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e80aed",
   "metadata": {},
   "source": [
    "## Parse inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f7b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files\n",
    "SUM_FILE = os.environ.get(\"SUM_FILE\", None)\n",
    "# SUM_FILE = '/lustre/aoc/projects/hera/h6c-analysis/IDR3/2459848/zen.2459848.38149.sum.uvh5'\n",
    "SUM_SUFFIX = os.environ.get(\"SUM_SUFFIX\", 'sum.uvh5')\n",
    "CAL_SUFFIX = os.environ.get(\"CAL_SUFFIX\", 'sum.omni.calfits')\n",
    "ANT_CLASS_SUFFIX = os.environ.get(\"ANT_CLASS_SUFFIX\", 'ant_class.csv')\n",
    "OUT_FLAG_SUFFIX = os.environ.get(\"OUT_FLAG_SUFFIX\", 'sum.antenna_flags.h5')\n",
    "APRIORI_YAML_PATH = os.environ.get(\"APRIORI_YAML_PATH\", None)\n",
    "\n",
    "# Parameters for harmonizing partially-flagged antennas\n",
    "SMOOTHING_SCALE_NFILES = float(os.environ.get(\"SMOOTHING_SCALE_NFILES\", 30))\n",
    "MAX_FLAG_GAP_NFILES = int(os.environ.get(\"MAX_FLAG_GAP_NFILES\", 30))\n",
    "\n",
    "# Max flag fractions (before just flagging the whole antenna)\n",
    "POWER_MAX_FLAG_FRAC = float(os.environ.get(\"POWER_MAX_FLAG_FRAC\", .5))\n",
    "AUTO_POWER_MAX_FLAG_FRAC = float(os.environ.get(\"AUTO_POWER_MAX_FLAG_FRAC\", .5))\n",
    "AUTO_SHAPE_MAX_FLAG_FRAC = float(os.environ.get(\"AUTO_SHAPE_MAX_FLAG_FRAC\", .25))\n",
    "AUTO_SLOPE_MAX_FLAG_FRAC = float(os.environ.get(\"AUTO_SLOPE_MAX_FLAG_FRAC\", .25))\n",
    "AUTO_RFI_MAX_FLAG_FRAC = float(os.environ.get(\"AUTO_RFI_MAX_FLAG_FRAC\", .25))\n",
    "CHISQ_MAX_FLAG_FRAC = float(os.environ.get(\"CHISQ_MAX_FLAG_FRAC\", .5))\n",
    "XENGINE_MAX_FLAG_FRAC = float(os.environ.get(\"XENGINE_MAX_FLAG_FRAC\", .05))\n",
    "OVERALL_MAX_FLAG_FRAC = float(os.environ.get(\"OVERALL_MAX_FLAG_FRAC\", .5))\n",
    "\n",
    "for setting in ['SUM_FILE', 'SUM_SUFFIX', 'CAL_SUFFIX', 'ANT_CLASS_SUFFIX', 'OUT_FLAG_SUFFIX', 'APRIORI_YAML_PATH',\n",
    "                'SMOOTHING_SCALE_NFILES', 'MAX_FLAG_GAP_NFILES', 'POWER_MAX_FLAG_FRAC', 'AUTO_POWER_MAX_FLAG_FRAC', \n",
    "                'AUTO_SHAPE_MAX_FLAG_FRAC', 'AUTO_SLOPE_MAX_FLAG_FRAC', 'AUTO_RFI_MAX_FLAG_FRAC', \n",
    "                'XENGINE_MAX_FLAG_FRAC', 'CHISQ_MAX_FLAG_FRAC', 'OVERALL_MAX_FLAG_FRAC']:\n",
    "        print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0023c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ant_metrics bounds for low correlation / dead antennas\n",
    "am_corr_bad = (0, float(os.environ.get(\"AM_CORR_BAD\", 0.3)))\n",
    "am_corr_suspect = (float(os.environ.get(\"AM_CORR_BAD\", 0.3)), float(os.environ.get(\"AM_CORR_SUSPECT\", 0.5)))\n",
    "\n",
    "# ant_metrics bounds for cross-polarized antennas\n",
    "am_xpol_bad = (-1, float(os.environ.get(\"AM_XPOL_BAD\", -0.1)))\n",
    "am_xpol_suspect = (float(os.environ.get(\"AM_XPOL_BAD\", -0.1)), float(os.environ.get(\"AM_XPOL_SUSPECT\", 0)))\n",
    "\n",
    "# bounds on solar altitude (in degrees)\n",
    "good_solar_altitude = (-90, float(os.environ.get(\"SUSPECT_SOLAR_ALTITUDE\", 0)))\n",
    "suspect_solar_altitude = (float(os.environ.get(\"SUSPECT_SOLAR_ALTITUDE\", 0)), 90)\n",
    "\n",
    "# bounds on zeros in spectra\n",
    "good_zeros_per_eo_spectrum = (0, int(os.environ.get(\"MAX_ZEROS_PER_EO_SPEC_GOOD\", 2)))\n",
    "suspect_zeros_per_eo_spectrum = (0, int(os.environ.get(\"MAX_ZEROS_PER_EO_SPEC_SUSPECT\", 8)))\n",
    "\n",
    "# bounds on autocorrelation power\n",
    "auto_power_good = (float(os.environ.get(\"AUTO_POWER_GOOD_LOW\", 5)), float(os.environ.get(\"AUTO_POWER_GOOD_HIGH\", 30)))\n",
    "auto_power_suspect = (float(os.environ.get(\"AUTO_POWER_SUSPECT_LOW\", 1)), float(os.environ.get(\"AUTO_POWER_SUSPECT_HIGH\", 60)))\n",
    "\n",
    "# bounds on autocorrelation slope\n",
    "auto_slope_good = (float(os.environ.get(\"AUTO_SLOPE_GOOD_LOW\", -0.4)), float(os.environ.get(\"AUTO_SLOPE_GOOD_HIGH\", 0.4)))\n",
    "auto_slope_suspect = (float(os.environ.get(\"AUTO_SLOPE_SUSPECT_LOW\", -0.6)), float(os.environ.get(\"AUTO_SLOPE_SUSPECT_HIGH\", 0.6)))\n",
    "\n",
    "# bounds on autocorrelation RFI\n",
    "auto_rfi_good = (0, float(os.environ.get(\"AUTO_RFI_GOOD\", 1.5)))\n",
    "auto_rfi_suspect = (0, float(os.environ.get(\"AUTO_RFI_SUSPECT\", 2.0)))\n",
    "\n",
    "# bounds on autocorrelation shape\n",
    "auto_shape_good = (0, float(os.environ.get(\"AUTO_SHAPE_GOOD\", 0.1)))\n",
    "auto_shape_suspect = (0, float(os.environ.get(\"AUTO_SHAPE_SUSPECT\", 0.2)))\n",
    "\n",
    "# bounds on chi^2 per antenna in omnical\n",
    "oc_cspa_good = (0, float(os.environ.get(\"OC_CSPA_GOOD\", 2)))\n",
    "oc_cspa_suspect = (0, float(os.environ.get(\"OC_CSPA_SUSPECT\", 3)))\n",
    "\n",
    "OC_SKIP_OUTRIGGERS = os.environ.get(\"OC_SKIP_OUTRIGGERS\", \"TRUE\").upper() == \"TRUE\"\n",
    "\n",
    "for bound in ['am_corr_bad', 'am_corr_suspect', 'am_xpol_bad', 'am_xpol_suspect', \n",
    "              'good_solar_altitude', 'suspect_solar_altitude',\n",
    "              'good_zeros_per_eo_spectrum', 'suspect_zeros_per_eo_spectrum',\n",
    "              'auto_power_good', 'auto_power_suspect', 'auto_slope_good', 'auto_slope_suspect',\n",
    "              'auto_rfi_good', 'auto_rfi_suspect', 'auto_shape_good', 'auto_shape_suspect',\n",
    "              'oc_cspa_good', 'oc_cspa_suspect', 'OC_SKIP_OUTRIGGERS']:\n",
    "    print(f'{bound} = {eval(bound)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f06b6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = io.HERAData(SUM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_glob = '.'.join(SUM_FILE.split('.')[:-3]) + '.*.' + SUM_SUFFIX\n",
    "cal_files_glob = sum_glob.replace(SUM_SUFFIX, CAL_SUFFIX)\n",
    "cal_files = sorted(glob.glob(cal_files_glob))\n",
    "print(f'Found {len(cal_files)} *.{CAL_SUFFIX} files starting with {cal_files[0]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c69833",
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_class_csvs_glob = sum_glob.replace(SUM_SUFFIX, ANT_CLASS_SUFFIX)\n",
    "ant_class_csvs = sorted(glob.glob(ant_class_csvs_glob))\n",
    "jds = [float(f.split('/')[-1].split('zen.')[-1].split('.sum')[0]) for f in ant_class_csvs]\n",
    "frac_jds = jds - np.floor(jds[0])\n",
    "Ncsvs = len(ant_class_csvs)\n",
    "print(f'Found {Ncsvs} *.{ANT_CLASS_SUFFIX} files starting with {ant_class_csvs[0]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc41446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ant_class csvs\n",
    "tables = [pd.read_csv(f).dropna(axis=0, how='all') for f in ant_class_csvs]\n",
    "table_cols = tables[0].columns[1::2]\n",
    "class_cols = tables[0].columns[2::2]\n",
    "ap_strs = np.array(tables[0]['Antenna'])\n",
    "ants = sorted(set(int(a[:-1]) for a in ap_strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up dictionaries for full night metrics and classifications\n",
    "replace = {'-': np.nan, 'INF': np.inf, 'No': False, 'Yes': True}\n",
    "\n",
    "metric_data = {tc: {} for tc in table_cols}\n",
    "class_data = {tc: {} for tc in table_cols}\n",
    "for tc, cc in zip(table_cols, class_cols):\n",
    "    class_array = np.vstack([t[cc] for t in tables]).T\n",
    "    metric_array = np.vstack([t[tc] for t in tables]).T\n",
    "    for ca, ma, ap_str in zip(class_array, metric_array, ap_strs):\n",
    "        class_data[tc][ap_str] = ca\n",
    "        if tc == 'Antenna':\n",
    "            metric_data[tc][ap_str] = ma\n",
    "        else:\n",
    "            metric_data[tc][ap_str] = np.array([replace[val] if val in replace else float(val) for val in ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_flags = {ap_str: np.array(class_data['Antenna'][ap_str] == 'bad') for ap_str in ap_strs}\n",
    "print(f'{np.mean(list(original_flags.values())):.2%} of antenna-files flagged by RTP.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlagHistory:\n",
    "    '''Helps keep strack of why flags get applied'''\n",
    "    \n",
    "    def __init__(self, ap_strs, Nfiles):\n",
    "        self.final_flags = {ap_str: np.zeros(Nfiles, dtype=bool) for ap_str in ap_strs}\n",
    "        self.history = {}\n",
    "    \n",
    "    def update(self, ap_str, rtp_flags, updated_flags, rationale):\n",
    "        self.history[(ap_str, rationale)] = (np.array(self.final_flags[ap_str]), np.array(rtp_flags), np.array(updated_flags))\n",
    "        self.final_flags[ap_str] |= updated_flags\n",
    "        \n",
    "    def summarize(self, description):\n",
    "        print(f'{np.mean(list(self.final_flags.values())):.2%} of antenna-files flagged after {description}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306c027",
   "metadata": {},
   "source": [
    "## Perform flagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = FlagHistory(ap_strs, Ncsvs)\n",
    "\n",
    "# STEP 1: FLAG SUN UP DATA AND OTHER A PRIORI FLAGGED TIMES\n",
    "for ap_str in ap_strs:\n",
    "    sun_up = metric_data['Solar Alt'][ap_str] > good_solar_altitude[1]\n",
    "    fh.update(ap_str, sun_up, sun_up, 'Solar Alt')\n",
    "solar_flags = np.all([metric_data['Solar Alt'][ap_str] > good_solar_altitude[1] for ap_str in ap_strs], axis=0)\n",
    "fh.summarize('flagging sun-up data')\n",
    "if APRIORI_YAML_PATH is not None:\n",
    "    apriori_flags = np.zeros(len(jds), dtype=bool)\n",
    "    apriori_flags[read_a_priori_int_flags(APRIORI_YAML_PATH, times=np.array(jds)).astype(int)] = True\n",
    "    for ap_str in ap_strs:\n",
    "        fh.update(ap_str, apriori_flags, apriori_flags, 'A Priori')\n",
    "    fh.summarize('flagging a priori flagged times')\n",
    "    apriori_flags |= solar_flags\n",
    "else:\n",
    "    apriori_flags = solar_flags\n",
    "\n",
    "# STEP 2: FLAG TOTALLY DEAD ANTENNAS\n",
    "for ap_str in ap_strs:\n",
    "    fh.update(ap_str, metric_data['Dead?'][ap_str], metric_data['Dead?'][ap_str], 'Dead?')\n",
    "fh.summarize('removing dead antennas')    \n",
    "\n",
    "# STEP 3: FLAG OUTRIGGERS\n",
    "if OC_SKIP_OUTRIGGERS:\n",
    "    for ap_str in ap_strs:\n",
    "        if int(ap_str[:-1]) >= 320:\n",
    "            fh.update(ap_str, np.ones(Ncsvs, dtype=bool), np.ones(Ncsvs, dtype=bool), 'Outrigger')\n",
    "    fh.summarize('flagging outriggers')\n",
    "\n",
    "# STEP 4: FLAG CROSS-POLARIZED ANTENNAS\n",
    "for ap_str in ap_strs:\n",
    "    if np.mean(metric_data['Cross-Polarized'][ap_str]) < am_xpol_bad[1]:\n",
    "        fh.update(ap_str, class_data['Cross-Polarized'][ap_str] == 'bad', np.ones(Ncsvs, dtype=bool), 'Cross-Polarized')\n",
    "fh.summarize('removing cross-polarized antennas')\n",
    "    \n",
    "# STEP 5: FLAG POORLY-CORRELATING ANTENNAS\n",
    "for ap_str in ap_strs:\n",
    "    if np.mean(metric_data['Low Correlation'][ap_str]) < am_corr_bad[1]:\n",
    "        fh.update(ap_str, class_data['Low Correlation'][ap_str] == 'bad', np.ones(Ncsvs, dtype=bool), 'Cross-Polarized')\n",
    "fh.summarize('removing non-correlating antennas')\n",
    "\n",
    "# STEP 6: FLAG ON AUTOCORRELATIONS\n",
    "for category, ok_range, max_flag_frac in zip(['Autocorr Power', 'Autocorr Shape', 'Autocorr Slope', 'Auto RFI RMS'],\n",
    "                                              [auto_power_suspect, auto_shape_good, auto_slope_good, auto_rfi_good],\n",
    "                                              [AUTO_POWER_MAX_FLAG_FRAC, AUTO_SHAPE_MAX_FLAG_FRAC, AUTO_SLOPE_MAX_FLAG_FRAC, AUTO_RFI_MAX_FLAG_FRAC]):\n",
    "    for ap_str in ap_strs:\n",
    "        # apply RTP flags for these categories\n",
    "        rtp_flags = (class_data[category][ap_str] == 'bad')\n",
    "        # if not completely flagged or completely unflagged, grow flags via convolution\n",
    "        if np.any(rtp_flags) and not np.all(fh.final_flags[ap_str] | rtp_flags):\n",
    "            metric = metric_data[category][ap_str]    \n",
    "            new_flags = metric_convolution_flagging(metric, rtp_flags, ok_range, sigma=SMOOTHING_SCALE_NFILES, max_flag_gap=MAX_FLAG_GAP_NFILES)\n",
    "            # if too many times are flagged for this category, flag the whole antenna (excluding sun-up times)\n",
    "            if np.mean(new_flags[~apriori_flags]) > max_flag_frac:\n",
    "                new_flags[:] = True\n",
    "        else:\n",
    "            new_flags = rtp_flags\n",
    "        fh.update(ap_str, rtp_flags, new_flags, category)\n",
    "    fh.summarize(f'flagging antennas for {category}')\n",
    "    \n",
    "# STEP 7: FLAG FOR HIGH CHI^2\n",
    "for ap_str in ap_strs:\n",
    "    flagged_for_cspa = (~fh.final_flags[ap_str]) & (class_data['Even/Odd Zeros'][ap_str] != 'bad') & \\\n",
    "                       (class_data['Bad Diff X-Engines'][ap_str] != 'bad') & (class_data['Redcal chi^2'][ap_str] == 'bad')\n",
    "    if np.any(flagged_for_cspa) and not np.all(fh.final_flags[ap_str] | flagged_for_cspa):\n",
    "        cspa = metric_data['Redcal chi^2'][ap_str]\n",
    "        new_flags = metric_convolution_flagging(cspa, flagged_for_cspa, oc_cspa_suspect, sigma=SMOOTHING_SCALE_NFILES, max_flag_gap=MAX_FLAG_GAP_NFILES)\n",
    "        if np.mean(new_flags[~apriori_flags]) > CHISQ_MAX_FLAG_FRAC:\n",
    "            new_flags[:] = True\n",
    "    else:\n",
    "        new_flags = flagged_for_cspa\n",
    "    fh.update(ap_str, flagged_for_cspa, new_flags, 'Redcal chi^2')\n",
    "fh.summarize('flagging antennas for high redcal chi^2')\n",
    "\n",
    "# STEP 8: FLAG FOR TOO EVEN/ODD ZEROS AND EXCESS DIFF POWER (USUALLY PACKET ISSUES)\n",
    "for ap_str in ap_strs:\n",
    "    rtp_flags = (class_data['Even/Odd Zeros'][ap_str] == 'bad')\n",
    "    new_flags = np.array(rtp_flags)\n",
    "    if np.mean(rtp_flags[~apriori_flags]) > XENGINE_MAX_FLAG_FRAC:\n",
    "        new_flags[:] = True\n",
    "    fh.update(ap_str, rtp_flags, new_flags, 'Even/Odd Zeros')\n",
    "fh.summarize('flagging antennas for excess even/odd zeros')\n",
    "for ap_str in ap_strs:\n",
    "    rtp_flags = (class_data['Bad Diff X-Engines'][ap_str] == 'bad')\n",
    "    new_flags = np.array(rtp_flags)\n",
    "    if np.mean(rtp_flags[~apriori_flags]) > XENGINE_MAX_FLAG_FRAC:\n",
    "        new_flags[:] = True\n",
    "    fh.update(ap_str, rtp_flags, new_flags, 'Bad Diff X-Engines')\n",
    "fh.summarize('flagging antennas for excess power in specific X-engines in the diffs')\n",
    "\n",
    "\n",
    "# STEP 9: FLAG ANTENNAS THAT ARE ALREADY LARGELY FLAGGED\n",
    "for ap_str in ap_strs:\n",
    "    new_flags = np.array(fh.final_flags[ap_str])\n",
    "    impose_max_flag_gap(new_flags)\n",
    "    if np.mean(new_flags[~apriori_flags]) > OVERALL_MAX_FLAG_FRAC:\n",
    "        new_flags[:] = True\n",
    "    fh.update(ap_str, fh.final_flags[ap_str], new_flags, 'Frequently Flagged')\n",
    "fh.summarize('flagging frequently-flagged antennas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1866c9",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flagging_board():\n",
    "    cmap = matplotlib.colors.ListedColormap(['blue', 'black', 'red', 'orange'])\n",
    "    to_plot = np.vstack([np.where(~fh.final_flags[ap_str] & ~original_flags[ap_str], 0,\n",
    "                                  np.where(~fh.final_flags[ap_str] & original_flags[ap_str], -1,\n",
    "                                           np.where(fh.final_flags[ap_str] & ~original_flags[ap_str], 2, 1))) for ap_str in ap_strs])\n",
    "\n",
    "    plt.figure(figsize=(14, len(ants) / 10), dpi=100)\n",
    "    plt.imshow(to_plot, aspect='auto', interpolation='none', cmap=cmap, vmin=-1.5, vmax=2.5,\n",
    "               extent=[frac_jds[0], frac_jds[-1], len(ants), 0])\n",
    "    plt.xlabel(f'JD - {int(jds[0])}')\n",
    "    plt.yticks(ticks=np.arange(.5, len(ants)+.5), labels=[ant for ant in ants], fontsize=6)\n",
    "    plt.ylabel('Antenna Number (East First, Then North)')\n",
    "    plt.gca().tick_params(right=True, top=True, labelright=True, labeltop=True)\n",
    "    cbar = plt.colorbar(location='top', aspect=40)\n",
    "    cbar.set_ticks([-1, 0, 1, 2])\n",
    "    cbar.set_ticklabels(['RTP Flag Removed', 'No Flags', 'Flagged by RTP and Here', 'Flagged Here Only'])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9777c427",
   "metadata": {},
   "source": [
    "# *Figure 1: Flag Summary vs. JD*\n",
    "\n",
    "This figure summarizes the flagging harmonization performed in this notebook, showing which flags were added (or potentially removed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde60694",
   "metadata": {},
   "outputs": [],
   "source": [
    "flagging_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_frac_array_plot():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 8), dpi=100, gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "    def flag_frac_panel(ax, antnums, radius=7, legend=False):\n",
    "\n",
    "        ang_dict = {'e': (225, 405), 'n': (45, 225)}\n",
    "\n",
    "        xpos = np.array([hd.antpos[antnum][0] for antnum in ants if antnum in antnums])\n",
    "        ypos = np.array([hd.antpos[antnum][1] for antnum in ants if antnum in antnums])\n",
    "        scatter = ax.scatter(xpos, ypos, c='w', s=0)\n",
    "        for ap_str in ap_strs:\n",
    "            antnum, pol = int(ap_str[:-1]), ap_str[-1]\n",
    "            if antnum in antnums:\n",
    "                ax.add_artist(matplotlib.patches.Wedge(tuple(hd.antpos[antnum][0:2]), radius, *ang_dict[pol], color='grey'))\n",
    "                flag_frac = np.mean(fh.final_flags[ap_str][~solar_flags])\n",
    "                if flag_frac > .05:\n",
    "                    ax.add_artist(matplotlib.patches.Wedge(tuple(hd.antpos[antnum][0:2]), radius * np.sqrt(flag_frac), *ang_dict[pol], color='r'))\n",
    "                ax.text(hd.antpos[antnum][0], hd.antpos[antnum][1], str(antnum), color='w',  va='center', ha='center', zorder=100)\n",
    "\n",
    "        ax.axis('equal')\n",
    "        ax.set_xlim([np.min(xpos) - radius * 2, np.max(xpos) + radius * 2])\n",
    "        ax.set_ylim([np.min(ypos) - radius * 2, np.max(ypos) + radius * 2])\n",
    "        ax.set_xlabel(\"East-West Position (meters)\", size=12)\n",
    "        ax.set_ylabel(\"North-South Position (meters)\", size=12)\n",
    "\n",
    "        if legend:\n",
    "            legend_objs = []\n",
    "            legend_labels = []\n",
    "\n",
    "            legend_objs.append(matplotlib.lines.Line2D([0], [0], marker='o', color='w', markeredgecolor='grey', markerfacecolor='grey', markersize=15))\n",
    "            unflagged_nights = lambda pol: np.sum([np.mean(~fh.final_flags[ap_str][~solar_flags]) for ap_str in ap_strs if ap_str[-1] == pol])\n",
    "            legend_labels.append((' \\u2571\\n').join([f'{unflagged_nights(pol):.1f} unflagged {pol}-polarized\\nantenna-nights.' for pol in ['e', 'n']]))\n",
    "\n",
    "            legend_objs.append(matplotlib.lines.Line2D([0], [0], marker='o', color='w', markeredgecolor='red', markerfacecolor='red', markersize=15))\n",
    "            unflagged_nights = lambda pol: np.sum([np.mean(fh.final_flags[ap_str][~solar_flags]) for ap_str in ap_strs if ap_str[-1] == pol])\n",
    "            legend_labels.append((' \\u2571\\n').join([f'{unflagged_nights(pol):.1f} flagged {pol}-polarized\\nantenna-nights.' for pol in ['e', 'n']]))        \n",
    "            ax.legend(legend_objs, legend_labels, ncol=1, fontsize=12)\n",
    "\n",
    "    flag_frac_panel(axes[0], [ant for ant in ants if ant < 320], radius=7)\n",
    "    flag_frac_panel(axes[1], [ant for ant in ants if ant >= 320], radius=50, legend=True)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111746d2",
   "metadata": {},
   "source": [
    "# *Figure 2: Array Flag Fraction Summary*\n",
    "\n",
    "Flagging fraction of nighttime data for each antpol. Top-left semicircles are North-South polarized antpols; bottom right semicircles are East-West polarized antpols. Flag fraction is proportional to red area of each semicircle. Left panel is core antennas, right panel is outriggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_frac_array_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e24261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_summary_vs_jd():\n",
    "    plt.figure(figsize=(14, 5), dpi=100,)\n",
    "    plt.plot(frac_jds, np.mean(np.vstack([fh.final_flags[ap_str] for ap_str in ap_strs if ap_str[-1] == 'e']), axis=0), '.', ms=2, label='EW-Polarized')\n",
    "    plt.plot(frac_jds, np.mean(np.vstack([fh.final_flags[ap_str] for ap_str in ap_strs if ap_str[-1] == 'n']), axis=0), '.', ms=2, label='NS-Polarized')\n",
    "    plt.plot(frac_jds, np.mean(np.vstack([fh.final_flags[ap_str] for ap_str in ap_strs]), axis=0), 'k.', ms=3, label='All Antpols')\n",
    "    plt.legend()\n",
    "    plt.xlabel(f'JD - {int(np.floor(jds[0]))}')\n",
    "    plt.ylabel('Fraction of Antennas Flagged')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927a636",
   "metadata": {},
   "source": [
    "# *Figure 3: Flag Fraction vs. JD Summary*\n",
    "\n",
    "This plot shows the fraction of the array that's flagged for any reason as a function of time, both overall and per-polarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00077948",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_summary_vs_jd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_int(c):\n",
    "    return np.where(c == 'bad', 1.7, np.where(c=='suspect', 1, 0))\n",
    "\n",
    "def per_antenna_flag_harmonization_plots():\n",
    "    # compute convolution kernel\n",
    "    kernel = np.exp(-np.arange(-Ncsvs // 2, Ncsvs // 2 + 1)**2 / 2 / SMOOTHING_SCALE_NFILES**2)\n",
    "    kernel /= np.sum(kernel)\n",
    "    \n",
    "    # JD computations\n",
    "    djd = np.median(np.diff(jds))\n",
    "\n",
    "    # loop over ant-pols\n",
    "    for ap_str in ap_strs:\n",
    "        # if there are new nighttime, not-apriori flags\n",
    "        if np.sum(fh.final_flags[ap_str][~apriori_flags]) > np.sum(original_flags[ap_str][~apriori_flags]):\n",
    "            # if the new flags aren't just because of the OVERALL_MAX_FLAG_FRAC\n",
    "            if np.mean(original_flags[ap_str][~apriori_flags]) <= OVERALL_MAX_FLAG_FRAC:\n",
    "                for aps, category in fh.history.keys():\n",
    "                    if category == 'Frequently Flagged':\n",
    "                        continue\n",
    "                    if ap_str == aps:\n",
    "                        previous_flags, rtp_flags, new_flags = fh.history[(aps, category)]\n",
    "                        # if new flags were added for this reason\n",
    "                        if np.sum(new_flags[~apriori_flags]) > np.sum(rtp_flags[~apriori_flags]):\n",
    "                            plt.figure(figsize=(14, 3), dpi=100)\n",
    "                            \n",
    "                            # plot \n",
    "                            plt.scatter(frac_jds, metric_data[category][ap_str], c=class_to_int(class_data[category][ap_str]), s=3,\n",
    "                                        vmin=0, vmax=1.7, cmap='RdYlGn_r', label='Metric/Classification')\n",
    "                            plt.plot(frac_jds, convolve(metric_data[category][ap_str], kernel, mode='reflect'), 'k--', label='Smoothed Metric')\n",
    "                            plt.ylabel(category)\n",
    "                            plt.xlabel(f'JD - {int(np.floor(jds[0]))}')\n",
    "                            plt.xlim([np.min(frac_jds) - 10 * djd, 1.2 * np.max(frac_jds) - .2 * np.min(frac_jds)])\n",
    "                            \n",
    "                            # Indicate flagged stretches \n",
    "                            for i, bad_stretch in enumerate(true_stretches(rtp_flags)):\n",
    "                                plt.axvspan(frac_jds[bad_stretch.start] - djd / 2, frac_jds[bad_stretch.stop - 1] + djd / 2, zorder=0, color='red', alpha=.75, lw=0,\n",
    "                                            label=(f'RTP Flags:\\n{np.mean(rtp_flags[~solar_flags]):.2%} of night' if i == 0 else None))\n",
    "                            for i, bad_stretch in enumerate(true_stretches(new_flags & ~apriori_flags)):\n",
    "                                plt.axvspan(frac_jds[bad_stretch.start] - djd / 2, frac_jds[bad_stretch.stop - 1] + djd / 2, zorder=0, color='orange', alpha=.75, lw=0,\n",
    "                                            label=(f'Harmonized Flags:\\n{np.mean((new_flags & ~apriori_flags)[~solar_flags]):.2%} of night' if i == 0 else None))\n",
    "                            for i, bad_stretch in enumerate(true_stretches((fh.final_flags[ap_str] & ~new_flags) | apriori_flags)):\n",
    "                                plt.axvspan(frac_jds[bad_stretch.start] - djd / 2, frac_jds[bad_stretch.stop - 1] + djd / 2, zorder=0, color='purple', alpha=.75, lw=0,\n",
    "                                            label=(f'All Final Flags:\\n{np.mean(fh.final_flags[ap_str][~solar_flags]):.2%} of night' if i == 0 else None))                            \n",
    "\n",
    "                            plt.legend(title=f'{ap_str}: {category}', loc='upper right')\n",
    "                            plt.tight_layout()\n",
    "                            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da50e7e",
   "metadata": {},
   "source": [
    "# *Figure 4: Per-Antenna Flag Harmonization Summary*\n",
    "\n",
    "This figure shows antennas that had their flags non-trivially modified by this notebook and tries to show the underlying rationale for why that happened. Sometimes the flag harmonizaton performed here leads to the whole antenna getting flagged; sometimes it just leads to large chunks of the night getting flagged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_antenna_flag_harmonization_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678d75a",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_history = 'Produced by full_day_antenna_flagging notebook with the following environment:\\n' + '=' * 65 + '\\n' + os.popen('conda env export').read() + '=' * 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a524bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_flag_files = [cal.replace(CAL_SUFFIX, OUT_FLAG_SUFFIX) for cal in cal_files]\n",
    "for i, (cal, out_flag_file) in enumerate(zip(cal_files, out_flag_files)):\n",
    "    # create UVFlag object based on UVCal\n",
    "    uvc = UVCal()\n",
    "    uvc.read_calfits(cal)\n",
    "    uvf = UVFlag(uvc, mode='flag')\n",
    "    \n",
    "    # fill with flags\n",
    "    for ant_ind, antnum in enumerate(uvf.ant_array):\n",
    "        for pol_ind, polnum in enumerate(uvf.polarization_array):\n",
    "            pol = {'Jee': 'e', 'Jnn': 'n'}[utils.jnum2str(polnum, x_orientation=uvf.telescope.get_x_orientation_from_feeds())]\n",
    "            uvf.flag_array[ant_ind, :, :, pol_ind] = fh.final_flags[f'{antnum}{pol}'][i]\n",
    "\n",
    "    # write to disk\n",
    "    uvf.history += add_to_history        \n",
    "    uvf.write(out_flag_file, clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b391f",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

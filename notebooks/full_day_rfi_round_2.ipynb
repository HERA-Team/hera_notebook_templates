{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468fb39",
   "metadata": {},
   "source": [
    "# Second Round of Full Day RFI Flagging\n",
    "\n",
    "**by Josh Dillon**, last updated July 28, 2023\n",
    "\n",
    "This notebook is synthesizes information from individual [delay_filtered_average_zscore](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/delay_filtered_average_zscore.ipynb) notebooks to find low-level RFI and flag it. That notebook takes `smooth_cal`ibrated data, redundantly averages it, performs a high-pass delay filter, and then incoherently averages across baselines, creating a per-polarization z-score. This notebook then takes that whole night of z-scores and finds a new set of flags to both add to the `smooth_cal` files, which are updated in place, and to write down as new `UVFlag` waterfall-type `.h5` files.\n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "\n",
    "\n",
    "# [• Figure 1: Waterfall of Maximum z-Score of Either Polarization Before Round 2 Flagging](#Figure-1:-Waterfall-of-Maximum-z-Score-of-Either-Polarization-Before-Round-2-Flagging)\n",
    "# [• Figure 2: Histogram of z-scores](#Figure-2:-Histogram-of-z-scores)\n",
    "# [• Figure 3: Waterfall of Maximum z-Score of Either Polarization After Round 2 Flagging](#Figure-3:-Waterfall-of-Maximum-z-Score-of-Either-Polarization-After-Round-2-Flagging)\n",
    "# [• Figure 4: Spectra of Time-Averaged z-Scores](#Figure-4:-Spectra-of-Time-Averaged-z-Scores)\n",
    "# [• Figure 5: Summary of Flags Before and After Round 2 Flagging](#Figure-5:-Summary-of-Flags-Before-and-After-Round-2-Flagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63080ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import warnings\n",
    "from pyuvdata import UVFlag, UVCal\n",
    "from hera_cal import utils\n",
    "from hera_qm import xrfi\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "_ = np.seterr(all='ignore')  # get rid of red warnings\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06891bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input data file names\n",
    "SUM_FILE = os.environ.get(\"SUM_FILE\", None)\n",
    "# SUM_FILE = '/lustre/aoc/projects/hera/h6c-analysis/IDR2/2459861/zen.2459861.25297.sum.uvh5'\n",
    "SUM_SUFFIX = os.environ.get(\"SUM_SUFFIX\", 'sum.uvh5')\n",
    "\n",
    "# get input and output suffixes\n",
    "SMOOTH_CAL_SUFFIX = os.environ.get(\"CAL_SUFFIX\", 'sum.smooth.calfits')\n",
    "ZSCORE_SUFFIX =  os.environ.get(\"ZSCORE_SUFFIX\", 'sum.red_avg_zscore.h5')\n",
    "FLAG_WATERFALL2_SUFFIX = os.environ.get(\"FLAG_WATERFALL2_SUFFIX\", 'sum.flag_waterfall_round_2.h5')\n",
    "\n",
    "# build globs\n",
    "sum_glob = '.'.join(SUM_FILE.split('.')[:-3]) + '.*.' + SUM_SUFFIX\n",
    "cal_files_glob = sum_glob.replace(SUM_SUFFIX, SMOOTH_CAL_SUFFIX)\n",
    "zscore_glob = sum_glob.replace(SUM_SUFFIX, ZSCORE_SUFFIX)\n",
    "\n",
    "# get flagging parameters\n",
    "Z_THRESH = float(os.environ.get(\"Z_THRESH\", 5))\n",
    "WS_Z_THRESH = float(os.environ.get(\"WS_Z_THRESH\", 4))\n",
    "AVG_Z_THRESH = float(os.environ.get(\"AVG_Z_THRESH\", 1))\n",
    "MAX_FREQ_FLAG_FRAC = float(os.environ.get(\"MAX_FREQ_FLAG_FRAC\", .25))\n",
    "MAX_TIME_FLAG_FRAC = float(os.environ.get(\"MAX_TIME_FLAG_FRAC\", .1))\n",
    "\n",
    "for setting in ['Z_THRESH', 'WS_Z_THRESH', 'AVG_Z_THRESH', 'MAX_FREQ_FLAG_FRAC', 'MAX_TIME_FLAG_FRAC']:\n",
    "    print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114c12c",
   "metadata": {},
   "source": [
    "# Load z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load z-scores\n",
    "zscore_files = sorted(glob.glob(zscore_glob))\n",
    "print(f'Found {len(zscore_files)} *.{ZSCORE_SUFFIX} files starting with {zscore_files[0]}.')\n",
    "uvf = UVFlag(zscore_files, use_future_array_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a865db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get calibration solution files\n",
    "cal_files = sorted(glob.glob(cal_files_glob))\n",
    "print(f'Found {len(cal_files)} *.{SMOOTH_CAL_SUFFIX} files starting with {cal_files[0]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80896b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(zscore_files) == len(cal_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract z-scores and correct by a single number per polarization to account for biases created by filtering\n",
    "zscore = {pol: uvf.metric_array[:, :, np.argwhere(uvf.polarization_array == utils.polstr2num(pol, x_orientation=uvf.x_orientation))[0][0]] for pol in ['ee', 'nn']}\n",
    "zscore = {pol: zscore[pol] - np.nanmedian(zscore[pol]) for pol in zscore}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = uvf.freq_array\n",
    "times = uvf.time_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [freqs[0] / 1e6, freqs[-1] / 1e6, times[-1] - int(times[0]), times[0] - int(times[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_max_z_score(zscore, flags=None):\n",
    "    if flags is None:\n",
    "        flags = np.any(~np.isfinite(list(zscore.values())), axis=0)\n",
    "    plt.figure(figsize=(14,10), dpi=100)\n",
    "    plt.imshow(np.where(flags, np.nan, np.nanmax([zscore['ee'], zscore['nn']], axis=0)), aspect='auto', \n",
    "               cmap='coolwarm', interpolation='none', vmin=-10, vmax=10, extent=extent)\n",
    "    plt.colorbar(location='top', label='Max z-score of either polarization', extend='both', aspect=40, pad=.02)\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel(f'JD - {int(times[0])}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6546fd",
   "metadata": {},
   "source": [
    "# *Figure 1: Waterfall of Maximum z-Score of Either Polarization Before Round 2 Flagging*\n",
    "\n",
    "Shows the worse of the two results from [delay_filtered_average_zscore](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/delay_filtered_average_zscore.ipynb) from either polarization. Dips near flagged channels are expected, due to overfitting of noise. Positive-going excursions are problematic and likely evidence of RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbf9eb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_max_z_score(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram():\n",
    "    plt.figure(figsize=(14,4), dpi=100)\n",
    "    bins = np.arange(-50, 100, .1)\n",
    "    hist_ee = plt.hist(np.ravel(zscore['ee']), bins=bins, density=True, label='ee-polarized z-scores', alpha=.5)\n",
    "    hist_nn = plt.hist(np.ravel(zscore['nn']), bins=bins, density=True, label='nn-polarized z-scores', alpha=.5)\n",
    "    plt.plot(bins, (2*np.pi)**-.5 * np.exp(-bins**2 / 2), 'k:', label='Gaussian approximate\\nnoise-only distribution')\n",
    "    plt.axvline(WS_Z_THRESH, c='r', ls='--', label='Watershed z-score')\n",
    "    plt.axvline(Z_THRESH, c='r', ls='-', label='Threshold z-score')\n",
    "    plt.yscale('log')\n",
    "    all_densities = np.concatenate([hist_ee[0][hist_ee[0] > 0], hist_nn[0][hist_nn[0] > 0]]) \n",
    "    plt.ylim(np.min(all_densities) / 2, np.max(all_densities) * 2)\n",
    "    plt.xlim([-50, 100])\n",
    "    plt.legend()\n",
    "    plt.xlabel('z-score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ad7bc",
   "metadata": {},
   "source": [
    "# *Figure 2: Histogram of z-scores*\n",
    "\n",
    "Shows a comparison of the histogram of z-scores in this file (one per polarization) to a Gaussian approximation of what one might expect from thermal noise. Without filtering, the actual distribution is a weighted sum of Rayleigh distributions. Filtering further complicates this. To make the z-scores more reliable, a single per-polarization median is subtracted from each waterfall, which allows us to flag low-level outliers with more confidence. Any points beyond the solid red line are flagged. Any points neighboring a flag beyond the dashed red line are also flagged. Finally, flagging is performed for low-level outliers in whole times or channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d91b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4511bc55",
   "metadata": {},
   "source": [
    "## Perform flagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed324abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteratively_flag_on_averaged_zscore(flags, zscore, avg_z_thresh=1.5, verbose=True):\n",
    "    '''Flag whole integrations or channels based on average z-score. This is done\n",
    "    iteratively to prevent bad times affecting channel averages or vice versa.'''\n",
    "    flagged_chan_count = 0\n",
    "    flagged_int_count = 0\n",
    "    while True:\n",
    "        zspec = np.nanmean(np.where(flags, np.nan, zscore), axis=0)\n",
    "        ztseries = np.nanmean(np.where(flags, np.nan, zscore), axis=1)\n",
    "\n",
    "        if (np.nanmax(zspec) < avg_z_thresh) and (np.nanmax(ztseries) < avg_z_thresh):\n",
    "            break\n",
    "\n",
    "        if np.nanmax(zspec) >= np.nanmax(ztseries):\n",
    "            flagged_chan_count += np.sum((zspec >= max(ztseries)) & (zspec >= avg_z_thresh))\n",
    "            flags[:, (zspec >= max(ztseries)) & (zspec >= avg_z_thresh)] = True\n",
    "        else:\n",
    "            flagged_int_count += np.sum((ztseries >= max(zspec)) & (ztseries >= avg_z_thresh))\n",
    "            flags[(ztseries >= max(zspec)) & (ztseries >= avg_z_thresh), :] = True\n",
    "\n",
    "    if verbose:\n",
    "        print(f'\\tFlagging an additional {flagged_int_count} integrations and {flagged_chan_count} channels.')\n",
    "\n",
    "def impose_max_chan_flag_frac(flags, max_flag_frac=.25, verbose=True):\n",
    "    '''Flag channels already flagged more than max_flag_frac (excluding completely flagged times).'''\n",
    "    unflagged_times = ~np.all(flags, axis=1)\n",
    "    frequently_flagged_chans =  np.mean(flags[unflagged_times, :], axis=0) >= max_flag_frac\n",
    "    if verbose:\n",
    "        print(f'\\tFlagging {np.sum(frequently_flagged_chans) - np.sum(np.all(flags, axis=0))} channels previously flagged {max_flag_frac:.2%} or more.')        \n",
    "    flags[:, frequently_flagged_chans] = True \n",
    "        \n",
    "def impose_max_time_flag_frac(flags, max_flag_frac=.25, verbose=True):\n",
    "    '''Flag times already flagged more than max_flag_frac (excluding completely flagged channels).'''\n",
    "    unflagged_chans = ~np.all(flags, axis=0)\n",
    "    frequently_flagged_times =  np.mean(flags[:, unflagged_chans], axis=1) >= max_flag_frac\n",
    "    if verbose:\n",
    "        print(f'\\tFlagging {np.sum(frequently_flagged_times) - np.sum(np.all(flags, axis=1))} times previously flagged {max_flag_frac:.2%} or more.')\n",
    "    flags[frequently_flagged_times, :] = True             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = np.any(~np.isfinite(list(zscore.values())), axis=0)\n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged to start.')\n",
    "\n",
    "# flag largest outliers\n",
    "for pol in ['ee', 'nn']:\n",
    "    flags |= (zscore[pol] > Z_THRESH) \n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged after flagging z > {Z_THRESH} outliers.')\n",
    "    \n",
    "# watershed flagging\n",
    "while True:\n",
    "    nflags = np.sum(flags)\n",
    "    for pol in ['ee', 'nn']:\n",
    "        flags |= xrfi._ws_flag_waterfall(zscore[pol], flags, WS_Z_THRESH)\n",
    "    if np.sum(flags) == nflags:\n",
    "        break\n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged after watershed flagging on z > {WS_Z_THRESH} neightbors of prior flags.')\n",
    "        \n",
    "# flag whole integrations or channels\n",
    "while True:\n",
    "    nflags = np.sum(flags)\n",
    "    for pol in ['ee', 'nn']:    \n",
    "        iteratively_flag_on_averaged_zscore(flags, zscore[pol], avg_z_thresh=AVG_Z_THRESH, verbose=True)\n",
    "        impose_max_chan_flag_frac(flags, max_flag_frac=MAX_FREQ_FLAG_FRAC, verbose=True)\n",
    "        impose_max_time_flag_frac(flags, max_flag_frac=MAX_TIME_FLAG_FRAC, verbose=True)\n",
    "    if np.sum(flags) == nflags:\n",
    "        break  \n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged after flagging whole times and channels with average z > {AVG_Z_THRESH}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4300e",
   "metadata": {},
   "source": [
    "## Show results of flagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb7367",
   "metadata": {},
   "source": [
    "# *Figure 3: Waterfall of Maximum z-Score of Either Polarization After Round 2 Flagging*\n",
    "\n",
    "The same as Figure 1, but after the flagging performed in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_max_z_score(zscore, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_spectra():\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14,6), dpi=100, sharex=True, sharey=True, gridspec_kw={'hspace': 0})\n",
    "    for ax, pol in zip(axes, ['ee', 'nn']):\n",
    "\n",
    "        ax.plot(freqs / 1e6, np.nanmean(zscore[pol], axis=0),'r', label=f'{pol}-Polarization Before Round 2 Flagging', lw=.5)\n",
    "        ax.plot(freqs / 1e6, np.nanmean(np.where(flags, np.nan, zscore[pol]), axis=0), label=f'{pol}-Polarization After Round 2 Flagging')\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_ylabel('Time-Averged Z-Score\\n(Excluding Flags)')\n",
    "        ax.set_ylim(-11, 11)\n",
    "    axes[1].set_xlabel('Frequency (MHz)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0361778",
   "metadata": {},
   "source": [
    "# *Figure 4: Spectra of Time-Averaged z-Scores*\n",
    "\n",
    "The average along the time axis of Figures 1 and 3 (though now separated per-polarization). This plot is useful for showing channels with repeated low-level RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da310f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore_spectra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_flagging():\n",
    "    plt.figure(figsize=(14,10), dpi=100)\n",
    "    cmap = matplotlib.colors.ListedColormap(((0, 0, 0),) + matplotlib.cm.get_cmap(\"Set2\").colors[0:2])\n",
    "    plt.imshow(np.where(np.any(~np.isfinite(list(zscore.values())), axis=0), 1, np.where(flags, 2, 0)), \n",
    "               aspect='auto', cmap=cmap, interpolation='none', extent=extent)\n",
    "    plt.clim([-.5, 2.5])\n",
    "    cbar = plt.colorbar(location='top', aspect=40, pad=.02)\n",
    "    cbar.set_ticks([0, 1, 2])\n",
    "    cbar.set_ticklabels(['Unflagged', 'Previously Flagged', 'Flagged Here Using Delayed Filtered z-Scores'])\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel(f'JD - {int(times[0])}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888c571",
   "metadata": {},
   "source": [
    "# *Figure 5: Summary of Flags Before and After Round 2 Flagging*\n",
    "\n",
    "This plot shows which times and frequencies were flagged before and after this notebook. It is directly comparable to Figure 5 of the first round [full_day_rfi](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/full_day_rfi.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_flagging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85224d0f",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14884b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_history = 'by full_day_rfi_round_2 notebook with the following environment:\\n' + '=' * 65 + '\\n' + os.popen('conda env export').read() + '=' * 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a400c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tind = 0\n",
    "for cal_file in cal_files:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")    \n",
    "        \n",
    "        # update cal_file\n",
    "        uvc = UVCal()\n",
    "        uvc.read(cal_file, use_future_array_shapes=True)\n",
    "        uvc.flag_array |= (flags[tind:tind + len(uvc.time_array), :].T)[None, :, :, None]\n",
    "        uvc.history += 'Modified ' + add_to_history\n",
    "        uvc.write_calfits(cal_file, clobber=True)\n",
    "\n",
    "        # Create new flag object\n",
    "        uvf = UVFlag(uvc, waterfall=True, mode='flag')\n",
    "        uvf.flag_array |= flags[tind:tind + len(uvc.time_array), :, None]\n",
    "        uvf.history += 'Produced ' + add_to_history\n",
    "        uvf.write(cal_file.replace(SMOOTH_CAL_SUFFIX, FLAG_WATERFALL2_SUFFIX), clobber=True)\n",
    "        \n",
    "        # increment time index\n",
    "        tind += len(uvc.time_array)\n",
    "\n",
    "print(f'Saved {len(cal_files)} *.{FLAG_WATERFALL2_SUFFIX} files starting with {cal_files[0].replace(SMOOTH_CAL_SUFFIX, FLAG_WATERFALL2_SUFFIX)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e1ea9f",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67d967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f691a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d337ad-0853-48b7-ae41-93682103ecf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:27:40.494407Z",
     "iopub.status.busy": "2025-01-31T18:27:40.494172Z",
     "iopub.status.idle": "2025-01-31T18:27:40.498516Z",
     "shell.execute_reply": "2025-01-31T18:27:40.497684Z",
     "shell.execute_reply.started": "2025-01-31T18:27:40.494388Z"
    }
   },
   "source": [
    "# Single Baseline 2D DPSS Filtered SNRs\n",
    "\n",
    "**by Josh Dillon and Tyler Cox**, last updated February 6, 2025\n",
    "\n",
    "This notebook performs single-baseline, full-day DPSS filtering on corner-turned files to calculate a 2D DPSS filtered SNR, which can later be combined to look for residual RFI or other systematics that may have evaded Round 2 RFI flagging based on 1D DPSS filtering in frequency/delay.\n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "# [• Figure 1: Waterfalls of 2D DPSS Filtered SNRs](#Figure-1:-Waterfalls-of-2D-DPSS-Filtered-SNRs)\n",
    "# [• Figure 2: Histograms of 2D DPSS Filtered SNRs](#Figure-2:-Histograms-of-2D-DPSS-Filtered-SNRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3af62-cb84-4cbc-a7b8-9a964aefb7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95540aa3-d138-41c4-8cae-7290c9d91492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import yaml\n",
    "import glob\n",
    "import copy\n",
    "import re\n",
    "from hera_cal import io, redcal, red_groups\n",
    "from hera_cal.frf import sky_frates\n",
    "from hera_cal.smooth_cal import solve_2D_DPSS\n",
    "from hera_filters.dspec import dpss_operator, sparse_linear_fit_2D\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a7e03-73bc-422e-946a-2fcef7fd0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_AVG_FILE = os.environ.get(\"RED_AVG_FILE\", None)\n",
    "# RED_AVG_FILE = '/lustre/aoc/projects/hera/jsdillon/H6C/corner_turn_dev/2459861/zen.2459861.25364.sum.smooth_calibrated.red_avg.uvh5'\n",
    "\n",
    "CORNER_TURN_MAP_YAML = os.environ.get(\"CORNER_TURN_MAP_YAML\", \n",
    "                                        os.path.join(os.path.dirname(RED_AVG_FILE), \"single_baseline_files/corner_turn_map.yaml\"))\n",
    "\n",
    "SNR_SUFFIX =  os.environ.get(\"SNR_SUFFIX\", \".2Dfilt_SNR.uvh5\")\n",
    "\n",
    "FM_LOW_FREQ = float(os.environ.get(\"FM_LOW_FREQ\", 87.5)) # in MHz\n",
    "FM_HIGH_FREQ = float(os.environ.get(\"FM_HIGH_FREQ\", 108.0)) # in MHz\n",
    "\n",
    "FILTER_DELAY = float(os.environ.get(\"FILTER_DELAY\", 750)) # in ns\n",
    "EIGENVAL_CUTOFF = float(os.environ.get(\"EIGENVAL_CUTOFF\", 1e-12))\n",
    "\n",
    "for setting in ['RED_AVG_FILE', 'CORNER_TURN_MAP_YAML', 'SNR_SUFFIX']:\n",
    "    print(f'{setting} = \"{eval(setting)}\"')\n",
    "for setting in ['FM_LOW_FREQ', 'FM_HIGH_FREQ', 'FILTER_DELAY', 'EIGENVAL_CUTOFF']:\n",
    "    print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98c109-2ce1-447a-8dad-372cb5a396fe",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1aaf0-3e7c-43ad-af50-1e8cd86325a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CORNER_TURN_MAP_YAML, 'r') as file:\n",
    "    corner_turn_map = yaml.unsafe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933c1dd-7f1b-4617-a2a2-8193de766490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get autocorrelations\n",
    "all_outfiles = [outfile for outfiles in corner_turn_map['files_to_outfiles_map'].values() for outfile in outfiles]\n",
    "for outfile in all_outfiles:\n",
    "    match = re.search(r'\\.(\\d+)_(\\d+)\\.', os.path.basename(outfile))\n",
    "    if match and match.group(1) == match.group(2):\n",
    "        hd_autos = io.HERAData(outfile)\n",
    "        autos, _, _ = hd_autos.read(polarizations=['ee', 'nn'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbb8ed-3122-4de4-9de9-f025041ccf19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T02:57:17.314387Z",
     "iopub.status.busy": "2025-02-04T02:57:17.314188Z",
     "iopub.status.idle": "2025-02-04T02:57:17.317006Z",
     "shell.execute_reply": "2025-02-04T02:57:17.316539Z",
     "shell.execute_reply.started": "2025-02-04T02:57:17.314369Z"
    }
   },
   "source": [
    "## Define functions for main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795003a-5f32-40b2-ab54-5eb95a5e6f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices(flags):\n",
    "    '''Gets the minimal boxes of all unflagged data above and below FM, handling case where one might be entirely flagged.'''\n",
    "    and_of_flags = np.all([flags[bl] for bl in flags], axis=0)\n",
    "    low_band, high_band, tslice = None, None, None\n",
    "    if not np.all(and_of_flags):    \n",
    "        # get band slices\n",
    "        not_always_flagged_freqs = data.freqs[~np.all(and_of_flags, axis=0)]\n",
    "        if np.any(not_always_flagged_freqs < FM_LOW_FREQ * 1e6):\n",
    "            low_start = np.argwhere(data.freqs == np.min(not_always_flagged_freqs))[0][0]\n",
    "            low_stop = np.argwhere(data.freqs == np.max(not_always_flagged_freqs[not_always_flagged_freqs < FM_LOW_FREQ * 1e6]))[0][0]\n",
    "            low_band = slice(low_start, low_stop + 1)\n",
    "        if np.any(not_always_flagged_freqs > FM_LOW_FREQ * 1e6):\n",
    "            high_start = np.argwhere(data.freqs == np.min(not_always_flagged_freqs[not_always_flagged_freqs > FM_LOW_FREQ * 1e6]))[0][0]\n",
    "            high_stop = np.argwhere(data.freqs == np.max(not_always_flagged_freqs))[0][0]\n",
    "            high_band = slice(high_start, high_stop + 1)\n",
    "        \n",
    "        # get time slice\n",
    "        not_always_flagged_tinds = np.arange(len(data.times))[~np.all(and_of_flags, axis=1)]\n",
    "        tslice = slice(np.min(not_always_flagged_tinds), np.max(not_always_flagged_tinds) + 1)\n",
    "    return low_band, high_band, tslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac437101-22a2-4c70-8612-1c86da88b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_filtered_SNR_waterfalls():\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=(14,10), dpi=100, sharex=True, sharey=True)\n",
    "    extent = [data.freqs[0] / 1e6, data.freqs[-1] / 1e6, data.times[-1] - int(data.times[0]), data.times[0] - int(data.times[0])]\n",
    "    vmax = 10\n",
    "    \n",
    "    for bl, ax in zip(data, axes):\n",
    "        im = ax.imshow(np.where(flags[bl], np.nan, np.abs(filtered_SNR[bl])), aspect='auto', interpolation='none', cmap='afmhot_r', vmin=0, vmax=vmax, extent=extent)\n",
    "        ax.set_title(bl)\n",
    "        ax.set_xlabel('Frequency (MHz)')\n",
    "    \n",
    "    axes[0].set_ylabel(f'JD - {int(data.times[0])}')\n",
    "    plt.tight_layout()\n",
    "    largest_pixel = np.max([np.max(np.abs(filtered_SNR[bl][~flags[bl]])) \n",
    "                            for bl in filtered_SNR if not np.all(flags[bl])])\n",
    "    plt.colorbar(im, ax=axes, label='|2D DPSS Filtered SNR|', pad=.02, \n",
    "                 extend=('max' if largest_pixel > vmax else None))\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037fef5-57aa-4f1a-afc4-b9c9db01b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_filtered_SNR_histograms():\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    bins = np.arange(0, 25, .05)\n",
    "    \n",
    "    all_densities = []\n",
    "    for bl in filtered_SNR:\n",
    "        hist = plt.hist(np.where(flags[bl], np.nan, np.abs(filtered_SNR[bl])).ravel(), bins=bins, label=str(bl), density=True, alpha=.5)\n",
    "        all_densities.extend(hist[0][hist[0] > 0])\n",
    "    \n",
    "    plt.plot(bins, 2 * bins * np.exp(-bins**2), 'k--', label='Rayleigh Distribution (Noise-Only)')\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(np.min(all_densities) / 2, np.max(all_densities) * 2)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlabel('2D DPSS Filtered SNR')\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e825ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_variance_correction(flags, time_filters, freq_filters):\n",
    "    \"\"\"\n",
    "    Estimate the variance correction from a 2D DPSS fit assuming the flags are separable and correcting \n",
    "    for the portion of the flags which are not separable\n",
    "    \"\"\"\n",
    "    # Get the separable portion of the flags\n",
    "    ntimes, nfreqs = flags.shape\n",
    "    freq_mask = (~np.all(flags, axis=0)).astype(float)\n",
    "    time_mask = (~np.all(flags, axis=1)).astype(float)\n",
    "    \n",
    "    # Compute the leverage for the frequency-axis\n",
    "    leverage_f = np.sum(\n",
    "        freq_filters.T * np.linalg.pinv(\n",
    "            (freq_filters.T.conj() * freq_mask).dot(freq_filters)\n",
    "        ).dot(freq_filters.T.conj() * freq_mask),\n",
    "        axis=0\n",
    "    )\n",
    "    # Compute the leverage for the frequency-axis\n",
    "    leverage_t = np.sum(\n",
    "        time_filters.T *\n",
    "        np.linalg.pinv((time_filters.T.conj() * time_mask).dot(time_filters)).dot(time_filters.T.conj() * time_mask),\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    # Compute the outer product of the leverage along each axis\n",
    "    leverage = np.abs(np.outer(leverage_t, leverage_f))\n",
    "    \n",
    "    # Rescale the leverage to handle point which are not separable in time and frequencys\n",
    "    n_separable_flags = (\n",
    "        np.sum(1 - freq_mask) * ntimes + \n",
    "        np.sum(1 - time_mask) * nfreqs - \n",
    "        np.sum(1 - time_mask) * np.sum(1 - freq_mask)\n",
    "    )\n",
    "    flagging_frac = (flags.sum() - n_separable_flags) / flags.size\n",
    "    return (1 - flagging_frac ** 2) * (1 - leverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fe43f-1ade-40b8-838c-156c219eee2a",
   "metadata": {},
   "source": [
    "## Perform 2D DPSS filtering, looping over baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de77294-242d-4eeb-ab6b-bc2cb19c9e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfall_figs = []\n",
    "histogram_figs = []\n",
    "\n",
    "for single_bl_file in corner_turn_map['files_to_outfiles_map'][RED_AVG_FILE]:\n",
    "    # Load data\n",
    "    print(f'Now loading {single_bl_file}')\n",
    "    hd = io.HERAData(single_bl_file)\n",
    "    data, flags, nsamples = hd.read(polarizations=['ee', 'nn'])\n",
    "    dt = np.median(np.diff(hd.times)) * 24 * 3600\n",
    "    df = np.median(np.diff(hd.freqs)) \n",
    "    low_band, high_band, tslice = get_slices(flags)\n",
    "\n",
    "    # Perform filtering\n",
    "    filtered_SNR = copy.deepcopy(data)\n",
    "    for bl in filtered_SNR.keys():\n",
    "\n",
    "        # get sky-like FR ranges\n",
    "        fr_center = sky_frates(hd)[0][bl]\n",
    "        fr_hw = sky_frates(hd)[1][bl]\n",
    "\n",
    "        # calculate noise\n",
    "        auto_bl = [k for k in autos if k[2] == bl[2]][0]\n",
    "        noise = np.abs(autos[auto_bl]) / (nsamples[bl] * dt * df)**.5\n",
    "        \n",
    "        for band in [low_band, high_band]:\n",
    "            if (band is None) or np.all(flags[bl][band, tslice]):\n",
    "                continue\n",
    "            time_filters, _ = dpss_operator((data.times[tslice] - data.times[tslice][0]) * 3600 * 24, \n",
    "                                            [fr_center / 1e3], [fr_hw / 1e3], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            freq_filters, _ = dpss_operator(data.freqs[band], [0.0], [FILTER_DELAY / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            \n",
    "            SNR = data[bl][tslice, band] / noise[tslice, band]\n",
    "            fit, meta = sparse_linear_fit_2D(\n",
    "                data=SNR,\n",
    "                weights=(~flags[bl][tslice, band]).astype(float),\n",
    "                axis_1_basis=time_filters,\n",
    "                axis_2_basis=freq_filters,\n",
    "            )\n",
    "            d_mdl = time_filters.dot(fit).dot(freq_filters.T)\n",
    "            filtered_SNR[bl][tslice, band] = SNR - d_mdl\n",
    "    \n",
    "            # estimate the leverage as the outer-product of the leverages along each axis assuming separable flags\n",
    "            # and a small correction which accounts for the non-separable flags\n",
    "            variance_correction = estimate_variance_correction(flags[bl][tslice, band], time_filters, freq_filters)\n",
    "            filtered_SNR[bl][tslice, band] /= variance_correction\n",
    "\n",
    "    # save figures to display later\n",
    "    if not np.all(list(flags.values())):\n",
    "        waterfall_figs.append(plot_2D_filtered_SNR_waterfalls())\n",
    "        histogram_figs.append(plot_2D_filtered_SNR_histograms())\n",
    "    else:\n",
    "        print(f'{list(flags.keys())} are all entirely flagged.')\n",
    "\n",
    "    # save results\n",
    "    hd.update(data=filtered_SNR)\n",
    "    print(f\"Writing results to {single_bl_file.replace('.uvh5', SNR_SUFFIX)}\")\n",
    "    hd.write_uvh5(single_bl_file.replace('.uvh5', SNR_SUFFIX), clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681da171-70ea-4bb7-85a6-a7cb615ab59c",
   "metadata": {},
   "source": [
    "# *Figure 1: Waterfalls of 2D DPSS Filtered SNRs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ac101-2920-41aa-9231-2591ac698293",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wf_fig in waterfall_figs:\n",
    "    display(wf_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ea4bd-25cb-4c1e-8429-4a0f04863046",
   "metadata": {},
   "source": [
    "# *Figure 2: Histograms of 2D DPSS Filtered SNRs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840d20b-eb3d-4db5-afca-cb7e93f3461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h_fig in histogram_figs:\n",
    "    display(h_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b34345-517a-4b5a-b378-877a3ed3826a",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea308ec0-e1e7-47cf-b887-7c330baa0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata', 'numpy']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abb874-6be1-4b68-a2f3-847873cfaf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

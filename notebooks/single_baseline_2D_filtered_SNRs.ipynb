{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d337ad-0853-48b7-ae41-93682103ecf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:27:40.494407Z",
     "iopub.status.busy": "2025-01-31T18:27:40.494172Z",
     "iopub.status.idle": "2025-01-31T18:27:40.498516Z",
     "shell.execute_reply": "2025-01-31T18:27:40.497684Z",
     "shell.execute_reply.started": "2025-01-31T18:27:40.494388Z"
    }
   },
   "source": [
    "# Single Baseline 2D DPSS Filtered SNRs\n",
    "\n",
    "**by Josh Dillon and Tyler Cox**, last updated March 26, 2025\n",
    "\n",
    "This notebook performs single-baseline, full-day DPSS filtering on corner-turned files to calculate a 2D DPSS filtered SNR, which can later be combined to look for residual RFI or other systematics that may have evaded Round 2 RFI flagging based on 1D DPSS filtering in frequency/delay.\n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "# [• Figure 1: Waterfalls of 2D DPSS Filtered SNRs](#Figure-1:-Waterfalls-of-2D-DPSS-Filtered-SNRs)\n",
    "# [• Figure 2: Histograms of 2D DPSS Filtered SNRs](#Figure-2:-Histograms-of-2D-DPSS-Filtered-SNRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3af62-cb84-4cbc-a7b8-9a964aefb7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95540aa3-d138-41c4-8cae-7290c9d91492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import yaml\n",
    "import glob\n",
    "import copy\n",
    "import re\n",
    "from hera_cal import io, redcal, red_groups, flag_utils\n",
    "from hera_cal.frf import sky_frates\n",
    "from hera_cal.smooth_cal import solve_2D_DPSS\n",
    "from hera_filters.dspec import dpss_operator, sparse_linear_fit_2D, fourier_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a7e03-73bc-422e-946a-2fcef7fd0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_AVG_FILE = os.environ.get(\"RED_AVG_FILE\", None)\n",
    "# RED_AVG_FILE = '/lustre/aoc/projects/hera/jsdillon/H6C/IDR3/2459861/zen.2459861.25319.sum.smooth_calibrated.red_avg.uvh5'\n",
    "\n",
    "CORNER_TURN_MAP_YAML = os.environ.get(\"CORNER_TURN_MAP_YAML\", \n",
    "                                        os.path.join(os.path.dirname(RED_AVG_FILE), \"single_baseline_files/corner_turn_map.yaml\"))\n",
    "\n",
    "SNR_SUFFIX =  os.environ.get(\"SNR_SUFFIX\", \".2Dfilt_SNR.uvh5\")\n",
    "\n",
    "FM_LOW_FREQ = float(os.environ.get(\"FM_LOW_FREQ\", 87.5)) # in MHz\n",
    "FM_HIGH_FREQ = float(os.environ.get(\"FM_HIGH_FREQ\", 108.0)) # in MHz\n",
    "\n",
    "FILTER_DELAY = float(os.environ.get(\"FILTER_DELAY\", 750)) # in ns\n",
    "POST_FILTER_DELAY_LOW_BAND = float(os.environ.get(\"POST_FILTER_DELAY_LOW_BAND\", 200.0)) # in ns\n",
    "POST_FILTER_DELAY_HIGH_BAND = float(os.environ.get(\"POST_FILTER_DELAY_HIGH_BAND\", 50.0)) # in ns\n",
    "MIN_FRATE_HALF_WIDTH = float(os.environ.get(\"MIN_FRATE_HALF_WIDTH\", 2.0)) # in mHz\n",
    "EIGENVAL_CUTOFF = float(os.environ.get(\"EIGENVAL_CUTOFF\", 1e-12))\n",
    "TV_CHAN_EDGES = os.environ.get(\"TV_CHAN_EDGES\", \"174,182,190,198,206,214,222,230,238,246,254\")\n",
    "TV_THRESH = float(os.environ.get(\"TV_THRESH\", 1.0))\n",
    "MIN_SAMP_FRAC = float(os.environ.get(\"MIN_SAMP_FRAC\", .15))\n",
    "\n",
    "for setting in ['RED_AVG_FILE', 'CORNER_TURN_MAP_YAML', 'SNR_SUFFIX', 'TV_CHAN_EDGES']:\n",
    "    print(f'{setting} = \"{eval(setting)}\"')\n",
    "for setting in ['FM_LOW_FREQ', 'FM_HIGH_FREQ', 'FILTER_DELAY', 'POST_FILTER_DELAY_LOW_BAND', 'POST_FILTER_DELAY_HIGH_BAND',\n",
    "                'MIN_FRATE_HALF_WIDTH', 'EIGENVAL_CUTOFF', 'TV_THRESH', 'MIN_SAMP_FRAC']:\n",
    "    print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98c109-2ce1-447a-8dad-372cb5a396fe",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1aaf0-3e7c-43ad-af50-1e8cd86325a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CORNER_TURN_MAP_YAML, 'r') as file:\n",
    "    corner_turn_map = yaml.unsafe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933c1dd-7f1b-4617-a2a2-8193de766490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get autocorrelations\n",
    "all_outfiles = [outfile for outfiles in corner_turn_map['files_to_outfiles_map'].values() for outfile in outfiles]\n",
    "for outfile in all_outfiles:\n",
    "    match = re.search(r'\\.(\\d+)_(\\d+)\\.', os.path.basename(outfile))\n",
    "    if match and match.group(1) == match.group(2):\n",
    "        hd_autos = io.HERAData(outfile)\n",
    "        autos, _, auto_nsamples = hd_autos.read(polarizations=['ee', 'nn'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dc253-5b28-4669-ad12-c539627ab032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define slices for TV allocations\n",
    "tv_edges = [float(edge) for edge in TV_CHAN_EDGES.split(',')]\n",
    "tv_slices = []\n",
    "for i in range(len(tv_edges) - 1):\n",
    "    chans_in_band = np.argwhere((autos.freqs / 1e6 > tv_edges[i]) & (autos.freqs / 1e6 < tv_edges[i+1]))\n",
    "    if len(chans_in_band) > 0:\n",
    "        tv_slices.append(slice(np.min(chans_in_band), np.max(chans_in_band) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbb8ed-3122-4de4-9de9-f025041ccf19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T02:57:17.314387Z",
     "iopub.status.busy": "2025-02-04T02:57:17.314188Z",
     "iopub.status.idle": "2025-02-04T02:57:17.317006Z",
     "shell.execute_reply": "2025-02-04T02:57:17.316539Z",
     "shell.execute_reply.started": "2025-02-04T02:57:17.314369Z"
    }
   },
   "source": [
    "## Define functions for main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac437101-22a2-4c70-8612-1c86da88b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_filtered_SNR_waterfalls(vmax=5):\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=(14,10), dpi=200, sharex=True, sharey=True)\n",
    "    extent = [data.freqs[0] / 1e6, data.freqs[-1] / 1e6, data.times[-1] - int(data.times[0]), data.times[0] - int(data.times[0])]\n",
    "    \n",
    "    for bl, ax in zip(data, axes):\n",
    "        im = ax.imshow(np.where(flags[bl], np.nan, np.abs(filtered_SNR[bl])), aspect='auto', interpolation='none', \n",
    "                       cmap='afmhot_r', vmin=0, vmax=vmax, extent=extent)\n",
    "        ax.set_title(bl)\n",
    "        ax.set_xlabel('Frequency (MHz)')\n",
    "        for freq in tv_edges:\n",
    "            if freq < data.freqs[-1] * 1e-6:\n",
    "                ax.axvline(freq, lw=.5, ls='--', color='k')\n",
    "\n",
    "    \n",
    "    axes[0].set_ylabel(f'JD - {int(data.times[0])}')\n",
    "    plt.tight_layout()\n",
    "    largest_pixel = np.max([np.max(np.abs(filtered_SNR[bl][~flags[bl]])) \n",
    "                            for bl in filtered_SNR if not np.all(flags[bl])])\n",
    "    plt.colorbar(im, ax=axes, label='|2D DPSS Filtered SNR|', pad=.02, \n",
    "                 extend=('max' if largest_pixel > vmax else None))\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037fef5-57aa-4f1a-afc4-b9c9db01b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_filtered_SNR_histograms():\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    bins = np.arange(0, 25, .05)\n",
    "    \n",
    "    all_densities = []\n",
    "    for bl in filtered_SNR:\n",
    "        hist = plt.hist(np.where(flags[bl], np.nan, np.abs(filtered_SNR[bl])).ravel(), bins=bins, label=str(bl), density=True, alpha=.5)\n",
    "        all_densities.extend(hist[0][hist[0] > 0])\n",
    "    \n",
    "    plt.plot(bins, 2 * bins * np.exp(-bins**2), 'k--', label='Rayleigh Distribution (Noise-Only)')\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(np.min(all_densities) / 2, np.max(all_densities) * 2)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlabel('2D DPSS Filtered SNR')\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e825ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_SNR_correction(wgts, time_filters, freq_filters):\n",
    "    \"\"\"\n",
    "    Estimate the SNR correction from a 2D DPSS fit with a given set of weights. Assumes weights are separable to \n",
    "    make the calculation tracktable, but then accounts for the portion of the flags which are not separable.\n",
    "    \"\"\"\n",
    "    # Get the separable portion of the weights/flags\n",
    "    ntimes, nfreqs = wgts.shape\n",
    "    freq_mask = (~np.all(wgts == 0, axis=0)).astype(float)\n",
    "    avg_freq_wgts = np.where(freq_mask, np.nanmean(np.where(wgts == 0, np.nan, wgts), axis=0), 0)\n",
    "    time_mask = (~np.all(wgts == 0, axis=1)).astype(float)\n",
    "    avg_time_wgts = np.where(time_mask, np.nanmean(np.where(wgts == 0, np.nan, wgts / avg_freq_wgts), axis=1), 0)\n",
    "    \n",
    "    # Compute the leverage for the frequency-axis\n",
    "    leverage_f = np.sum(\n",
    "        freq_filters.T * np.linalg.pinv(\n",
    "            (freq_filters.T.conj() * avg_freq_wgts).dot(freq_filters)\n",
    "        ).dot(freq_filters.T.conj() * avg_freq_wgts),\n",
    "        axis=0\n",
    "    )\n",
    "    # Compute the leverage for the frequency-axis\n",
    "    leverage_t = np.sum(\n",
    "        time_filters.T *\n",
    "        np.linalg.pinv((time_filters.T.conj() * avg_time_wgts).dot(time_filters)).dot(time_filters.T.conj() * avg_time_wgts),\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    # Compute the outer product of the leverage along each axis\n",
    "    leverage = np.abs(np.outer(leverage_t, leverage_f))\n",
    "    \n",
    "    # Rescale the leverage to handle flags which are not separable in time and frequency\n",
    "    n_separable_flags = (\n",
    "        np.sum(1 - freq_mask) * ntimes + \n",
    "        np.sum(1 - time_mask) * nfreqs - \n",
    "        np.sum(1 - time_mask) * np.sum(1 - freq_mask)\n",
    "    )\n",
    "    flagging_frac = ((wgts == 0).sum() - n_separable_flags) / wgts.size\n",
    "    return (1 - flagging_frac ** 2) * (1 - leverage)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fe43f-1ade-40b8-838c-156c219eee2a",
   "metadata": {},
   "source": [
    "## Perform 2D DPSS filtering, looping over baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665003e-0988-473f-8781-c30d80b7d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfall_figs = []\n",
    "histogram_figs = []\n",
    "\n",
    "for single_bl_file in corner_turn_map['files_to_outfiles_map'][RED_AVG_FILE]:\n",
    "    # Load data\n",
    "    print(f'Now loading {single_bl_file}')\n",
    "    hd = io.HERAData(single_bl_file)\n",
    "    data, flags, nsamples = hd.read(polarizations=['ee', 'nn'])\n",
    "    dt = np.median(np.diff(hd.times)) * 24 * 3600\n",
    "    df = np.median(np.diff(hd.freqs))\n",
    "\n",
    "    med_auto_nsamples = {bl[2]: np.median(n) for bl, n in auto_nsamples.items()}\n",
    "    if not any([np.median(nsamples[bl]) > MIN_SAMP_FRAC * med_auto_nsamples[bl[2]] for bl in nsamples]):\n",
    "        print('\\tNo polarization has enough nsamples to be worth filtering. Skipping...')\n",
    "        continue\n",
    "    \n",
    "    # Perform filtering\n",
    "    filtered_SNR = copy.deepcopy(data)\n",
    "    for bl in filtered_SNR.keys():\n",
    "        # calculate the unflagged region to filter\n",
    "        tslice, (low_band, high_band) = flag_utils.get_minimal_slices(flags[bl], freqs=data.freqs, \n",
    "                                                                      freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "        \n",
    "        # get sky-like FR ranges\n",
    "        fr_center = sky_frates(hd, min_frate_half_width=MIN_FRATE_HALF_WIDTH)[0][bl]\n",
    "        fr_hw = sky_frates(hd, min_frate_half_width=MIN_FRATE_HALF_WIDTH)[1][bl]\n",
    "\n",
    "        # calculate noise\n",
    "        auto_bl = [k for k in autos if k[2] == bl[2]][0]\n",
    "        noise = np.abs(autos[auto_bl]) / (nsamples[bl] * dt * df)**.5\n",
    "        wgts = np.where(flags[bl], 0, noise**-2)\n",
    "        wgts /= np.mean(wgts[wgts > 0])\n",
    "        \n",
    "        for band in [low_band, high_band]:\n",
    "            if (band is None) or np.all(flags[bl][tslice, band]):\n",
    "                continue\n",
    "\n",
    "            # perform 2D DPSS filter    \n",
    "            time_filters, _ = dpss_operator((data.times[tslice] - data.times[tslice][0]) * 3600 * 24, \n",
    "                                            [fr_center / 1e3], [fr_hw / 1e3], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            freq_filters, _ = dpss_operator(data.freqs[band], [0.0], [FILTER_DELAY / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            fit, meta = sparse_linear_fit_2D(\n",
    "                data=data[bl][tslice, band],\n",
    "                weights=wgts[tslice, band],\n",
    "                axis_1_basis=time_filters,\n",
    "                axis_2_basis=freq_filters,\n",
    "                precondition_solver=True,\n",
    "            )\n",
    "            d_mdl = time_filters.dot(fit).dot(freq_filters.T)\n",
    "            filtered_SNR[bl][tslice, band] = np.where(flags[bl][tslice, band], 0, \n",
    "                                                      (data[bl][tslice, band] - d_mdl) / noise[tslice, band])\n",
    "            # estimate the leverage as the outer-product of the leverages along each axis assuming separable weights\n",
    "            # and a small correction which accounts for the non-separable flags\n",
    "            SNR_correction = estimate_SNR_correction(wgts[tslice, band], time_filters, freq_filters)\n",
    "            filtered_SNR[bl][tslice, band] /= SNR_correction\n",
    "\n",
    "            # identify TV channels with high SNR and give them near-0 weight when 1D DPSS filtering\n",
    "            wgts_1D = (~flags[bl]).astype(float)\n",
    "            if band == high_band: \n",
    "                predicted_mean = np.sqrt(np.pi) / 2\n",
    "                predicted_std = np.sqrt((4 - np.pi) / 4)\n",
    "                zscore = np.where(flags[bl], np.nan, (np.abs(filtered_SNR[bl]) - predicted_mean) / predicted_std)\n",
    "                for tvs in tv_slices:\n",
    "                    for tind in range(zscore.shape[0]):\n",
    "                        if np.nanmean(zscore[tind, tvs]) > TV_THRESH:\n",
    "                            wgts_1D[tind, tvs] *= np.finfo(float).eps  # make weight very small\n",
    "            \n",
    "            # filter out very low delay modes in 1D \n",
    "            post_filter_delay = (POST_FILTER_DELAY_LOW_BAND if band == low_band else POST_FILTER_DELAY_HIGH_BAND)\n",
    "            d_mdl_1D, _, _ = fourier_filter(data.freqs[band], \n",
    "                                            filtered_SNR[bl][tslice, band], \n",
    "                                            wgts=wgts_1D[tslice, band], \n",
    "                                            filter_centers=[0], \n",
    "                                            filter_half_widths=[post_filter_delay / 1e9],\n",
    "                                            mode='dpss_solve', \n",
    "                                            eigenval_cutoff=[EIGENVAL_CUTOFF],\n",
    "                                            suppression_factors=[EIGENVAL_CUTOFF], \n",
    "                                            max_contiguous_edge_flags=len(data.freqs))\n",
    "            filtered_SNR[bl][tslice, band] = np.where(flags[bl][tslice, band], 0, filtered_SNR[bl][tslice, band] - d_mdl_1D)\n",
    "    \n",
    "            # calculate and apply another correction factor based on the leverage to flatten out the SNR\n",
    "            correction_factors = np.full_like(wgts_1D[tslice, band], np.nan)     \n",
    "            X = dpss_operator(data.freqs[band], [0], filter_half_widths=[post_filter_delay / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])[0]\n",
    "            for tind in range(wgts_1D[tslice, band].shape[0]):\n",
    "                W = wgts_1D[tind, band]\n",
    "                if not np.all(W == 0):\n",
    "                    leverage = np.diag(X @ np.linalg.pinv(np.dot(X.T * W, X)) @ (X.T * W))\n",
    "                    correction_factors[tind, :] = np.where(leverage > 0, (1 - leverage)**.5, np.nan)\n",
    "            filtered_SNR[bl][tslice, band] /= correction_factors\n",
    "\n",
    "        # get rid of nans/infs in flagged channels\n",
    "        filtered_SNR[bl] = np.where(flags[bl], 0, filtered_SNR[bl])\n",
    "    \n",
    "    # save figures to display later\n",
    "    if not np.all(list(flags.values())):\n",
    "        waterfall_figs.append(plot_2D_filtered_SNR_waterfalls())\n",
    "        histogram_figs.append(plot_2D_filtered_SNR_histograms())\n",
    "    else:\n",
    "        print(f'{list(flags.keys())} are all entirely flagged.')\n",
    "\n",
    "    # save results\n",
    "    hd.update(data=filtered_SNR)\n",
    "    print(f\"Writing results to {single_bl_file.replace('.uvh5', SNR_SUFFIX)}\")\n",
    "    hd.write_uvh5(single_bl_file.replace('.uvh5', SNR_SUFFIX), clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681da171-70ea-4bb7-85a6-a7cb615ab59c",
   "metadata": {},
   "source": [
    "# *Figure 1: Waterfalls of 2D DPSS Filtered SNRs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ac101-2920-41aa-9231-2591ac698293",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wf_fig in waterfall_figs:\n",
    "    display(wf_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ea4bd-25cb-4c1e-8429-4a0f04863046",
   "metadata": {},
   "source": [
    "# *Figure 2: Histograms of 2D DPSS Filtered SNRs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840d20b-eb3d-4db5-afca-cb7e93f3461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h_fig in histogram_figs:\n",
    "    display(h_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b34345-517a-4b5a-b378-877a3ed3826a",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea308ec0-e1e7-47cf-b887-7c330baa0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata', 'numpy']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abb874-6be1-4b68-a2f3-847873cfaf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

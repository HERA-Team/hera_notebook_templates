{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d337ad-0853-48b7-ae41-93682103ecf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:27:40.494407Z",
     "iopub.status.busy": "2025-01-31T18:27:40.494172Z",
     "iopub.status.idle": "2025-01-31T18:27:40.498516Z",
     "shell.execute_reply": "2025-01-31T18:27:40.497684Z",
     "shell.execute_reply.started": "2025-01-31T18:27:40.494388Z"
    }
   },
   "source": [
    "# Single Baseline 2D DPSS Filtered SNRs\n",
    "\n",
    "**by Josh Dillon and Tyler Cox**, last updated May 15, 2025\n",
    "\n",
    "This notebook performs single-baseline, full-day DPSS filtering on corner-turned files to calculate a 2D DPSS filtered SNR, which can later be combined to look for residual RFI or other systematics that may have evaded Round 2 RFI flagging based on 1D DPSS filtering in frequency/delay.\n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "# [• Figure 1: Waterfalls of 2D DPSS Filtered SNRs](#Figure-1:-Waterfalls-of-2D-DPSS-Filtered-SNRs)\n",
    "# [• Figure 2: Histograms of 2D DPSS Filtered SNRs](#Figure-2:-Histograms-of-2D-DPSS-Filtered-SNRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3af62-cb84-4cbc-a7b8-9a964aefb7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95540aa3-d138-41c4-8cae-7290c9d91492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import yaml\n",
    "import glob\n",
    "import copy\n",
    "import re\n",
    "from astropy import units\n",
    "from scipy import interpolate, optimize, constants\n",
    "from hera_cal import io, redcal, red_groups, flag_utils\n",
    "from hera_cal.frf import sky_frates, get_FR_buffer_from_spectra\n",
    "from hera_cal.smooth_cal import solve_2D_DPSS\n",
    "from hera_filters.dspec import dpss_operator, sparse_linear_fit_2D, fourier_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a7e03-73bc-422e-946a-2fcef7fd0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_AVG_FILE = os.environ.get(\"RED_AVG_FILE\", None)\n",
    "# RED_AVG_FILE = '/lustre/aoc/projects/hera/jsdillon/H6C/IDR3/2459861/zen.2459861.25319.sum.smooth_calibrated.red_avg.uvh5'\n",
    "\n",
    "CORNER_TURN_MAP_YAML = os.environ.get(\"CORNER_TURN_MAP_YAML\", \n",
    "                                        os.path.join(os.path.dirname(RED_AVG_FILE), \"single_baseline_files/corner_turn_map.yaml\"))\n",
    "\n",
    "SNR_SUFFIX =  os.environ.get(\"SNR_SUFFIX\", \".2Dfilt_SNR.uvh5\")\n",
    "\n",
    "FM_LOW_FREQ = float(os.environ.get(\"FM_LOW_FREQ\", 87.5)) # in MHz\n",
    "FM_HIGH_FREQ = float(os.environ.get(\"FM_HIGH_FREQ\", 108.0)) # in MHz\n",
    "\n",
    "FILTER_DELAY = float(os.environ.get(\"FILTER_DELAY\", 750)) # in ns\n",
    "POST_FILTER_DELAY_LOW_BAND = float(os.environ.get(\"POST_FILTER_DELAY_LOW_BAND\", 200.0)) # in ns\n",
    "POST_FILTER_DELAY_HIGH_BAND = float(os.environ.get(\"POST_FILTER_DELAY_HIGH_BAND\", 50.0)) # in ns\n",
    "\n",
    "AUTO_FR_SPECTRUM_FILE = '/lustre/aoc/projects/hera/zmartino/hera_frf/spectra_cache/spectra_cache_hera_auto.h5'\n",
    "GAUSS_FIT_BUFFER_CUT = float(os.environ.get(\"GAUSS_FIT_BUFFER_CUT\", 1e-5))\n",
    "\n",
    "EIGENVAL_CUTOFF = float(os.environ.get(\"EIGENVAL_CUTOFF\", 1e-12))\n",
    "CG_ITER_LIM = int(os.environ.get(\"CG_ITER_LIM\", 500))\n",
    "TV_CHAN_EDGES = os.environ.get(\"TV_CHAN_EDGES\", \"174,182,190,198,206,214,222,230,238,246,254\")\n",
    "TV_THRESH = float(os.environ.get(\"TV_THRESH\", 1.0))\n",
    "MIN_SAMP_FRAC = float(os.environ.get(\"MIN_SAMP_FRAC\", .15))\n",
    "\n",
    "for setting in ['RED_AVG_FILE', 'CORNER_TURN_MAP_YAML', 'SNR_SUFFIX', 'AUTO_FR_SPECTRUM_FILE', 'TV_CHAN_EDGES']:\n",
    "    print(f'{setting} = \"{eval(setting)}\"')\n",
    "for setting in ['FM_LOW_FREQ', 'FM_HIGH_FREQ', 'FILTER_DELAY', 'POST_FILTER_DELAY_LOW_BAND', 'POST_FILTER_DELAY_HIGH_BAND',\n",
    "                'GAUSS_FIT_BUFFER_CUT', 'EIGENVAL_CUTOFF', 'CG_ITER_LIM', 'TV_THRESH', 'MIN_SAMP_FRAC']:\n",
    "    print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98c109-2ce1-447a-8dad-372cb5a396fe",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1aaf0-3e7c-43ad-af50-1e8cd86325a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CORNER_TURN_MAP_YAML, 'r') as file:\n",
    "    corner_turn_map = yaml.unsafe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933c1dd-7f1b-4617-a2a2-8193de766490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get autocorrelations\n",
    "all_outfiles = [outfile for outfiles in corner_turn_map['files_to_outfiles_map'].values() for outfile in outfiles]\n",
    "for outfile in all_outfiles:\n",
    "    match = re.search(r'\\.(\\d+)_(\\d+)\\.', os.path.basename(outfile))\n",
    "    if match and match.group(1) == match.group(2):\n",
    "        hd_autos = io.HERAData(outfile)\n",
    "        autos, _, auto_nsamples = hd_autos.read(polarizations=['ee', 'nn'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dc253-5b28-4669-ad12-c539627ab032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define slices for TV allocations\n",
    "tv_edges = [float(edge) for edge in TV_CHAN_EDGES.split(',')]\n",
    "tv_slices = []\n",
    "for i in range(len(tv_edges) - 1):\n",
    "    chans_in_band = np.argwhere((autos.freqs / 1e6 > tv_edges[i]) & (autos.freqs / 1e6 < tv_edges[i+1]))\n",
    "    if len(chans_in_band) > 0:\n",
    "        tv_slices.append(slice(np.min(chans_in_band), np.max(chans_in_band) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbb8ed-3122-4de4-9de9-f025041ccf19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T02:57:17.314387Z",
     "iopub.status.busy": "2025-02-04T02:57:17.314188Z",
     "iopub.status.idle": "2025-02-04T02:57:17.317006Z",
     "shell.execute_reply": "2025-02-04T02:57:17.316539Z",
     "shell.execute_reply.started": "2025-02-04T02:57:17.314369Z"
    }
   },
   "source": [
    "## Define functions for main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac437101-22a2-4c70-8612-1c86da88b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_filtered_SNR_waterfalls(vmax=5):\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=(14,10), dpi=200, sharex=True, sharey=True)\n",
    "    extent = [data.freqs[0] / 1e6, data.freqs[-1] / 1e6, data.times[-1] - int(data.times[0]), data.times[0] - int(data.times[0])]\n",
    "    \n",
    "    for bl, ax in zip(data, axes):\n",
    "        im = ax.imshow(np.where(flags[bl], np.nan, np.abs(filtered_SNR[bl])), aspect='auto', interpolation='none', \n",
    "                       cmap='afmhot_r', vmin=0, vmax=vmax, extent=extent)\n",
    "        ax.set_title(bl)\n",
    "        ax.set_xlabel('Frequency (MHz)')\n",
    "        for freq in tv_edges:\n",
    "            if freq < data.freqs[-1] * 1e-6:\n",
    "                ax.axvline(freq, lw=.5, ls='--', color='k')\n",
    "\n",
    "    \n",
    "    axes[0].set_ylabel(f'JD - {int(data.times[0])}')\n",
    "    plt.tight_layout()\n",
    "    largest_pixel = np.max([np.max(np.abs(filtered_SNR[bl][~flags[bl]])) \n",
    "                            for bl in filtered_SNR if not np.all(flags[bl])])\n",
    "    plt.colorbar(im, ax=axes, label='|2D DPSS Filtered SNR|', pad=.02, \n",
    "                 extend=('max' if largest_pixel > vmax else None))\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037fef5-57aa-4f1a-afc4-b9c9db01b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_filtered_SNR_histograms():\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    bins = np.arange(0, 25, .05)\n",
    "    \n",
    "    all_densities = []\n",
    "    for bl in filtered_SNR:\n",
    "        hist = plt.hist(np.where(flags[bl], np.nan, np.abs(filtered_SNR[bl])).ravel(), bins=bins, label=str(bl), density=True, alpha=.5)\n",
    "        all_densities.extend(hist[0][hist[0] > 0])\n",
    "    \n",
    "    plt.plot(bins, 2 * bins * np.exp(-bins**2), 'k--', label='Rayleigh Distribution (Noise-Only)')\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(np.min(all_densities) / 2, np.max(all_densities) * 2)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlabel('2D DPSS Filtered SNR')\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc8f01-e884-4e03-95ff-77ca4055be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "FR_CENTER_AND_HW_CACHE = {}\n",
    "\n",
    "def cache_fr_center_and_hw(hd, antpair, tslice, band):\n",
    "    '''Figure out the range of FRs in Hz spanned for a given band and tslice, buffered by the size of the autocorrelation FR kernel,\n",
    "    and stores the value in FR_CENTER_AND_HW_CACHE (if it hasn't already been computed.'''\n",
    "    if (tslice is not None) and (band is not None) and ((antpair, tslice, band) not in FR_CENTER_AND_HW_CACHE):\n",
    "        # calculate fringe rate center and half-width and then update cache\n",
    "        fr_buffer = get_FR_buffer_from_spectra(AUTO_FR_SPECTRUM_FILE, hd.times[tslice], hd.freqs[band], \n",
    "                                               gauss_fit_buffer_cut=GAUSS_FIT_BUFFER_CUT)\n",
    "        hd_here = hd.select(inplace=False, frequencies=hd.freqs[band])\n",
    "        fr_center = list(sky_frates(hd_here)[0].values())[0] / 1e3  # converts to Hz\n",
    "        fr_hw = (list(sky_frates(hd_here)[1].values())[0] + fr_buffer) / 1e3    \n",
    "        FR_CENTER_AND_HW_CACHE[(antpair, tslice, band)] = fr_center, fr_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e825ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_SNR_correction(wgts, time_filters, freq_filters):\n",
    "    \"\"\"\n",
    "    Estimate the SNR correction from a 2D DPSS fit with a given set of weights. Assumes weights are separable to \n",
    "    make the calculation tracktable, but then accounts for the portion of the flags which are not separable.\n",
    "    \"\"\"\n",
    "    # Get the separable portion of the weights/flags\n",
    "    ntimes, nfreqs = wgts.shape\n",
    "    freq_mask = (~np.all(wgts == 0, axis=0)).astype(float)\n",
    "    avg_freq_wgts = np.where(freq_mask, np.nanmean(np.where(wgts == 0, np.nan, wgts), axis=0), 0)\n",
    "    time_mask = (~np.all(wgts == 0, axis=1)).astype(float)\n",
    "    avg_time_wgts = np.where(time_mask, np.nanmean(np.where(wgts == 0, np.nan, wgts / avg_freq_wgts), axis=1), 0)\n",
    "    \n",
    "    # Compute the leverage for the frequency-axis\n",
    "    leverage_f = np.sum(\n",
    "        freq_filters.T * np.linalg.pinv(\n",
    "            (freq_filters.T.conj() * avg_freq_wgts).dot(freq_filters)\n",
    "        ).dot(freq_filters.T.conj() * avg_freq_wgts),\n",
    "        axis=0\n",
    "    )\n",
    "    # Compute the leverage for the frequency-axis\n",
    "    leverage_t = np.sum(\n",
    "        time_filters.T *\n",
    "        np.linalg.pinv((time_filters.T.conj() * avg_time_wgts).dot(time_filters)).dot(time_filters.T.conj() * avg_time_wgts),\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    # Compute the outer product of the leverage along each axis\n",
    "    leverage = np.abs(np.outer(leverage_t, leverage_f))\n",
    "    \n",
    "    # Rescale the leverage to handle flags which are not separable in time and frequency\n",
    "    n_separable_flags = (\n",
    "        np.sum(1 - freq_mask) * ntimes + \n",
    "        np.sum(1 - time_mask) * nfreqs - \n",
    "        np.sum(1 - time_mask) * np.sum(1 - freq_mask)\n",
    "    )\n",
    "    flagging_frac = ((wgts == 0).sum() - n_separable_flags) / wgts.size\n",
    "    return (1 - flagging_frac ** 2) * (1 - leverage)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fe43f-1ade-40b8-838c-156c219eee2a",
   "metadata": {},
   "source": [
    "## Perform 2D DPSS filtering, looping over baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665003e-0988-473f-8781-c30d80b7d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfall_figs = []\n",
    "histogram_figs = []\n",
    "\n",
    "for single_bl_file in corner_turn_map['files_to_outfiles_map'][RED_AVG_FILE]:\n",
    "    # Load data\n",
    "    print(f'Now loading {single_bl_file}')\n",
    "    hd = io.HERAData(single_bl_file)\n",
    "    data, flags, nsamples = hd.read(polarizations=['ee', 'nn'])\n",
    "    dt = np.median(np.diff(hd.times)) * 24 * 3600\n",
    "    df = np.median(np.diff(hd.freqs))\n",
    "    antpair = data.antpairs().pop()\n",
    "\n",
    "    med_auto_nsamples = {bl[2]: np.median(n) for bl, n in auto_nsamples.items()}\n",
    "    if not any([np.median(nsamples[bl]) > MIN_SAMP_FRAC * med_auto_nsamples[bl[2]] for bl in nsamples]):\n",
    "        print('\\tNo polarization has enough nsamples to be worth filtering. Skipping...')\n",
    "        continue\n",
    "\n",
    "    # get tslice and bands and figure out the corresponding fr_centers and fr_hws\n",
    "    tslices = {}\n",
    "    bands = {}\n",
    "    for bl in data:\n",
    "        tslices[bl], bands[bl] = flag_utils.get_minimal_slices(flags[bl], freqs=data.freqs, freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "        for tslice, band in zip(tslices[bl], bands[bl]):\n",
    "            cache_fr_center_and_hw(hd, bl[0:2], tslice, band)\n",
    "    \n",
    "    # Perform filtering\n",
    "    filtered_SNR = copy.deepcopy(data)\n",
    "    for bl in filtered_SNR.keys():\n",
    "\n",
    "        # calculate noise\n",
    "        auto_bl = [k for k in autos if k[2] == bl[2]][0]\n",
    "        noise = np.abs(autos[auto_bl]) / (nsamples[bl] * dt * df)**.5\n",
    "        wgts = np.where(flags[bl], 0, noise**-2)\n",
    "        if np.any(wgts > 0):\n",
    "            wgts /= np.mean(wgts[wgts > 0])\n",
    "        \n",
    "        for tslice, band in zip(tslices[bl], bands[bl]):\n",
    "            if (band is None) or np.all(flags[bl][tslice, band]):\n",
    "                continue\n",
    "\n",
    "            # perform 2D DPSS filter\n",
    "            fr_center, fr_hw = FR_CENTER_AND_HW_CACHE[(antpair, tslice, band)]\n",
    "            time_filters, _ = dpss_operator((data.times[tslice] - data.times[tslice][0]) * 3600 * 24, \n",
    "                                            [fr_center], [fr_hw], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            freq_filters, _ = dpss_operator(data.freqs[band], [0.0], [FILTER_DELAY / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            fit, meta = sparse_linear_fit_2D(\n",
    "                data=data[bl][tslice, band],\n",
    "                weights=wgts[tslice, band],\n",
    "                axis_1_basis=time_filters,\n",
    "                axis_2_basis=freq_filters,\n",
    "                precondition_solver=True,\n",
    "                iter_lim=CG_ITER_LIM,\n",
    "            )\n",
    "            d_mdl = time_filters.dot(fit).dot(freq_filters.T)\n",
    "            filtered_SNR[bl][tslice, band] = np.where(flags[bl][tslice, band], 0, \n",
    "                                                      (data[bl][tslice, band] - d_mdl) / noise[tslice, band])\n",
    "            # estimate the leverage as the outer-product of the leverages along each axis assuming separable weights\n",
    "            # and a small correction which accounts for the non-separable flags\n",
    "            SNR_correction = estimate_SNR_correction(wgts[tslice, band], time_filters, freq_filters)\n",
    "            filtered_SNR[bl][tslice, band] /= SNR_correction\n",
    "\n",
    "            # identify TV channels with high SNR and give them near-0 weight when 1D DPSS filtering\n",
    "            wgts_1D = (~flags[bl]).astype(float)\n",
    "            if band == bands[bl][1]:  # high band\n",
    "                predicted_mean = np.sqrt(np.pi) / 2\n",
    "                predicted_std = np.sqrt((4 - np.pi) / 4)\n",
    "                zscore = np.where(flags[bl], np.nan, (np.abs(filtered_SNR[bl]) - predicted_mean) / predicted_std)\n",
    "                for tvs in tv_slices:\n",
    "                    for tind in range(zscore.shape[0]):\n",
    "                        if np.nanmean(zscore[tind, tvs]) > TV_THRESH:\n",
    "                            wgts_1D[tind, tvs] *= np.finfo(float).eps  # make weight very small\n",
    "            \n",
    "            # filter out very low delay modes in 1D \n",
    "            post_filter_delay = (POST_FILTER_DELAY_LOW_BAND if band == bands[bl][0] else POST_FILTER_DELAY_HIGH_BAND)\n",
    "            d_mdl_1D, _, _ = fourier_filter(data.freqs[band], \n",
    "                                            filtered_SNR[bl][tslice, band], \n",
    "                                            wgts=wgts_1D[tslice, band], \n",
    "                                            filter_centers=[0], \n",
    "                                            filter_half_widths=[post_filter_delay / 1e9],\n",
    "                                            mode='dpss_solve', \n",
    "                                            eigenval_cutoff=[EIGENVAL_CUTOFF],\n",
    "                                            suppression_factors=[EIGENVAL_CUTOFF], \n",
    "                                            max_contiguous_edge_flags=len(data.freqs))\n",
    "            filtered_SNR[bl][tslice, band] = np.where(flags[bl][tslice, band], 0, filtered_SNR[bl][tslice, band] - d_mdl_1D)\n",
    "    \n",
    "            # calculate and apply another correction factor based on the leverage to flatten out the SNR\n",
    "            correction_factors = np.full_like(wgts_1D[tslice, band], np.nan)     \n",
    "            X = dpss_operator(data.freqs[band], [0], filter_half_widths=[post_filter_delay / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])[0]\n",
    "            for tind in range(wgts_1D[tslice, band].shape[0]):\n",
    "                W = wgts_1D[tslice.start + tind, band]\n",
    "                if not np.all(W == 0):\n",
    "                    leverage = np.diag(X @ np.linalg.pinv(np.dot(X.T * W, X)) @ (X.T * W))\n",
    "                    correction_factors[tind, :] = np.where(leverage > 0, (1 - leverage)**.5, np.nan)\n",
    "            filtered_SNR[bl][tslice, band] /= correction_factors\n",
    "\n",
    "        # get rid of nans/infs in flagged channels\n",
    "        filtered_SNR[bl] = np.where(flags[bl], 0, filtered_SNR[bl])\n",
    "    \n",
    "    # save figures to display later\n",
    "    if not np.all(list(flags.values())):\n",
    "        waterfall_figs.append(plot_2D_filtered_SNR_waterfalls())\n",
    "        histogram_figs.append(plot_2D_filtered_SNR_histograms())\n",
    "    else:\n",
    "        print(f'{list(flags.keys())} are all entirely flagged.')\n",
    "\n",
    "    # save results\n",
    "    hd.update(data=filtered_SNR)\n",
    "    print(f\"Writing results to {single_bl_file.replace('.uvh5', SNR_SUFFIX)}\")\n",
    "    hd.write_uvh5(single_bl_file.replace('.uvh5', SNR_SUFFIX), clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681da171-70ea-4bb7-85a6-a7cb615ab59c",
   "metadata": {},
   "source": [
    "# *Figure 1: Waterfalls of 2D DPSS Filtered SNRs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ac101-2920-41aa-9231-2591ac698293",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wf_fig in waterfall_figs:\n",
    "    display(wf_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ea4bd-25cb-4c1e-8429-4a0f04863046",
   "metadata": {},
   "source": [
    "# *Figure 2: Histograms of 2D DPSS Filtered SNRs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840d20b-eb3d-4db5-afca-cb7e93f3461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h_fig in histogram_figs:\n",
    "    display(h_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b34345-517a-4b5a-b378-877a3ed3826a",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea308ec0-e1e7-47cf-b887-7c330baa0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata', 'numpy']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abb874-6be1-4b68-a2f3-847873cfaf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

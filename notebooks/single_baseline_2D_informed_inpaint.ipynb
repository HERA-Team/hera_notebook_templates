{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d337ad-0853-48b7-ae41-93682103ecf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T18:27:40.494407Z",
     "iopub.status.busy": "2025-01-31T18:27:40.494172Z",
     "iopub.status.idle": "2025-01-31T18:27:40.498516Z",
     "shell.execute_reply": "2025-01-31T18:27:40.497684Z",
     "shell.execute_reply.started": "2025-01-31T18:27:40.494388Z"
    }
   },
   "source": [
    "# Single Baseline 2D-Informed 1D DPSS Inpainting\n",
    "\n",
    "**by Josh Dillon**, last updated April 25, 2025\n",
    "\n",
    "This notebook performs single-baseline, full-day DPSS inpainting. Excluded are fully-flagged edge channels, FM, and times that are fully flagged either before or above FM. Inpainting is done first by iteratively forming a 2D DPSS model, then using it in the 1D DPSS fits where we have flags, but with reduced weight that increases to near unity far from unflagged channels. If desired, it also performs a subsequent 1D DPSS notch filter in time around FR=0. \n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "# [â€¢ Figure 1: 4-Pol Phase and Amplitude Waterfalls Before and After Inpainting](#Figure-1:-4-Pol-Phase-and-Amplitude-Waterfalls-Before-and-After-Inpainting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3af62-cb84-4cbc-a7b8-9a964aefb7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95540aa3-d138-41c4-8cae-7290c9d91492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import yaml\n",
    "import glob\n",
    "import copy\n",
    "import re\n",
    "from astropy import units\n",
    "from scipy import interpolate, optimize, constants\n",
    "\n",
    "from pyuvdata import UVFlag\n",
    "from hera_cal import io, flag_utils, utils\n",
    "from hera_cal.frf import sky_frates\n",
    "from hera_cal.smooth_cal import solve_2D_DPSS\n",
    "from hera_filters.dspec import dpss_operator, sparse_linear_fit_2D, fourier_filter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7f0b0-1f4b-4d66-8249-1c4c69f8dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_AVG_FILE = os.environ.get(\"RED_AVG_FILE\", None)\n",
    "# RED_AVG_FILE = '/lustre/aoc/projects/hera/jsdillon/H6C/IDR3/2459866/zen.2459866.25359.sum.smooth_calibrated.red_avg.uvh5' # 3 unit EW\n",
    "\n",
    "CORNER_TURN_MAP_YAML = os.environ.get(\"CORNER_TURN_MAP_YAML\", \n",
    "                                        os.path.join(os.path.dirname(RED_AVG_FILE), \"single_baseline_files/corner_turn_map.yaml\"))\n",
    "\n",
    "R3_FLAG_FILE = os.environ.get(\"R3_FLAG_FILE\", None)\n",
    "if R3_FLAG_FILE is None:\n",
    "    jdstr = [s for s in os.path.basename(RED_AVG_FILE).split('.') if s.isnumeric()][0]\n",
    "    R3_FLAG_FILE = os.path.basename(RED_AVG_FILE).split(jdstr)[0] + jdstr + '.flag_waterfall_round_3.h5'\n",
    "    R3_FLAG_FILE = os.path.join(os.path.dirname(CORNER_TURN_MAP_YAML), R3_FLAG_FILE)\n",
    "\n",
    "for setting in ['RED_AVG_FILE', 'CORNER_TURN_MAP_YAML', 'R3_FLAG_FILE']:\n",
    "    print(f'{setting} = \"{eval(setting)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a7e03-73bc-422e-946a-2fcef7fd0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_LOW_FREQ = float(os.environ.get(\"FM_LOW_FREQ\", 87.5)) # in MHz\n",
    "FM_HIGH_FREQ = float(os.environ.get(\"FM_HIGH_FREQ\", 108.0)) # in MHz\n",
    "\n",
    "AUTO_INPAINT_DELAY = float(os.environ.get(\"AUTO_INPAINT_DELAY\", 100)) # in ns\n",
    "INPAINT_DELAY = float(os.environ.get(\"INPAINT_DELAY\", 1000)) # in ns\n",
    "ITERATIVE_DELAY_DELTA = float(os.environ.get(\"ITERATIVE_DELAY_DELTA\", 25)) # in ns\n",
    "EIGENVAL_CUTOFF = float(os.environ.get(\"EIGENVAL_CUTOFF\", 1e-12))\n",
    "CG_TOL = float(os.environ.get(\"CG_TOL\", 1e-6))\n",
    "\n",
    "INPAINTED_EXTENSION = os.environ.get(\"INPAINTED_EXTENSION\", \".inpainted.uvh5\")\n",
    "WHERE_INPAINTED_EXTENSION = os.environ.get(\"WHERE_INPAINTED_EXTENSION\", \".where_inpainted.h5\")\n",
    "\n",
    "INPAINT_WIDTH_FACTOR = float(os.environ.get(\"INPAINT_WIDTH_FACTOR\", 0.5))\n",
    "INPAINT_ZERO_DIST_WEIGHT = float(os.environ.get(\"INPAINT_ZERO_DIST_WEIGHT\", 1e-2))\n",
    "\n",
    "AUTO_FR_SPECTRUM_FILE = '/lustre/aoc/projects/hera/zmartino/hera_frf/spectra_cache/spectra_cache_hera_auto.h5'\n",
    "GAUSS_FIT_BUFFER_CUT = float(os.environ.get(\"GAUSS_FIT_BUFFER_CUT\", 1e-5))\n",
    "\n",
    "FR0_FILTER = os.environ.get(\"FR0_FILTER\", \"TRUE\").upper() == \"TRUE\"\n",
    "FR0_FILTER_EXTENSION = os.environ.get(\"FR0_FILTER_EXTENSION\", \".inpainted.FR0_filtered.uvh5\")\n",
    "FR0_HALFWIDTH = float(os.environ.get(\"FR0_HALFWIDTH\", 0.01))  # in mHz\n",
    "\n",
    "for setting in ['AUTO_FR_SPECTRUM_FILE', 'FR0_FILTER_EXTENSION']:\n",
    "    print(f'{setting} = \"{eval(setting)}\"')\n",
    "for setting in ['FM_LOW_FREQ', 'FM_HIGH_FREQ', 'INPAINT_DELAY', 'ITERATIVE_DELAY_DELTA', \n",
    "                'EIGENVAL_CUTOFF', 'CG_TOL', 'GAUSS_FIT_BUFFER_CUT', \n",
    "                'FR0_FILTER', 'FR0_HALFWIDTH']:\n",
    "    print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33468fae-7137-40bc-8fc0-fb3a265b13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_history = 'Produced by single_baseline_2D_informed_inpaint notebook with the following environment:\\n' + '=' * 65 + '\\n' + os.popen('mamba env export').read() + '=' * 65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98c109-2ce1-447a-8dad-372cb5a396fe",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1aaf0-3e7c-43ad-af50-1e8cd86325a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # This branch is meant for interactive testing of the notebook (e.g. for exploring new algorithms), avoiding corner turn logic\n",
    "\n",
    "    # EDIT THIS TO PICK A DIFFERENT JD/BASELINE FROM THE LIST BELOW (no need to edit the rest, in theory)\n",
    "    RED_AVG_FILE = '/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.2459866.baseline.0_4.sum.smooth_calibrated.red_avg.uvh5' \n",
    "    \n",
    "    files = ['/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.2459861.baseline.0_0.sum.smooth_calibrated.red_avg.uvh5', \n",
    "             '/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.2459861.baseline.0_1.sum.smooth_calibrated.red_avg.uvh5',\n",
    "             '/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.2459861.baseline.0_4.sum.smooth_calibrated.red_avg.uvh5',\n",
    "             '/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.2459861.baseline.1_61.sum.smooth_calibrated.red_avg.uvh5',\n",
    "             '/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.2459866.baseline.0_0.sum.smooth_calibrated.red_avg.uvh5',\n",
    "             '/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.2459866.baseline.0_1.sum.smooth_calibrated.red_avg.uvh5',\n",
    "             '/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.2459866.baseline.0_4.sum.smooth_calibrated.red_avg.uvh5',\n",
    "             '/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.2459866.baseline.1_61.sum.smooth_calibrated.red_avg.uvh5']\n",
    "    corner_turn_map = {'files_to_outfiles_map': {f: [f] for f in files}}\n",
    "    jdstr = [s for s in os.path.basename(RED_AVG_FILE).split('.') if s.isnumeric()][0]\n",
    "    R3_FLAG_FILE = f'/users/jsdillon/lustre/H6C/2D_inpainting_battletest/zen.{jdstr}.flag_waterfall_round_3.h5'\n",
    "else:\n",
    "    with open(CORNER_TURN_MAP_YAML, 'r') as file:\n",
    "        corner_turn_map = yaml.unsafe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041f453-2bc3-4933-8c58-361d0317204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get round 3 flags\n",
    "print(f'Loading {R3_FLAG_FILE} for additional flags to add to the data.')\n",
    "uvf = UVFlag(R3_FLAG_FILE)\n",
    "round_3_flags = np.all(uvf.flag_array, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11161ce1-1eda-4239-9f8e-f3d7658fde14",
   "metadata": {},
   "source": [
    "## Functions for main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae6e19-c2e2-43c3-9e4a-c59bd1bc796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FR_buffers_from_spectra(antpair, jds, freqs, bands, gauss_fit_buffer_cut=GAUSS_FIT_BUFFER_CUT):\n",
    "    '''This function computes an appropriate buffer to fringe-rate half-widths for a given antpair and times.\n",
    "    These are used to pad the widths given by hera_cal.frf.sky_frates() for the basic calculation, with a\n",
    "    Gaussian fit the the FR spectra of the autocorrelation at the highest frequency (and thus widest FR range) in each band.\n",
    "    \n",
    "    Arguments:\n",
    "        antpair: 2-tuple of antennas\n",
    "        jds: times in units of days\n",
    "        freqs: frequencies in Hz\n",
    "        bands: list of slices into freqs\n",
    "        gauss_fit_buffer_cut: where to cutoff the Gaussian fit to figure out the halfwidth buffer\n",
    "\n",
    "    Returns:\n",
    "        fr_buffers: dict from band slice to FR buffers in mHz\n",
    "    '''\n",
    "    with h5py.File(AUTO_FR_SPECTRUM_FILE, \"r\") as h5f:\n",
    "        metadata = h5f[\"metadata\"]\n",
    "        bl_to_index_map = {tuple(ap): int(index) for index, antpairs in metadata[\"baseline_groups\"].items() for ap in antpairs}\n",
    "        spectrum_freqs = metadata[\"frequencies_MHz\"][()] * 1e6\n",
    "        m_modes = metadata[\"erh_mode_integer_index\"][()]\n",
    "        mmode_spectrum = h5f[\"erh_mode_power_spectrum\"][:, :, bl_to_index_map[0, 0]]  # use autocorrelation\n",
    "    \n",
    "    # convert to fringe rate, accouting for the fact that we have less than 24 hours of LST\n",
    "    def m2f(m_modes):\n",
    "        # Convert m-modes to fringe-rates in mHz.\n",
    "        return m_modes / units.sday.to(units.ks)\n",
    "    times_ks = (jds - jds[0] + np.median(np.diff(jds))) * units.day.to(units.ks)\n",
    "    m2f_phasors = np.exp(2j * np.pi * m2f(m_modes)[None, :] * times_ks[:, None])\n",
    "    m2f_mixer = np.fft.fftshift(np.fft.fft(np.fft.ifftshift(m2f_phasors, axes=0), axis=0), axes=0)\n",
    "    # f is fringe rate, m is m-mode, n is nu (i.e. freqeuency)\n",
    "    fr_spectrum = np.abs(np.einsum('fm,mn,mf->fn', m2f_mixer, mmode_spectrum, m2f_mixer.T.conj()))\n",
    "\n",
    "    # create interpolator as a funciton of frequency \n",
    "    fr_spec_interpolator = interpolate.interp1d(spectrum_freqs, fr_spectrum, kind='cubic', fill_value='extrapolate')\n",
    "    frates = np.fft.fftshift(np.fft.fftfreq(len(times_ks), d=np.median(np.diff(times_ks))))\n",
    "\n",
    "    # loop over bands to produce results\n",
    "    fr_buffers = {}\n",
    "    for band in bands:\n",
    "        if band is None:\n",
    "            continue\n",
    "        band_top_fr_spectrum = fr_spec_interpolator(freqs[band][-1])  # take top frequency (widest FR) per band\n",
    "        band_top_fr_spectrum /= np.max(band_top_fr_spectrum)\n",
    "\n",
    "        # fit gaussian to get a decent estimate of the width without being too sensitive to the FT of the limited time range\n",
    "        gaussian = lambda x, a, sigma: a * np.exp(-(x**2) / (2 * sigma**2))\n",
    "        initial_guess = [1.0, np.std(frates[band_top_fr_spectrum > 1e-2])]\n",
    "        popt, _ = optimize.curve_fit(gaussian, frates, band_top_fr_spectrum, p0=initial_guess)\n",
    "        fr_buffers[band] = np.abs(2 * popt[1]**2 * np.log(gauss_fit_buffer_cut))**.5  # how far out in the gaussian fit should we go\n",
    "        \n",
    "    return fr_buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469700d-0a38-4759-9f48-7bbdb64150ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fr_centers_and_hws(antpair, hd, times, freqs, bands):\n",
    "    '''Figure out the range of FRs in Hz spanned by each band, buffered by the size of the autocorrelation FR kernel.'''\n",
    "    fr_buffers = get_FR_buffers_from_spectra(antpair, times, freqs, bands)\n",
    "    fr_centers = {}\n",
    "    fr_hws = {}\n",
    "    for band in bands:\n",
    "        if band is None:\n",
    "            continue\n",
    "        hd_here = hd.select(inplace=False, frequencies=hd.freqs[band])\n",
    "        fr_centers[band] = list(sky_frates(hd_here)[0].values())[0] / 1e3  # converts to Hz\n",
    "        fr_hws[band] = (list(sky_frates(hd_here)[1].values())[0] + fr_buffers[band]) / 1e3\n",
    "    return fr_centers, fr_hws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a2e50-6545-4749-a349-ab653ac15f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ip_nsamples(nsamples, tslice, bands):\n",
    "    '''Put in reasonable values for nsamples in totally flagged integrations (used only for 2D DPSS fitting)'''\n",
    "    ip_nsamples = copy.deepcopy(nsamples)\n",
    "    for bl in nsamples:\n",
    "        for band in [low_band, high_band]:\n",
    "            if band is None:\n",
    "                continue\n",
    "            med = np.median(nsamples[bl][tslice, band])\n",
    "            all_flagged = np.all(flags[bl][tslice, band], axis=1)\n",
    "            ip_nsamples[bl][tslice, band][all_flagged] = med\n",
    "\n",
    "    # check that all ip_nsamples are constant across frequency within a band\n",
    "    for band in bands:\n",
    "        assert np.all(ip_nsamples[bl][tslice, band] == ip_nsamples[bl][tslice, band][:, 0:1])\n",
    "    \n",
    "    return ip_nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe439026-ef0e-4f76-8570-bcbfff430c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_for_2D_inpainting(data, flags, ip_autos, auto_flags):\n",
    "    '''Get inverse noise variance weights for inpainting. These come in two flavors:\n",
    "        * weights_before_ip: has 0s wherever the data or autos are flagged\n",
    "        * weights_after_ip: uses inpainted autos for \"noise,\" so only has 0s wherever the \n",
    "            autos weren't inpainted (in practice, no where in the bands/tslice of interest).\n",
    "    '''\n",
    "    weights_before_ip = {}\n",
    "    weights_after_ip = {}\n",
    "    for bl in data:\n",
    "        ant1, ant2 = utils.split_bl(bl)\n",
    "        \n",
    "        auto_bl_1 = [k for k in ip_autos if k[2] == utils.join_pol(ant1[1], ant1[1])][0]\n",
    "        auto_bl_2 = [k for k in ip_autos if k[2] == utils.join_pol(ant2[1], ant2[1])][0]\n",
    "        noise = (np.abs(ip_autos[auto_bl_1] * ip_autos[auto_bl_2]) / (ip_nsamples[bl] * dt * df))**.5\n",
    "        flags_here = (~np.isfinite(ip_autos[auto_bl_1])) | (~np.isfinite(ip_autos[auto_bl_2])) | np.all(flags[bl])\n",
    "        weights_after_ip[bl] = np.where(flags_here, 0, noise**-2)\n",
    "        \n",
    "        flags_here |= flags[bl] | auto_flags[auto_bl_1] | auto_flags[auto_bl_2]\n",
    "        weights_before_ip[bl] = np.where(flags_here, 0, noise**-2)\n",
    "        \n",
    "        for wgts in [weights_after_ip[bl], weights_before_ip[bl]]:\n",
    "            if np.any(wgts > 0):\n",
    "                wgts /= np.mean(wgts[wgts > 0])\n",
    "    return weights_before_ip, weights_after_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86109b44-32ad-4b74-9950-9c8f86528bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_2D_DPSS(data, weights, filter_delay, fr_centers, fr_hws, **kwargs):\n",
    "    '''Fit a 2D DPSS model to all the baselines in data. The time-dimension is based\n",
    "    on sky FRs and the FR spectrum of the autos.\n",
    "    Arguments:\n",
    "        data: datacontainer mapping baselines to complex visibility waterfalls\n",
    "        weights: datacontainer mapping baselines to real weight waterfalls. \n",
    "        filter_delay: maximum delay in ns for the 2D filter\n",
    "        fr_centers: dictionary mapping band to FR centers in Hz\n",
    "        fr_hws: dictionary mapping band to FR half-widths in Hz\n",
    "        kwargs: kwargs to pass into sparse_linear_fit_2D()\n",
    "    \n",
    "    Returns:\n",
    "        dpss_fit: datacontainer mapping baselines to 2D DPSS models\n",
    "    '''\n",
    "    dpss_fit = copy.deepcopy(data)\n",
    "    for bl in data.keys():\n",
    "        # set to all nans by default\n",
    "        dpss_fit[bl] *= np.nan\n",
    "\n",
    "        if np.all(weights[bl] == 0):\n",
    "            continue\n",
    "        \n",
    "        # calculate the unflagged region to filter and thus the FR half-width buffers\n",
    "        tslice, (low_band, high_band) = flag_utils.get_minimal_slices(weights[bl] == 0, freqs=data.freqs, \n",
    "                                                                      freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "        fr_buffers = get_FR_buffers_from_spectra(bl[0:2], data.times[tslice], data.freqs, [low_band, high_band])\n",
    "\n",
    "\n",
    "        for band in [low_band, high_band]:\n",
    "            if (band is None) or np.all(weights[bl][tslice, band] == 0):\n",
    "                continue\n",
    "\n",
    "            # perform 2D DPSS filter    \n",
    "            time_filters, _ = dpss_operator((data.times[tslice] - data.times[tslice][0]) * 3600 * 24, \n",
    "                                            [fr_centers[band]], [fr_hws[band]], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            freq_filters, _ = dpss_operator(data.freqs[band], [0.0], [filter_delay / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])\n",
    "            \n",
    "            fit, meta = sparse_linear_fit_2D(\n",
    "                data=data[bl][tslice, band],\n",
    "                weights=weights[bl][tslice, band],\n",
    "                axis_1_basis=time_filters,\n",
    "                axis_2_basis=freq_filters,\n",
    "                precondition_solver=True,\n",
    "                **kwargs,\n",
    "            )\n",
    "            dpss_fit[bl][tslice, band] = time_filters.dot(fit).dot(freq_filters.T)\n",
    "            \n",
    "    return dpss_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00c6e2-3ca9-4f36-b62a-b419bcb911eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_nearest_nonzero_vectorized(arr):\n",
    "    \"\"\"\n",
    "    For each index in `arr`, return the distance (number of indices) \n",
    "    to the nearest nonzero entry, using a fully vectorized 1D distance transform.\n",
    "    \"\"\"\n",
    "    indices = np.arange(len(arr))\n",
    "\n",
    "    # 1) Find nearest nonzero to the left of each position.\n",
    "    left_pos = np.where(arr != 0, indices, -np.inf)\n",
    "    left_pos = np.maximum.accumulate(left_pos)  # in-place left-to-right\n",
    "    dist_left = np.where(~np.isfinite(left_pos), np.inf, indices - left_pos)\n",
    "\n",
    "    # 2) Find nearest nonzero to the right of each position.\n",
    "    right_pos = np.where(arr != 0, indices, np.inf)\n",
    "    right_pos = np.minimum.accumulate(right_pos[::-1])[::-1] # in-place right-to-left\n",
    "    dist_right = np.where(~np.isfinite(right_pos), np.inf, right_pos - indices)\n",
    "\n",
    "    # 3) Final distance is the min of left- and right-distances.\n",
    "    return np.minimum(dist_left, dist_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e11fb-3634-40e5-836a-a93615c7335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_pol_inpainting_figure(ip_data, flags, ip_flags, close=False):\n",
    "    '''Plots all phase and amplitude waterfalls before and after inpainting for all 4 polarizations in the data.'''\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(16, 30), sharex=True, sharey=True, dpi=200, gridspec_kw={'wspace': 0.02, 'hspace': 0.01})\n",
    "    \n",
    "    vmin = np.nanmin([np.where(~flags[bl], np.abs(ip_data[bl]), np.nan) for bl in ip_data])\n",
    "    vmax = np.nanmax([np.where(~flags[bl], np.abs(ip_data[bl]), np.nan) for bl in ip_data])\n",
    "    lst_grid = ip_data.lsts * 12 / np.pi\n",
    "    lst_grid[lst_grid > lst_grid[-1]] -= 24\n",
    "    extent = [ip_data.freqs[0] / 1e6, ip_data.freqs[-1] / 1e6, lst_grid[-1], lst_grid[0]]\n",
    "    \n",
    "    for row, bl in zip(axes, data):\n",
    "    \n",
    "        row[0].imshow(np.where(flags[bl], np.nan, np.angle(ip_data[bl])), aspect='auto', interpolation='none', cmap='twilight', extent=extent)\n",
    "        row[1].imshow(np.where(ip_flags[bl], np.nan, np.angle(ip_data[bl])), aspect='auto', interpolation='none', cmap='twilight', extent=extent)\n",
    "        row[2].imshow(np.where(flags[bl], np.nan, np.abs(ip_data[bl])), aspect='auto', interpolation='none', norm=matplotlib.colors.LogNorm(vmin=vmin, vmax=vmax), extent=extent)\n",
    "        im = row[3].imshow(np.where(ip_flags[bl], np.nan, np.abs(ip_data[bl])), aspect='auto', interpolation='none', norm=matplotlib.colors.LogNorm(vmin=vmin, vmax=vmax), extent=extent)\n",
    "        mod24 = lambda x, _: f\"{int(x % 24)}\"\n",
    "        row[0].yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(mod24))\n",
    "        \n",
    "        row[0].set_ylabel('LST (hours)')\n",
    "        for ax in row:\n",
    "            ax.tick_params(axis='x', direction='in')\n",
    "    \n",
    "        row[0].text(0.02, 0.99, bl, transform=row[0].transAxes, ha='left', va='top', fontsize=12, color='white',\n",
    "                bbox=dict(facecolor='black', alpha=0.5, pad=2))\n",
    "    \n",
    "    for ax in axes[-1]:\n",
    "        ax.set_xlabel('Frequency (MHz)')\n",
    "    \n",
    "    plt.tight_layout()   \n",
    "    plt.colorbar(im, ax=axes[0], location='top', label='|V| (Jy)', aspect=50)\n",
    "    \n",
    "    if close:\n",
    "        plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a695bb67-471f-4346-b593-ad8fd94ce8b0",
   "metadata": {},
   "source": [
    "## Generate smooth model of autos for noise modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933c1dd-7f1b-4617-a2a2-8193de766490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get autocorrelations\n",
    "all_outfiles = [outfile for outfiles in corner_turn_map['files_to_outfiles_map'].values() for outfile in outfiles]\n",
    "for outfile in all_outfiles:\n",
    "    match = re.search(r'\\.(\\d+)_(\\d+)\\.', os.path.basename(outfile))\n",
    "    if match and match.group(1) == match.group(2):\n",
    "        print(f'Loading {outfile} for autocorrelations to use for noise modeling.')\n",
    "        hd_autos = io.HERAData(outfile)\n",
    "        autos, auto_flags, auto_nsamples = hd_autos.read(polarizations=['ee', 'nn'])\n",
    "        dt = np.median(np.diff(hd_autos.times)) * 24 * 3600\n",
    "        df = np.median(np.diff(hd_autos.freqs))        \n",
    "        for bl in auto_flags:\n",
    "            auto_flags[bl] |= round_3_flags\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575a500-2578-4ba2-b603-108826e73582",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "for bl in autos:\n",
    "    noise = 2 *np.abs(autos[bl]) / (auto_nsamples[bl] * dt * df)**.5\n",
    "    weights[bl] = np.where(auto_flags[bl], 0, noise**-2)\n",
    "    weights[bl] /= np.mean(weights[bl][weights[bl] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a17a24-6b92-4471-bc7b-801a25bbf55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tslice, (low_band, high_band) = flag_utils.get_minimal_slices(np.all([weights[bl] == 0 for bl in weights], axis=0), \n",
    "                                                              freqs=autos.freqs, freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "fr_centers, fr_hws = get_fr_centers_and_hws(autos.antpairs().pop(), hd_autos, autos.times[tslice], \n",
    "                                            autos.freqs, [low_band, high_band])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b37d42-da6c-4f71-9cd2-c4f676553a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_fit = fit_2D_DPSS(autos, weights, AUTO_INPAINT_DELAY, fr_centers, fr_hws, atol=CG_TOL, btol=CG_TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152baa73-c5f5-4fd0-b86f-fd77c0855f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unused objects to save memory\n",
    "del hd_autos, autos, auto_nsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53838296-19ab-431f-856c-1a9ded504da0",
   "metadata": {},
   "source": [
    "## Main loop for inpainting crosses (and possibly also doing a FR=0 notch filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1e30b-cdcd-4b92-9d3c-9419abfc8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfall_figs = []\n",
    "\n",
    "for single_bl_file in corner_turn_map['files_to_outfiles_map'][RED_AVG_FILE]:\n",
    "\n",
    "    # load data\n",
    "    print(f'Now loading {single_bl_file}')\n",
    "    hd = io.HERAData(single_bl_file)\n",
    "    data, flags, nsamples = hd.read()\n",
    "    dt = np.median(np.diff(hd.times)) * 24 * 3600\n",
    "    df = np.median(np.diff(hd.freqs))\n",
    "    antpair = data.antpairs().pop()\n",
    "    is_auto = (antpair[0] == antpair[1])\n",
    "    for bl in flags:\n",
    "        # update with round 3 flags\n",
    "        flags[bl] |= round_3_flags\n",
    "\n",
    "    if np.all([flags[bl] for bl in flags]):\n",
    "        print('\\tThis baseline is entirely flagged. Skipping...')\n",
    "        continue\n",
    "    \n",
    "    # get tslice and bands\n",
    "    tslice, (low_band, high_band) = flag_utils.get_minimal_slices(np.all([flags[bl] for bl in flags], axis=0), freqs=data.freqs, \n",
    "                                                                  freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6])\n",
    "    # compute FR ranges plausibly attributable to the sky\n",
    "    fr_centers, fr_hws = get_fr_centers_and_hws(data.antpairs().pop(), hd, data.times[tslice], \n",
    "                                                data.freqs, [low_band, high_band])\n",
    "\n",
    "    # fill in nsamples in totally flagged integrations with reasonable values, used only for weighting, not updated in data\n",
    "    ip_nsamples = get_ip_nsamples(nsamples, tslice, (low_band, high_band))\n",
    "\n",
    "    # get weights for 2D DPSS fitting\n",
    "    weights_before_ip, weights_after_ip = get_weights_for_2D_inpainting(data, flags, auto_fit, auto_flags)\n",
    "\n",
    "    # set up ip_weights and where_inpainted\n",
    "    ip_flags = copy.deepcopy(flags)\n",
    "    where_inpainted = copy.deepcopy(flags)\n",
    "    for bl in ip_flags:\n",
    "        ip_flags[bl][:, :] = True\n",
    "        where_inpainted[bl][:, :] = False\n",
    "        for band in [low_band, high_band]:\n",
    "            if band is None:\n",
    "                continue\n",
    "            ip_flags[bl][tslice, band] = np.all(weights_before_ip[bl][tslice, band] == 0, axis=1, keepdims=True)\n",
    "            where_inpainted[bl][tslice, band] = flags[bl][tslice, band] & (~ip_flags[bl][tslice, band])\n",
    "\n",
    "    # perform iterative 2D DPSS fitting and inpainting\n",
    "    current_filter_delay = ITERATIVE_DELAY_DELTA\n",
    "    dpss_fit = None\n",
    "    ip_data = None\n",
    "    while True:\n",
    "        print(f'\\tNow inpainting out to {current_filter_delay} ns.')\n",
    "\n",
    "        if dpss_fit is None:\n",
    "            # first fit with gaps in data\n",
    "            weights = weights_before_ip\n",
    "            data_here = data\n",
    "        else:\n",
    "            # subsequent fits\n",
    "            weights = weights_after_ip\n",
    "            data_here = ip_data\n",
    "    \n",
    "        dpss_fit = fit_2D_DPSS(data_here, weights, current_filter_delay, fr_centers, fr_hws, \n",
    "                               atol=CG_TOL, btol=CG_TOL)\n",
    "    \n",
    "        ip_data = copy.deepcopy(data)\n",
    "        for bl in ip_data:\n",
    "            ip_data[bl] = np.where(flags[bl], dpss_fit[bl], data[bl])\n",
    "\n",
    "        # increment current delay until we finally do INPAINT_DELAY\n",
    "        if current_filter_delay == INPAINT_DELAY:\n",
    "            break\n",
    "        current_filter_delay += ITERATIVE_DELAY_DELTA\n",
    "        if current_filter_delay > INPAINT_DELAY:\n",
    "            current_filter_delay = INPAINT_DELAY\n",
    "\n",
    "    # Perform 2D-informed (feathered) \n",
    "    ip_data = copy.deepcopy(data)\n",
    "    print(f'\\tNow performing 2D-informed 1D DPSS inpainting out to {INPAINT_DELAY} ns.')\n",
    "    for bl in ip_data:\n",
    "        # figure out feathering\n",
    "        distances = np.array([distance_to_nearest_nonzero_vectorized(~flags[bl][tind, :]) for tind in range(flags[bl].shape[0])])\n",
    "        width = (1e-9 * INPAINT_DELAY)**-1 / df * INPAINT_WIDTH_FACTOR\n",
    "        rel_weights = (1 + np.exp(-np.log(INPAINT_ZERO_DIST_WEIGHT**-1 - 1) / width * (distances - width)))**-1\n",
    "    \n",
    "        d_mdl = np.full_like(data[bl], np.nan)\n",
    "        for band in [low_band, high_band]: \n",
    "            if band is None:\n",
    "                continue\n",
    "\n",
    "            # weights from inpainted autos, except totally-flagged integrations, then mutliplied by rel_weights where originally flagged\n",
    "            wgts = np.where(ip_flags[bl][:, band], 0, weights_after_ip[bl][:, band])\n",
    "            wgts = np.where(flags[bl][:, band], wgts * rel_weights[:, band], wgts)\n",
    "            if np.any(wgts > 0):\n",
    "                wgts /= np.mean(wgts[wgts > 0])\n",
    "\n",
    "            # 1D DPSS fitting\n",
    "            d_mdl[:, band], _, _ = fourier_filter(data.freqs[band],\n",
    "                                                  np.where(flags[bl], dpss_fit[bl], data[bl])[:, band],\n",
    "                                                  wgts=wgts,\n",
    "                                                  filter_centers=[0],\n",
    "                                                  filter_half_widths=[INPAINT_DELAY * 1e-9], \n",
    "                                                  mode='dpss_solve',\n",
    "                                                  eigenval_cutoff=[EIGENVAL_CUTOFF], \n",
    "                                                  suppression_factors=[EIGENVAL_CUTOFF], \n",
    "                                                  max_contiguous_edge_flags=len(data.freqs),\n",
    "                                                  filter_dims=1)\n",
    "        # fill in model where we inpaint, 2D dpss_fit where we don't but were stilled flagged, and data otherwise\n",
    "        ip_data[bl] = np.where(where_inpainted[bl], d_mdl, np.where(flags[bl], dpss_fit[bl], data[bl]))\n",
    "\n",
    "    # perform FR=0 filter, if desired\n",
    "    if FR0_FILTER and not is_auto:\n",
    "        fr0_filt_ip_data = copy.deepcopy(ip_data)\n",
    "        for bl in fr0_filt_ip_data:\n",
    "            wgts_here = np.where(ip_flags[bl], 0, weights_after_ip[bl])[tslice, :]\n",
    "            d_mdl, _, info = fourier_filter(data.times[tslice] * 24 * 60 * 60, \n",
    "                                            np.where(wgts_here == 0, 0, fr0_filt_ip_data[bl][tslice]), \n",
    "                                            wgts=wgts_here,\n",
    "                                            filter_centers=[0], \n",
    "                                            filter_half_widths=[FR0_HALFWIDTH / 1000], \n",
    "                                            mode='dpss_solve', \n",
    "                                            eigenval_cutoff=[EIGENVAL_CUTOFF], \n",
    "                                            suppression_factors=[EIGENVAL_CUTOFF], \n",
    "                                            max_contiguous_edge_flags=len(data.times), \n",
    "                                            filter_dims=0)\n",
    "            fr0_filt_ip_data[bl][tslice] -= d_mdl\n",
    "    \n",
    "    # save figures to display later\n",
    "    if not np.all(list(flags.values())):\n",
    "        waterfall_figs.append(four_pol_inpainting_figure((fr0_filt_ip_data if (FR0_FILTER and not is_auto) else ip_data), \n",
    "                                                         flags, ip_flags, close=True))\n",
    "\n",
    "    # Save inpainting results\n",
    "    hd.update(data=ip_data, flags=ip_flags)\n",
    "    hd.history += add_to_history\n",
    "    hd.write_uvh5(single_bl_file.replace('.uvh5', INPAINTED_EXTENSION), clobber=True)\n",
    "\n",
    "    # Save inpainting results\n",
    "    if FR0_FILTER and not is_auto:\n",
    "        hd.update(data=fr0_filt_ip_data)\n",
    "        hd.write_uvh5(single_bl_file.replace('.uvh5', FR0_FILTER_EXTENSION), clobber=True)\n",
    "    \n",
    "    # Save where_inpainted metadata\n",
    "    hd.update(flags=where_inpainted)\n",
    "    uvf = UVFlag(hd, mode='flag', copy_flags=True)\n",
    "    uvf.history += add_to_history\n",
    "    uvf.write(single_bl_file.replace('.uvh5', WHERE_INPAINTED_EXTENSION), clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e8305-b62a-4414-b1b4-b12fdd2b5fe8",
   "metadata": {},
   "source": [
    "# *Figure 1: 4-Pol Phase and Amplitude Waterfalls Before and After Inpainting*\n",
    "\n",
    "Note that this includes FR=0 filtering if `FR0_FILTER` is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15223e-cd10-4055-ab2d-507e2a6c36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wf_fig in waterfall_figs:\n",
    "    display(wf_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b34345-517a-4b5a-b378-877a3ed3826a",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea308ec0-e1e7-47cf-b887-7c330baa0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata', 'numpy']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abb874-6be1-4b68-a2f3-847873cfaf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

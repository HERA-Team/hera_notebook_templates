{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9118075-181e-4d79-ba39-c443c27bf56a",
   "metadata": {},
   "source": [
    "# Single Night LST-Binned Calibration Notebook\n",
    "\n",
    "**by Tyler Cox**, last updated on Sept 8th, 2025\n",
    "\n",
    "This notebook performs LST-binned calibration (or LST-cal) on whole-JD, single-baseline, all polarization files. Most parameters are controlled by a toml config file, [such as this one](https://github.com/HERA-Team/hera_pipelines/blob/main/pipelines/h6c/idr3/v1/lstbin/single_bl_lst_stack_config.toml). In addition to single-baseline files, this notebook also requires UVFlag-compatible `where_inpainted` files which tell us where inpainting was previously done.\n",
    "\n",
    "To keep the total memory footprint of the notebook reasonable, the full list of baselines are first downselected to a subset of the `Nbls` redundant baseline types that have the largest number of `nsamples`, and then compute the redundant-calibration degenerate parameters (namely, the per-frequency/time amplitude, tip-tilt, and cross-polarized phase degeneracies) that bring a single night into better alignment with the LST-average. The calibration parameters are then smoothed in time and frequency with DPSS basis functions given a user specified time and frequency smoothing scale.\n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "\n",
    "# [• Figure 1: Amplitude Parameters Before/After Smoothing](#Figure-1:-Amplitude-Parameters-Before/After-Smoothing)\n",
    "# [• Figure 2: Tip/Tilt Parameters Before/After Smoothing](#Figure-2:-Tip/Tilt-Parameters-Before/After-Smoothing)\n",
    "# [• Figure 3: Cross-Polarized Phase Before/After Smoothing](#Figure-3:-Cross-Polarized-Phase-Before/After-Smoothing)\n",
    "# [• Figure 4: Visibility/LST-Averaged Variance Across Baseline Before/After LST-Cal](#Figure-4:-Visibility/LST-Averaged-Variance-Across-Baseline-Before/After-LST-Cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c4381-70cb-4340-acaf-a1c0a5094130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu') # Force jax to use CPU if GPU available\n",
    "\n",
    "import re\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import glob\n",
    "import toml\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "\n",
    "from pyuvdata import UVData\n",
    "from hera_cal.lst_stack import LSTConfig\n",
    "from hera_cal import lst_stack, io, flag_utils, abscal, datacontainer, redcal, utils, smooth_cal, red_groups\n",
    "from hera_qm.time_series_metrics import true_stretches\n",
    "from hera_filters.dspec import fourier_filter, dpss_operator\n",
    "from hera_cal.lst_stack.calibration import _expand_degeneracies_to_ant_gains\n",
    "from hera_cal.lst_stack.config import LSTBinConfiguratorSingleBaseline, make_lst_grid\n",
    "from hera_cal.lst_stack.binning import SingleBaselineStacker, _get_freqs_chans, adjust_lst_bin_edges, _allocate_dfn, get_lst_bins\n",
    "\n",
    "from hera_qm.metrics_io import read_a_priori_ant_flags\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"hera_cal\")\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc57a03-7f15-4d3c-b7f5-9d4c2c13763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_file = os.environ.get(\n",
    "    'TOML_FILE', '/lustre/aoc/projects/hera/h6c-analysis/IDR3/src/hera_pipelines/pipelines/h6c/idr3/v1/lstbin/single_bl_lst_stack.toml'\n",
    ")\n",
    "print(f'toml_file = \"{toml_file}\"')\n",
    "\n",
    "baseline_string = os.environ.get('BASELINE_STRING', None)\n",
    "print(f'baseline_string = \"{baseline_string}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7644b04-7e83-48e7-adf2-90c75fc2ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get options from toml file, print them out, and update globals\n",
    "toml_options = toml.load(toml_file)\n",
    "\n",
    "print(f\"Now setting the following global variables from {toml_file}:\\n\")\n",
    "\n",
    "globals().update({'lst_branch_cut': toml_options['FILE_CFG']['lst_branch_cut']})\n",
    "print(f\"lst_branch_cut = {lst_branch_cut}\")\n",
    "\n",
    "globals().update({'where_inpainted_file_rules': toml_options['FILE_CFG']['where_inpainted_file_rules']})\n",
    "print(f\"where_inpainted_file_rules = {where_inpainted_file_rules}\")\n",
    "\n",
    "# this is used for an initial stacking of a handful of baselines, which are then used for LSTCal\n",
    "toml_options['LST_STACK_OPTS']['FNAME_FORMAT'] = toml_options['LST_STACK_OPTS']['FNAME_FORMAT'].replace('.sum.uvh5', '.preliminary.sum.uvh5')\n",
    "\n",
    "for key, val in toml_options['LSTCAL_OPTS'].items():\n",
    "    if isinstance(val, str):\n",
    "        print(f'{key} = \"{val}\"')\n",
    "    else:\n",
    "        print(f'{key} = {val}')\n",
    "globals().update(toml_options['LSTCAL_OPTS'])\n",
    "        \n",
    "for key, val in toml_options['LST_STACK_OPTS'].items():\n",
    "    if isinstance(val, str):\n",
    "        print(f'{key} = \"{val}\"')\n",
    "    else:\n",
    "        print(f'{key} = {val}')\n",
    "globals().update(toml_options['LST_STACK_OPTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22dfb3-c538-4118-af40-88eaf087c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline configurator\n",
    "configurator = lst_stack.config.LSTBinConfiguratorSingleBaseline.from_toml(toml_file)\n",
    "auto_baseline_string = [s for s in configurator.bl_to_file_map if (p := s.split('_'))[0] == p[1]][0]\n",
    "\n",
    "# Get metadata for LST-stacking\n",
    "hd = io.HERAData(\n",
    "    configurator.bl_to_file_map[baseline_string][-1]\n",
    ")\n",
    "df = np.median(np.diff(hd.freqs))\n",
    "dlst = np.median(np.diff(hd.lsts))\n",
    "lst_grid = lst_stack.config.make_lst_grid(dlst, begin_lst=0, lst_width=(2 * np.pi)) # _fix_dlst function making the grid the wrong size\n",
    "lst_bin_edges =  np.concatenate([lst_grid - dlst / 2, (lst_grid[-1] + dlst / 2)[None]])\n",
    "\n",
    "# Julian dates for LST-calibration\n",
    "jds = [int(night) for night in configurator.nights]\n",
    "filepath = toml_options['FILE_CFG']['datafiles']['datadir']\n",
    "aposteriori_yamls = {jd: filepath + f'/{jd}/{jd}_aposteriori_flags.yaml' for jd in jds}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba176262-78e2-48ae-9dbd-4d06a5520eb7",
   "metadata": {},
   "source": [
    "# 1. Load Single Night Data and Rephase to Correct LST-bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7317c6-cb9d-48c8-8d3e-aaeffe358217",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bl_strings = sorted(list(configurator.bl_to_file_map.keys()))\n",
    "\n",
    "bl_string_to_jd_map = {\n",
    "    bl_string: night\n",
    "    for night, bl_string in zip(sorted(configurator.nights), all_bl_strings)\n",
    "}\n",
    "\n",
    "# Get baseline keys from the files that have been previously saved by the stacking notebook\n",
    "single_bl_files = glob.glob(\n",
    "    os.path.join(OUTDIR, FNAME_FORMAT.format(bl_str=\"*\"))\n",
    ")\n",
    "\n",
    "pattern = '^' + re.escape(os.path.join(OUTDIR, FNAME_FORMAT)).replace(r'\\{bl_str\\}', r'(?P<a>\\d+)_(?P<b>\\d+)') + '$'\n",
    "rx = re.compile(pattern)\n",
    "\n",
    "baselines = []\n",
    "baseline_strings = []\n",
    "for file in single_bl_files:\n",
    "    match = rx.match(file)\n",
    "    i, j = map(int, match.groups())\n",
    "    baselines.append((i, j))\n",
    "    baseline_strings.append(\"{}_{}\".format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a911e43-7d3a-45fe-97b3-b8614c7b3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the JD for this particular file\n",
    "RUN_CALIBRATION = baseline_string in bl_string_to_jd_map\n",
    "\n",
    "if RUN_CALIBRATION:\n",
    "    jd_here = bl_string_to_jd_map[baseline_string]\n",
    "    \n",
    "    # Now load good baselines for a single day\n",
    "    single_day_config = deepcopy(configurator)\n",
    "    single_day_config.nights = [str(jd_here)]\n",
    "    single_day_config.bl_to_file_map = single_day_config.build_bl_to_file_map()\n",
    "    \n",
    "    # Set up dictionaries to store \n",
    "    data_for_cal = {}\n",
    "    wgts = {}\n",
    "    model = {}\n",
    "    where_inpainted = {}\n",
    "    all_flagged = {}\n",
    "    \n",
    "    if RUN_CROSS_POL_PHASE_CAL:\n",
    "        cross_pol_model = {}\n",
    "        cross_pol_data = {}\n",
    "    \n",
    "    # Loop through baseline strings\n",
    "    for bl_string in baseline_strings:\n",
    "        crosses = SingleBaselineStacker.from_configurator(\n",
    "            single_day_config,\n",
    "            bl_string,\n",
    "            lst_bin_edges,\n",
    "            lst_branch_cut=lst_branch_cut, \n",
    "            where_inpainted_file_rules=where_inpainted_file_rules\n",
    "        )\n",
    "    \n",
    "        # Get antennas that make up the baseline\n",
    "        ai, aj = list(map(int, bl_string.split('_')))\n",
    "    \n",
    "        # Load the corresponding LST-binned baseline\n",
    "        bl_to_load = os.path.join(OUTDIR, FNAME_FORMAT.format(bl_str=bl_string))\n",
    "        \n",
    "        polarizations = crosses.hd.pols if RUN_CROSS_POL_PHASE_CAL else crosses.hd.pols[:2]\n",
    "        hd = io.HERAData(bl_to_load)\n",
    "        single_bl_stacked_data, lst_avg_flags, _ = hd.read(polarizations=polarizations)\n",
    "    \n",
    "        # Match lst-averaged to data and handle precision loss from converting to times to LSTs\n",
    "        lst_grid = hd.lsts.copy()\n",
    "        lst_grid[lst_grid[0] > lst_grid] += 2 * np.pi\n",
    "        lst_grid_rounding_factor = np.abs(np.floor(np.log10(dlst) - 2)).astype(int)\n",
    "        indices = np.searchsorted(\n",
    "            np.round(lst_grid, lst_grid_rounding_factor), \n",
    "            np.round(crosses.bin_lst, lst_grid_rounding_factor)\n",
    "        )\n",
    "    \n",
    "        \n",
    "        for pi, pol in enumerate(polarizations):\n",
    "            # Set the weights\n",
    "            nsamples = np.concatenate([_nsamples[..., pi] for _nsamples in crosses.nsamples], axis=0)\n",
    "            flags = np.concatenate([_flags[..., pi] for _flags in crosses.flags], axis=0)\n",
    "            model_flags = np.concatenate([\n",
    "                np.repeat(lst_avg_flags[(ai, aj, pol)][[idx]], len(tinb), axis=0)\n",
    "                for idx, tinb in zip(indices, crosses.times_in_bins)\n",
    "            ], axis=0)\n",
    "            flags |= model_flags\n",
    "            \n",
    "            wgts[(ai, aj, pol)] = nsamples * (~flags).astype(float)\n",
    "            \n",
    "            if pol in flags:\n",
    "                all_flagged[pol] &= flags\n",
    "            else:\n",
    "                all_flagged[pol] = flags\n",
    "    \n",
    "            if pol in where_inpainted:\n",
    "                where_inpainted[pol] &= np.concatenate([winp[..., pi] for winp in crosses.where_inpainted], axis=0)\n",
    "            else:\n",
    "                where_inpainted[pol] = np.concatenate([winp[..., pi] for winp in crosses.where_inpainted], axis=0)\n",
    "            \n",
    "            if pol[0] == pol[1]:\n",
    "                data_for_cal[(ai, aj, pol)] = np.concatenate([_data[..., pi] for _data in crosses.data], axis=0)\n",
    "                model[(ai, aj, pol)] = np.concatenate([\n",
    "                    single_bl_stacked_data[(ai, aj, pol)][[idx]] * np.ones((len(tinb), 1))\n",
    "                    for idx, tinb in zip(indices, crosses.times_in_bins)\n",
    "                ], axis=0)\n",
    "            else:\n",
    "                cross_pol_data[(ai, aj, pol)] = np.concatenate([_data[..., pi] for _data in crosses.data], axis=0)\n",
    "                cross_pol_model[(ai, aj, pol)] = np.concatenate([\n",
    "                    single_bl_stacked_data[(ai, aj, pol)][[idx]] * np.ones((len(tinb), 1))\n",
    "                    for idx, tinb in zip(indices, crosses.times_in_bins)\n",
    "                ], axis=0)\n",
    "    \n",
    "            \n",
    "    \n",
    "    # Get the frequencies and times of the data\n",
    "    freqs = crosses.hd.freqs\n",
    "    times = np.concatenate(crosses.times_in_bins)\n",
    "\n",
    "    # Get the original time grid\n",
    "    single_jd_hd = io.HERAData(single_day_config.bl_to_file_map[bl_string])\n",
    "    single_jd_times = single_jd_hd.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0293d0-603b-47f2-b449-3f14be097723",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    autos = SingleBaselineStacker.from_configurator(\n",
    "        single_day_config,\n",
    "        auto_baseline_string,\n",
    "        lst_bin_edges,\n",
    "        lst_branch_cut=lst_branch_cut, \n",
    "        where_inpainted_file_rules=where_inpainted_file_rules\n",
    "    )\n",
    "    \n",
    "    auto_model = {}\n",
    "    for pi, pol in enumerate(polarizations):\n",
    "        auto_model[(0, 0, pol)] = np.concatenate([_data[..., pi] for _data in autos.data], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db07a485-18d8-48a3-91e6-4e6705ddff00",
   "metadata": {},
   "source": [
    "# 2. LST-Binned Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837e04a-7083-4e44-90df-65a46f242942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_phase_abscal(data, model, reds, data_bls, model_bls, transformed_antpos=None, newton_maxiter=50):\n",
    "    \"\"\"\n",
    "    Stripped down version of hera_cal.abscal.complex_phase_abscal that assumes the tip-tilt solution is close to zero. \n",
    "    Calculates gains that would absolute calibrate the phase of already redundantly-calibrated data. \n",
    "    Only operates one polarization at a time.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : DataContainer or RedDataContainer\n",
    "        Dictionary-like container mapping baselines to data visibilities to abscal\n",
    "    model : DataContainer or RedDataContainer\n",
    "        Dictionary-like container mapping baselines to model visibilities\n",
    "    reds : list of lists\n",
    "        List of lists of redundant baselines tuples like (0, 1, 'ee'). Ignored if transformed_antpos is not None.\n",
    "    data_bls : list of tuples\n",
    "        List of baseline tuples in data to use.\n",
    "    model_bls : list of tuples\n",
    "        List of baseline tuples in model to use. Must correspond the same physical separations as data_bls.\n",
    "    transformed_antpos : dict\n",
    "        Dictionary of abstracted antenna positions that you'd normally get from redcal.reds_to_antpos().\n",
    "        If None, will be inferred from reds.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    meta : dictionary\n",
    "        Contains keys for\n",
    "            'Lambda_sol' : phase gradient solutions,\n",
    "            'Z_sol' : value of the objective function at the solution,\n",
    "            'newton_iterations' : number of iterations completed by the Newton's method solver\n",
    "    delta_gains : dictionary\n",
    "        Dictionary mapping antenna keys like (0, 'Jee') to gains of the same shape of the data\n",
    "    \"\"\"\n",
    "    # Check that baselines selected are for the same polarization\n",
    "    pols = list(set([bl[2] for bls in (data_bls, model_bls) for bl in bls]))\n",
    "    assert len(pols) == 1, 'complex_phase_abscal() can only solve for one polarization at a time.'\n",
    "\n",
    "    # Get transformed antenna positions and baselines\n",
    "    if transformed_antpos is None:\n",
    "        transformed_antpos = redcal.reds_to_antpos(reds)\n",
    "    abscal._put_transformed_array_on_integer_grid(transformed_antpos)\n",
    "    transformed_b_vecs = np.rint([transformed_antpos[jj] - transformed_antpos[ii] for (ii, jj, pol) in data_bls]).astype(int)\n",
    "\n",
    "    # Get number of baselines and times/freqs\n",
    "    Ngroups = len(data_bls)\n",
    "    Ntimes, Nfreqs = data[data_bls[0]].shape\n",
    "\n",
    "    # Build up array of Fourier coefficients of the objective function\n",
    "    Z_coefficients = np.zeros((Ntimes, Nfreqs, Ngroups), dtype=complex)\n",
    "    for nn in range(Ngroups):\n",
    "\n",
    "        Vhat_n = data[data_bls[nn]]\n",
    "        Vbar_n = model[model_bls[nn]]\n",
    "        Z_coefficients[:, :, nn] = Vhat_n * np.conj(Vbar_n)\n",
    "\n",
    "    # Get solution for degenerate phase gradient vectors\n",
    "    Ntimes, Nfreqs, Ngroups = Z_coefficients.shape\n",
    "    Ndims = transformed_b_vecs.shape[1]\n",
    "\n",
    "    Lambda_sol = np.zeros((Ntimes, Nfreqs, Ndims), dtype=float)\n",
    "\n",
    "    for i_t in range(Ntimes):\n",
    "        for i_f in range(Nfreqs):\n",
    "            Z_coeffs_t_f = Z_coefficients[i_t, i_f]\n",
    "            Lambda_t_f, niter_t_f = abscal._newton_solve(np.zeros(Ndims), transformed_b_vecs, Z_coeffs_t_f, 1e-8, maxiter=newton_maxiter)\n",
    "            Lambda_sol[i_t, i_f] = -Lambda_t_f\n",
    "        \n",
    "    # turn solution into per-antenna gains\n",
    "    meta = {\n",
    "        'Lambda_sol': Lambda_sol, \n",
    "        'transformed_antpos': transformed_antpos\n",
    "    }\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c0847-0e24-48ae-a62b-adace2b549d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_CALIBRATION:\n",
    "    # Amplitude Calibration\n",
    "    if RUN_AMPLITUDE_CAL:\n",
    "        amplitude_solutions = abscal.abs_amp_lincal(\n",
    "            model=model,\n",
    "            data=data_for_cal,\n",
    "            wgts=wgts,\n",
    "            verbose=False,\n",
    "        )\n",
    "    else:\n",
    "        data_shape = data_for_cal[list(data_for_cal.keys())[0]].shape\n",
    "        amplitude_solutions['ee'] = np.ones(data_shape)\n",
    "        amplitude_solutions['nn'] = np.ones(data_shape)\n",
    "    \n",
    "    # Tip-tilt Phase Calibration\n",
    "    if RUN_TIP_TILT_PHASE_CAL:\n",
    "        # Get the redundancies\n",
    "        all_reds = red_groups.RedundantGroups.from_antpos(\n",
    "            antpos=hd.antpos, \n",
    "            pols=('nn', 'ee'), \n",
    "            include_autos=False\n",
    "        )\n",
    "    \n",
    "        # Fit the tip-tilt for both pols\n",
    "        phase_solutions = {}\n",
    "        for pol in ['ee', 'nn']:\n",
    "            phase_fit = complex_phase_abscal(\n",
    "                {k: data_for_cal[k][:] for k in data_for_cal if k[-1] == pol}, \n",
    "                {k: model[k][:] for k in model if k[-1] == pol}, \n",
    "                all_reds, \n",
    "                [k for k in data_for_cal if k[-1] == pol], \n",
    "                [k for k in model if k[-1] == pol], \n",
    "            )\n",
    "            phase_solutions[pol] = phase_fit['Lambda_sol']\n",
    "    \n",
    "        transformed_antpos = phase_fit['transformed_antpos']   \n",
    "    else:\n",
    "        data_shape = data_for_cal[list(data_for_cal.keys())[0]].shape\n",
    "        phase_solutions = {}\n",
    "        for pol in ['ee', 'nn']:\n",
    "            phase_fit = np.zeros(data_shape + (2,))\n",
    "            phase_solutions[pol] = phase_fit\n",
    "    \n",
    "        transformed_antpos = hd.antpos\n",
    "        \n",
    "    if RUN_CROSS_POL_PHASE_CAL:\n",
    "        cross_pol_phase = abscal.cross_pol_phase_cal(\n",
    "            model=cross_pol_model,\n",
    "            data=cross_pol_data,\n",
    "            model_bls=list(cross_pol_model.keys()),\n",
    "            data_bls=list(cross_pol_data.keys()),\n",
    "            wgts=wgts,\n",
    "        )\n",
    "    else:\n",
    "        data_shape = data_for_cal[list(data_for_cal.keys())[0]].shape\n",
    "        cross_pol_phase = np.zeros(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1edb474-6514-4b11-b033-e0a6a0bf15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    # Check blacklisting in amplitude calibration (harder to do in phase)\n",
    "    blacklist_wgts = {}\n",
    "    \n",
    "    avg_wgts = {\n",
    "        pol: np.mean([wgts[key] for key in wgts if pol in key], axis=0)\n",
    "        for pol in polarizations\n",
    "    }\n",
    "    \n",
    "    for pol in ['ee', 'nn']:\n",
    "        if RUN_AMPLITUDE_CAL:\n",
    "            gains = np.where(\n",
    "                np.isfinite(amplitude_solutions[f\"A_J{pol}\"]), \n",
    "                amplitude_solutions[f\"A_J{pol}\"], \n",
    "                1.0\n",
    "            )\n",
    "            wgts_here = np.where(np.isfinite(amplitude_solutions[f\"A_J{pol}\"]), avg_wgts[pol], 0.0)\n",
    "            wgts_here = np.where(where_inpainted[pol], WHERE_INPAINTED_WGTS, wgts_here)\n",
    "            smoothed_amp, _ = smooth_cal.time_freq_2D_filter(\n",
    "                gains=gains.astype(complex),\n",
    "                wgts=wgts_here,\n",
    "                freqs=freqs,\n",
    "                times=times,\n",
    "                freq_scale=FREQ_SMOOTHING_SCALE,\n",
    "                time_scale=TIME_SMOOTHING_SCALE * BLACKLIST_TIMESCALE_FACTOR,\n",
    "                eigenval_cutoff=EIGENVAL_CUTOFF,\n",
    "                method='DPSS', \n",
    "                fit_method='lu_solve', \n",
    "                fix_phase_flips=False, \n",
    "                flag_phase_flip_ints=False,\n",
    "                skip_flagged_edges=True, \n",
    "                freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6],\n",
    "            ) \n",
    "            blacklist_wgts[pol] = np.where(\n",
    "                (np.abs(gains - smoothed_amp) / np.abs(smoothed_amp)) > BLACKLIST_RELATIVE_ERROR_THRESH,\n",
    "                0.0,\n",
    "                1.0\n",
    "            )\n",
    "        else:\n",
    "            blacklist_wgts[pol] = np.ones_like(amplitude_solutions[f\"A_J{pol}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d2fa1-ef96-4cd7-8a04-23bdb7304d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    smoothed_tip_tilt = {}\n",
    "    smoothed_amplitude = {}\n",
    "    \n",
    "    for pol in ['ee', 'nn']:\n",
    "        if RUN_AMPLITUDE_CAL:\n",
    "            gains = np.where(\n",
    "                np.isfinite(amplitude_solutions[f\"A_J{pol}\"]), \n",
    "                amplitude_solutions[f\"A_J{pol}\"], \n",
    "                1.0\n",
    "            )\n",
    "            wgts_here = np.where(np.isfinite(amplitude_solutions[f\"A_J{pol}\"]), avg_wgts[pol], 0.0)\n",
    "            wgts_here = np.where(where_inpainted[pol], WHERE_INPAINTED_WGTS, wgts_here)\n",
    "            wgts_here *= blacklist_wgts[pol]\n",
    "            smoothed_amp, _ = smooth_cal.time_freq_2D_filter(\n",
    "                gains=gains.astype(complex),\n",
    "                wgts=wgts_here,\n",
    "                freqs=freqs,\n",
    "                times=times,\n",
    "                freq_scale=FREQ_SMOOTHING_SCALE,\n",
    "                time_scale=TIME_SMOOTHING_SCALE,\n",
    "                eigenval_cutoff=EIGENVAL_CUTOFF,\n",
    "                method='DPSS', \n",
    "                fit_method='lu_solve', \n",
    "                fix_phase_flips=False, \n",
    "                flag_phase_flip_ints=False,\n",
    "                skip_flagged_edges=True, \n",
    "                freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6],\n",
    "            ) \n",
    "            smoothed_amplitude[pol] = np.where(\n",
    "                all_flagged[pol], 1.0, smoothed_amp.real\n",
    "            )\n",
    "        else:\n",
    "            smoothed_amplitude[pol] = np.ones_like(amplitude_solutions[pol])\n",
    "            \n",
    "        if RUN_TIP_TILT_PHASE_CAL:\n",
    "            smoothed_solutions = []\n",
    "            for i in range(2):\n",
    "                tip_tilt = phase_solutions[pol][..., i].astype(complex)\n",
    "                gains = np.where(np.isfinite(tip_tilt), tip_tilt, 0.0)\n",
    "                wgts_here = np.where(np.isfinite(tip_tilt), avg_wgts[pol], 0.0)\n",
    "                wgts_here = np.where(where_inpainted[pol], WHERE_INPAINTED_WGTS, wgts_here)\n",
    "                wgts_here *= blacklist_wgts[pol]\n",
    "                \n",
    "                tip_tilt_smoothed, _ = smooth_cal.time_freq_2D_filter(\n",
    "                    gains=gains,\n",
    "                    wgts=wgts_here,\n",
    "                    freqs=freqs,\n",
    "                    times=times,\n",
    "                    freq_scale=FREQ_SMOOTHING_SCALE,\n",
    "                    time_scale=TIME_SMOOTHING_SCALE,\n",
    "                    eigenval_cutoff=EIGENVAL_CUTOFF,\n",
    "                    method='DPSS', \n",
    "                    fit_method='lu_solve', \n",
    "                    fix_phase_flips=False, \n",
    "                    flag_phase_flip_ints=False,\n",
    "                    skip_flagged_edges=True, \n",
    "                    freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6],\n",
    "                ) \n",
    "                smoothed_solutions.append(tip_tilt_smoothed.real)\n",
    "            \n",
    "            smoothed_tip_tilt[pol] = np.where(\n",
    "                all_flagged[pol][..., None], 0.0, np.transpose(smoothed_solutions, (1, 2, 0))\n",
    "            )\n",
    "        else:\n",
    "            smoothed_tip_tilt[pol] = np.zeros(wgts[(0, 1, pol)].shape + (2,))\n",
    "    \n",
    "    if RUN_CROSS_POL_PHASE_CAL:\n",
    "        gains = np.where(np.isfinite(cross_pol_phase), cross_pol_phase, 0.0)\n",
    "        wgts_here = np.where(np.isfinite(cross_pol_phase), avg_wgts['en'] + avg_wgts['ne'], 0.0)\n",
    "        wgts_here = np.where(where_inpainted[pol], WHERE_INPAINTED_WGTS, wgts_here)\n",
    "        wgts_here *= blacklist_wgts[pol]\n",
    "        \n",
    "        cross_pol_smoothed, _ = smooth_cal.time_freq_2D_filter(\n",
    "            gains=gains.astype(complex),\n",
    "            wgts=wgts_here,\n",
    "            freqs=freqs,\n",
    "            times=times,\n",
    "            freq_scale=FREQ_SMOOTHING_SCALE,\n",
    "            time_scale=TIME_SMOOTHING_SCALE,\n",
    "            eigenval_cutoff=EIGENVAL_CUTOFF,\n",
    "            method='DPSS', \n",
    "            fit_method='lu_solve', \n",
    "            fix_phase_flips=False, \n",
    "            flag_phase_flip_ints=False,\n",
    "            skip_flagged_edges=True, \n",
    "            freq_cuts=[(FM_LOW_FREQ + FM_HIGH_FREQ) * .5e6],\n",
    "        ) \n",
    "        cross_pol_smoothed = np.where(\n",
    "            all_flagged[\"nn\"] | all_flagged[\"ee\"],\n",
    "            0.0,\n",
    "            cross_pol_smoothed\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd4a02-42db-43ed-8126-3911c0b23744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amplitude_degeneracy():\n",
    "    ai, aj = list(map(int, baseline_strings[0].split(\"_\")))\n",
    "    lsts = utils.JD2LST(times) * 12 / np.pi\n",
    "    wrap_point = (lsts[0] + lsts[-1]) / 2\n",
    "    lsts[wrap_point < lsts] -= 24\n",
    "    extent = [freqs.min() / 1e6, freqs.max() / 1e6, lsts.max(), lsts.min()]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 10), sharex=True, sharey=True)\n",
    "    for pi, pol in enumerate(['ee', 'nn']):\n",
    "        axs[pi, 0].imshow(\n",
    "            np.where(\n",
    "                where_inpainted[pol] | (all_flagged[pol]), \n",
    "                np.nan, \n",
    "                np.abs(amplitude_solutions[f'A_J{pol}'])\n",
    "            ), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            vmin=0.95, \n",
    "            vmax=1.05, \n",
    "            extent=extent, \n",
    "            cmap='turbo'\n",
    "        )\n",
    "        im = axs[pi, 1].imshow(\n",
    "            np.where(all_flagged[pol], np.nan, np.abs(smoothed_amplitude[pol])),\n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            vmin=0.95, \n",
    "            vmax=1.05, \n",
    "            extent=extent, \n",
    "            cmap='turbo'\n",
    "        )\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    axs[1, 0].set_xlabel(\"Frequency (MHz)\", fontsize=12)\n",
    "    axs[1, 1].set_xlabel(\"Frequency (MHz)\", fontsize=12)\n",
    "    axs[0, 0].set_ylabel(\"ee\", fontsize=12)\n",
    "    axs[1, 0].set_ylabel(\"nn\", fontsize=12)\n",
    "    axs[0, 0].set_title(\"Raw Amplitude Degeneracy\", fontsize=14)\n",
    "    axs[0, 1].set_title(\"Smoothed Amplitude Degeneracy\", fontsize=14)\n",
    "    cbar = plt.colorbar(im, ax=axs, fraction=0.05, pad=0.01)\n",
    "    cbar.set_label(\"Gain Amplitude\", fontsize=14)\n",
    "    fig.text(-0.02, 0.5, 'LST (hr)', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "def plot_tip_tilt_degeneracy():\n",
    "    ai, aj = list(map(int, baseline_strings[0].split(\"_\")))\n",
    "    lsts = utils.JD2LST(times) * 12 / np.pi\n",
    "    wrap_point = (lsts[0] + lsts[-1]) / 2\n",
    "    lsts[wrap_point < lsts] -= 24\n",
    "    extent = [freqs.min() / 1e6, freqs.max() / 1e6, lsts.max(), lsts.min()]\n",
    "\n",
    "    antvec = np.array([hd.antpos[k][:2] for k in hd.antpos])\n",
    "    antvec -= antvec[0]\n",
    "    transformed_antvec = np.array([transformed_antpos[k][:2] for k in hd.antpos])\n",
    "    transformed_antvec -= transformed_antvec[0]\n",
    "    coord_scalar = np.diag(np.linalg.solve(transformed_antvec.T.dot(transformed_antvec), transformed_antvec.T.dot(antvec)))\n",
    "    \n",
    "    fig, axs = plt.subplots(4, 2, figsize=(15, 12), sharex=True, sharey=True)\n",
    "    ci = 0\n",
    "    for pi, pol in enumerate(['ee', 'nn']):\n",
    "        for ni in range(2):\n",
    "            axs[ci, 0].imshow(\n",
    "                np.where(\n",
    "                    where_inpainted[pol] | (all_flagged[pol]),\n",
    "                    np.nan,\n",
    "                    phase_solutions[pol][..., ni] * coord_scalar[ni],\n",
    "                ),\n",
    "                aspect='auto', \n",
    "                interpolation='None', \n",
    "                vmin=-0.05, \n",
    "                vmax=0.05, \n",
    "                extent=extent, \n",
    "                cmap='turbo'\n",
    "            )\n",
    "            tip_tilt = smoothed_tip_tilt[pol][..., ni] * coord_scalar[ni]\n",
    "            im = axs[ci, 1].imshow( \n",
    "                np.where(all_flagged[pol], np.nan, tip_tilt),\n",
    "                aspect='auto', \n",
    "                interpolation='None', \n",
    "                vmin=-0.05, \n",
    "                vmax=0.05, \n",
    "                extent=extent, \n",
    "                cmap='turbo'\n",
    "            )\n",
    "\n",
    "            # Labeling\n",
    "            axs[ci, 0].set_ylabel(f\"{pol} component-{ci%2}\")\n",
    "            \n",
    "            ci += 1\n",
    "        \n",
    "        axs[3, 0].set_xlabel(r\"Frequency (MHz)\", fontsize=12)\n",
    "        axs[3, 1].set_xlabel(r\"Frequency (MHz)\", fontsize=12)\n",
    "\n",
    "    axs[0, 0].set_title(\"Raw Tip-Tilt Degeneracy\", fontsize=14)\n",
    "    axs[0, 1].set_title(\"Smoothed Tip-Tilt Degeneracy\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cbar = plt.colorbar(im, ax=axs, fraction=0.04, pad=0.01)\n",
    "    cbar.set_label(\"Phase Gradient (rad/m)\", fontsize=14)\n",
    "    fig.text(-0.02, 0.5, 'LST (hr)', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "def plot_cross_polarized_phase_degeneracy():\n",
    "    ai, aj = list(map(int, baseline_strings[0].split(\"_\")))\n",
    "    lsts = utils.JD2LST(times) * 12 / np.pi\n",
    "    wrap_point = (lsts[0] + lsts[-1]) / 2\n",
    "    lsts[wrap_point < lsts] -= 24\n",
    "    extent = [freqs.min() / 1e6, freqs.max() / 1e6, lsts.max(), lsts.min()]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6), sharex=True, sharey=True)\n",
    "    pol = 'ne'\n",
    "    axs[0].imshow(\n",
    "        np.where(\n",
    "            where_inpainted[pol] | (all_flagged[pol]),\n",
    "            np.nan,\n",
    "            cross_pol_phase,\n",
    "        ),\n",
    "        aspect='auto', \n",
    "        interpolation='None', \n",
    "        vmin=-0.1, \n",
    "        vmax=0.1, \n",
    "        extent=extent, \n",
    "        cmap='coolwarm'\n",
    "    )\n",
    "    im = axs[1].imshow( \n",
    "        np.where(all_flagged[pol], np.nan, cross_pol_smoothed.real),\n",
    "        aspect='auto', \n",
    "        interpolation='None', \n",
    "        vmin=-0.1, \n",
    "        vmax=0.1, \n",
    "        extent=extent, \n",
    "        cmap='coolwarm'\n",
    "    )\n",
    "\n",
    "    # Labeling\n",
    "    axs[0].set_ylabel(r\"LST (hr)\")    \n",
    "    axs[0].set_xlabel(r\"Frequency (MHz)\")\n",
    "    axs[1].set_xlabel(r\"Frequency (MHz)\")\n",
    "    axs[0].set_title(\"Raw Relative Phase Degeneracy\")\n",
    "    axs[1].set_title(\"Smoothed Relative Phase Degeneracy\")\n",
    "    plt.tight_layout()\n",
    "    cbar = plt.colorbar(im, ax=axs, fraction=0.05, pad=0.01)\n",
    "    cbar.set_label(\"Jee/Jnn Relative Phase (rad)\", fontsize=14)\n",
    "\n",
    "def expand_degenerate_gains_single_baseline(key, all_calibration_parameters, transformed_antpos, use_cross_pol=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ant1pol, ant2pol = utils.split_bl(key)\n",
    "    blvec = transformed_antpos[ant2pol[0]] - transformed_antpos[ant1pol[0]]\n",
    "    gain = all_calibration_parameters[f\"A_{ant1pol[1]}\"].astype(complex) * all_calibration_parameters[f\"A_{ant1pol[1]}\"].astype(complex)\n",
    "    g1 = np.exp(\n",
    "        1j * np.einsum(\"tfc,c->tf\", all_calibration_parameters[f\"T_{ant2pol[1]}\"], transformed_antpos[ant2pol[0]])\n",
    "    )\n",
    "    g2 = np.exp(\n",
    "        1j * np.einsum(\"tfc,c->tf\", all_calibration_parameters[f\"T_{ant1pol[1]}\"], transformed_antpos[ant1pol[0]])\n",
    "    )\n",
    "    gain *= g1 * g2.conj()\n",
    "\n",
    "    if ant1pol[-1] != ant2pol[-1]: \n",
    "        if ant1pol[-1] == 'Jnn':\n",
    "            g1 = np.exp(1j * all_calibration_parameters['cross_pol'])\n",
    "            gain *= g1\n",
    "        elif ant2pol[-1] == 'Jnn':\n",
    "            g1 = np.exp(-1j * all_calibration_parameters['cross_pol'])\n",
    "            gain *= g1\n",
    "    \n",
    "    return gain\n",
    "\n",
    "def plot_excess_variance():\n",
    "    ai, aj = list(map(int, baseline_strings[0].split(\"_\")))\n",
    "    lsts = utils.JD2LST(times) * 12 / np.pi\n",
    "    wrap_point = (lsts[0] + lsts[-1]) / 2\n",
    "    lsts[wrap_point < lsts] -= 24\n",
    "    extent = [freqs.min() / 1e6, freqs.max() / 1e6, lsts.max(), lsts.min()]\n",
    "    \n",
    "    all_calibration_parameters = {\n",
    "        \"A_Jee\": smoothed_amplitude['ee'],\n",
    "        \"A_Jnn\": smoothed_amplitude['nn'],\n",
    "        \"T_Jee\": smoothed_tip_tilt['ee'],\n",
    "        \"T_Jnn\": smoothed_tip_tilt['nn'],\n",
    "        \"cross_pol\": cross_pol_smoothed,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(4, 2, figsize=(15, 10), sharey=True, sharex=True)\n",
    "    \n",
    "    for pi, pol in enumerate(['ee', 'nn']):\n",
    "        excess_var = 0\n",
    "        excess_var_cal = 0\n",
    "        count = 0\n",
    "        weights = 0\n",
    "        for key in data_for_cal:\n",
    "            if pol in key:\n",
    "                noise_var = np.abs(auto_model[(0, 0, pol)]) ** 2 / wgts[key] / 10 / 122e3\n",
    "                zsquare = np.abs(data_for_cal[key] - model[key]) ** 2 / noise_var\n",
    "                excess_var += zsquare * (wgts[key])# * (~where_inpainted[pol]).astype(float))\n",
    "                gain = expand_degenerate_gains_single_baseline(key, all_calibration_parameters, transformed_antpos, use_cross_pol=True)\n",
    "                data_cal = data_for_cal[key] / gain\n",
    "                zsquare = np.abs(data_cal - model[key]) ** 2 / noise_var\n",
    "                excess_var_cal += zsquare * (wgts[key])# * (~where_inpainted[pol]).astype(float))\n",
    "                weights += (wgts[key])# * (~where_inpainted[pol]).astype(float))\n",
    "    \n",
    "        im = axs[pi, 0].imshow(\n",
    "            np.real(np.abs(excess_var) / weights), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            cmap='turbo', \n",
    "            vmin=0.5, \n",
    "            vmax=10, \n",
    "            extent=extent\n",
    "        )\n",
    "        im = axs[pi, 1].imshow(\n",
    "            np.real(np.abs(excess_var_cal) / weights), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            cmap='turbo', \n",
    "            vmin=0.5, \n",
    "            vmax=10, \n",
    "            extent=extent\n",
    "        )\n",
    "    \n",
    "    for pi, pol in enumerate(['en', 'ne']):\n",
    "        excess_var = 0\n",
    "        excess_var_cal = 0\n",
    "        count = 0\n",
    "        weights = 0\n",
    "        for key in cross_pol_data:\n",
    "            if pol in key:\n",
    "                noise_var = np.abs(auto_model[(0, 0, \"ee\")] * auto_model[(0, 0, \"nn\")]) / wgts[key] / 10 / 122e3\n",
    "                zsquare = np.abs(cross_pol_data[key] - cross_pol_model[key]) ** 2 / noise_var\n",
    "                excess_var += zsquare * (wgts[key])# * (~where_inpainted[pol]).astype(float))\n",
    "                gain = expand_degenerate_gains_single_baseline(key, all_calibration_parameters, transformed_antpos, use_cross_pol=True)\n",
    "                data_cal = cross_pol_data[key] / gain\n",
    "                zsquare = np.abs(data_cal - cross_pol_model[key]) ** 2 / noise_var\n",
    "                excess_var_cal += zsquare * (wgts[key])# * (~where_inpainted[pol]).astype(float))\n",
    "                weights += (wgts[key])# * (~where_inpainted[pol]).astype(float))\n",
    "    \n",
    "        im = axs[pi + 2, 0].imshow(\n",
    "            np.real(np.abs(excess_var) / weights), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            cmap='turbo', \n",
    "            vmin=0.5, \n",
    "            vmax=10, \n",
    "            extent=extent\n",
    "        )\n",
    "        im = axs[pi + 2, 1].imshow(\n",
    "            np.real(np.abs(excess_var_cal) / weights), \n",
    "            aspect='auto', \n",
    "            interpolation='None', \n",
    "            cmap='turbo', \n",
    "            vmin=0.5, \n",
    "            vmax=10, \n",
    "            extent=extent\n",
    "        )\n",
    "    \n",
    "    # Labeling\n",
    "    for i, pol in enumerate(['ee', 'nn', 'en', 'ne']):\n",
    "        axs[i, 0].set_ylabel(pol)   \n",
    "    \n",
    "    axs[3, 0].set_xlabel(r\"Frequency (MHz)\", fontsize=12)\n",
    "    axs[3, 1].set_xlabel(r\"Frequency (MHz)\", fontsize=12)\n",
    "    axs[0, 0].set_title(\"Pre-LST Calibration\", fontsize=14)\n",
    "    axs[0, 1].set_title(\"Post-LST Calibration\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cbar = plt.colorbar(im, ax=axs)\n",
    "    cbar.set_label(r\"Excess Variance $[|V^{\\rm night} - V^{\\rm LST}|^2 / V^2_N]$\", fontsize=14)\n",
    "    fig.text(-0.02, 0.5, 'LST (hr)', va='center', rotation='vertical', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47890fd1-7116-4659-9ae9-5289255bd11d",
   "metadata": {},
   "source": [
    "# Figure 1: Amplitude Parameters Before/After Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36fd92-6ca5-432e-a16e-ab439c176cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the local times for plotting\n",
    "if RUN_AMPLITUDE_CAL and RUN_CALIBRATION:\n",
    "    plot_amplitude_degeneracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c5048-3b56-43f7-a006-892a2a605049",
   "metadata": {},
   "source": [
    "# Figure 2: Tip/Tilt Parameters Before/After Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca91fb-3dd3-42cf-b304-35c7c0aaa081",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TIP_TILT_PHASE_CAL and RUN_CALIBRATION:\n",
    "    plot_tip_tilt_degeneracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a170d-d5d0-441c-99ef-717bdb1e6e84",
   "metadata": {},
   "source": [
    "# Figure 3: Cross-Polarized Phase Before/After Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbcacc-8b51-4702-bc54-f6e037fa2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CROSS_POL_PHASE_CAL and RUN_CALIBRATION:\n",
    "    plot_cross_polarized_phase_degeneracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9d820-d1fb-4172-baaa-7ab70da92242",
   "metadata": {},
   "source": [
    "# Figure 4: Visibility/LST-Averaged Variance Across Baseline Before/After LST-Cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e40b0a-2e47-4152-a972-f56d9dee8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    plot_excess_variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbb7a5-e5b8-40f0-a2aa-da13bcf660e9",
   "metadata": {},
   "source": [
    "# 4. Save Smoothed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14aa6a3-9d93-41a1-8c8e-ba53336a4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    indices = np.searchsorted(single_jd_times, times)\n",
    "    \n",
    "    # Expand out tip/tilt to full data size\n",
    "    expanded_tip_tilt = {\n",
    "        pol: np.zeros((single_jd_times.size,) + smoothed_tip_tilt[pol].shape[1:])\n",
    "        for pol in smoothed_tip_tilt\n",
    "    }\n",
    "    expanded_amplitude = {\n",
    "        pol: np.ones((single_jd_times.size,) + smoothed_amplitude[pol].shape[1:])\n",
    "        for pol in smoothed_amplitude\n",
    "    }\n",
    "    for pol in expanded_tip_tilt:\n",
    "        expanded_tip_tilt[pol][indices] = smoothed_tip_tilt[pol]\n",
    "        expanded_amplitude[pol][indices] = np.where(\n",
    "            np.isclose(smoothed_amplitude[pol], 0.0),\n",
    "            1.0,\n",
    "            smoothed_amplitude[pol]\n",
    "        )\n",
    "    \n",
    "    # Expand out cross-polarized degeneracy to full data size\n",
    "    expanded_cross_pol = np.zeros((single_jd_times.size,) + cross_pol_smoothed.shape[1:])\n",
    "    expanded_cross_pol[indices] = cross_pol_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e5c6a-c0a2-4319-999d-06ba425bbe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CALIBRATION:\n",
    "    # Store calibration parameters\n",
    "    all_calibration_parameters = {\n",
    "        \"A_Jee\": expanded_amplitude['ee'],\n",
    "        \"A_Jnn\": expanded_amplitude['nn'],\n",
    "        \"T_Jee\": expanded_tip_tilt['ee'],\n",
    "        \"T_Jnn\": expanded_tip_tilt['nn'],\n",
    "        \"cross_pol\": expanded_cross_pol,\n",
    "    }\n",
    "    \n",
    "    # Get the calibration filename\n",
    "    cal_fname = os.path.join(OUTDIR, LSTCAL_FNAME_FORMAT.format(night=jd_here))\n",
    "\n",
    "    # Write LST-cal solutions to disk\n",
    "    lst_stack.calibration.write_single_baseline_lstcal_solutions(\n",
    "        filename=cal_fname, \n",
    "        all_calibration_parameters=all_calibration_parameters, \n",
    "        flags=all_flagged,\n",
    "        transformed_antpos=transformed_antpos, \n",
    "        antpos=hd.antpos,\n",
    "        times=single_jd_times, \n",
    "        freqs=freqs, \n",
    "        pols=polarizations\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907dd39-d51c-457b-a762-901827494410",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata', 'numpy']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ccbf4-cca3-4f3b-b355-2762fd90198c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

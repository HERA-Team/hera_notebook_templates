{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27126d16",
   "metadata": {},
   "source": [
    "# Goal: Calibrate a File as Fast as Possible\n",
    "The goal of this notebook is to demonstrate techniques for quickly getting as much diagnostic information about a file as possible. This involves running a full suite of calibration, using shortcuts where possible to converge quickly to absolute calibration.\n",
    "\n",
    "Current calibration shortcuts include:\n",
    "- using autocorrelations for first-pass relative gain calibration\n",
    "- using an empirically determined scaling applied to autocorrelations to approximate absolute gain calibration\n",
    "- using empirically determined RFI station headings to approximate absolute phase calibration\n",
    "- using DPSS filters to derive RFI flagging from autocorrelations\n",
    "\n",
    "Important speed-ups come from:\n",
    "- general I/O speed-ups from hera_cal.io.read_hera_hdf5 (~20x)\n",
    "- speed-ups to DPSS fitting from hera_filters (~100x)\n",
    "- speed-up of firstcal by using RFI channels and fewer channels (~10x)\n",
    "- obtaining sufficient firstcal accuracy to skip logcal (saves 15s)\n",
    "- capping Omnical iterations at 100 (~20x) relative to 10,000 used in current pipeline. Obtains equivalent $\\chi^2$.\n",
    "\n",
    "With plotting turned off, current notebook runs in ~60s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97317476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "PLOT = False\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "filenames = glob.glob('/lustre/aoc/projects/hera/aparsons/2459114/zen.2459114.6*.sum.uvh5')[100:101]\n",
    "#filenames = glob.glob('/lustre/aoc/projects/hera/erath/2459639/zen.2459639.45*.sum.uvh5')[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "986bf977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hera_cal\n",
    "from hera_cal.utils import split_bl, join_bl\n",
    "import uvtools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import hera_filters\n",
    "import linsolve\n",
    "from copy import deepcopy\n",
    "_ = np.seterr(all='ignore')  # get rid of red warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3a5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    '''Keep track of run-time through various stages and print nicely\n",
    "    formatted deltas.'''\n",
    "    order = []\n",
    "    def clock(self, name):\n",
    "        self.order.append((name, time.time()))\n",
    "    def __str__(self):\n",
    "        t_full = '%5.2f s' % (self.order[-1][-1] - self.order[0][-1])\n",
    "        s = f'{self.order[0][0]}->{self.order[-1][0]}: {t_full}'\n",
    "        if len(self.order) <= 2:\n",
    "            return s\n",
    "        t_last = '%5.2f s' % (self.order[-1][-1] - self.order[-2][-1])\n",
    "        return s + f', {self.order[-2][0]}->{self.order[-1][0]}: {t_last}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147361da",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Timer()\n",
    "timer.clock('start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb5888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: ['/lustre/aoc/projects/hera/aparsons/2459114/zen.2459114.65411.sum.uvh5']\n",
      "NANTS: 104\n",
      "NFREQS: 1536 (46920776.3671875, 234298706.0546875)\n",
      "NTIMES: 2 (2459114.654052777, 2459114.6541646253)\n",
      "LSTS: (1.367506215348899, 1.3682109019040458)\n",
      "NPOLS: 4 ['nn', 'ee', 'ne', 'en']\n"
     ]
    }
   ],
   "source": [
    "# Pick an input file and get header information\n",
    "print('FILE:', filenames)\n",
    "hc = hera_cal.io.HERADataFastReader(filenames)\n",
    "_ = hc.read(read_data=False, read_flags=False, read_nsamples=False)\n",
    "\n",
    "print('NANTS:', len(hc.data_ants))\n",
    "print('NFREQS:', len(hc.freqs), (hc.freqs[0], hc.freqs[-1]))\n",
    "print('NTIMES:', len(hc.times), (hc.times[0], hc.times[-1]))\n",
    "print('LSTS:', (hc.lsts[0], hc.lsts[-1]))\n",
    "print('NPOLS:', len(hc.pols), hc.pols)\n",
    "\n",
    "inttime = 24 * 3600 * np.median(np.diff(hc.times))  # XXX get directly\n",
    "chan_res = np.median(np.diff(hc.freqs))  # XXX get directly\n",
    "intcnt = int(inttime * chan_res)  # number of samples per integration in correlator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3baf03",
   "metadata": {},
   "source": [
    "# Check Autocorrelation Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a41dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read autocorrelations from the file, indexing by (antenna, pol) rather than baseline\n",
    "auto_pols = ['ee', 'nn']\n",
    "auto_bls = [(i, i, pol) for i in hc.data_ants for pol in hc.pols if pol in auto_pols]\n",
    "autos = hc.read(bls=auto_bls, read_data=True, read_flags=False, read_nsamples=False)[0]\n",
    "autos = {split_bl(k)[0]: v for k, v in autos.items()}  # index by ant, not bl\n",
    "antpos = {k: pos for k, pos in hc.antpos.items() if k in hc.data_ants}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbde861",
   "metadata": {},
   "source": [
    "## Sort antennas based on autocorrelation spectra\n",
    "\n",
    "Cuts are made on:\n",
    "- absolute power range, dividing out by correlator accumulation to get the 4b real/4b imag RMS levels. Should nominally be ~10 for well-trimmed RF inputs\n",
    "- spectral slope across band, computed by medians on either side of the center frequency. Deviations from flatness are signs of antennas not seeing sky emission\n",
    "- RFI occupancy. Positive outliers from a (-0.5, 1, 0.5) convolving kernel are flagged for being above the specified fraction of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa5b0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def within(val, bounds):\n",
    "    return bounds[0] <= val <= bounds[1]\n",
    "\n",
    "class Bounds:\n",
    "    '''Sort antennas into good/suspect/bad categories based on bounds.'''\n",
    "    \n",
    "    def __init__(self, absolute, good):\n",
    "        self.abs_bound = absolute\n",
    "        self.good_bound = good\n",
    "        self.bad = set()\n",
    "        self.suspect = set()\n",
    "        self.good = set()\n",
    "        \n",
    "    def classify(self, k, val):\n",
    "        '''Assign k to internal sets of good/suspect/bad based on value.'''\n",
    "        if not within(val, self.abs_bound):\n",
    "            self.bad.add(k)\n",
    "        elif not within(val, self.good_bound):\n",
    "            self.suspect.add(k)\n",
    "        else:\n",
    "            self.good.add(k)\n",
    "\n",
    "def _antenna_str(ants):\n",
    "    '''Turn a set of (ant, pol) keys into a string.'''\n",
    "    return ','.join(['%d%s' % (ant[0], ant[1][-1]) for ant in sorted(ants)])\n",
    "\n",
    "class AntennaClassification:\n",
    "    '''Injests Bounds to create sets of good/suspect/bad antennas.'''\n",
    "    \n",
    "    def __init__(self, *bounds_list):\n",
    "        self.clear()\n",
    "        for b in bounds_list:\n",
    "            self.add_bounds(b)\n",
    "            \n",
    "    def clear(self):\n",
    "        '''Clear good/suspect/bad sets.'''\n",
    "        self.bad = set()\n",
    "        self.suspect = set()\n",
    "        self.good = set()\n",
    "        \n",
    "    def add_bounds(self, bound):\n",
    "        '''Add antennas from Bounds to good/suspect/bad sets and remove\n",
    "        intersections from superior categories.'''\n",
    "        self.bad.update(bound.bad)\n",
    "        self.suspect.update(bound.suspect)\n",
    "        self.good.update(bound.good)\n",
    "        self.good.difference_update(self.bad)  # remove bad from good\n",
    "        self.good.difference_update(self.suspect)  # remove suspect from good\n",
    "        self.suspect.difference_update(self.bad)  # remove bad from suspect\n",
    "\n",
    "    def __str__(self):\n",
    "        s = []\n",
    "        s.append(f'Good: {_antenna_str(self.good)}')\n",
    "        s.append(f'Suspect: {_antenna_str(self.suspect)}')\n",
    "        s.append(f'Bad: {_antenna_str(self.bad)}')\n",
    "        return '\\n\\n'.join(s)\n",
    "    \n",
    "    def is_good(self, k):\n",
    "        return k in self.good\n",
    "    \n",
    "    def is_bad(self, k):\n",
    "        return k in self.bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4956b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good: 45n,73n,85n,88e,88n,98n,100e,100n,101e,102e,103e,104n,107n,108n,118n,124e,135e,136e,140e,142e,143e,144e,145e,156e,156n,157e,157n,163e,164e,164n,165e,165n,166n,178e,179e,179n,183e,184n,185n,187n\n",
      "\n",
      "Suspect: 0e,1e,1n,2e,11e,11n,13e,13n,14e,14n,24e,24n,25e,26e,26n,39e,39n,44e,44n,46e,46n,58e,58n,59n,73e,75e,82e,82n,83e,83n,85e,86e,87e,87n,89n,91e,91n,92e,92n,94e,94n,98e,99e,99n,102n,103n,104e,105e,105n,107e,108e,109e,109n,111e,111n,112n,117e,117n,118e,120e,120n,122n,124n,127e,127n,128e,128n,129e,129n,130e,130n,135n,136n,140n,141e,141n,143n,144n,158e,160e,160n,161e,162e,162n,163n,166e,176e,176n,177e,177n,178n,181e,181n,182n,183n,185e,186e,186n,187e\n",
      "\n",
      "Bad: 0n,2n,12e,12n,23e,23n,25n,36e,36n,37e,37n,38e,38n,45e,50e,50n,51e,51n,52e,52n,53e,53n,59e,65e,65n,66e,66n,67e,67n,68e,68n,75n,81e,81n,84e,84n,86n,89e,90e,90n,93e,93n,101n,110e,110n,112e,116e,116n,119e,119n,121e,121n,122e,123e,123n,137e,137n,138e,138n,142n,145n,155e,155n,158n,161n,180e,180n,182e,184e\n"
     ]
    }
   ],
   "source": [
    "# First-pass antenna classification based on auto levels\n",
    "\n",
    "CEN_FREQ = 136e6  # Hz\n",
    "RFI_THRESH = 1e-2  # fraction of mean\n",
    "\n",
    "pwr_bound = Bounds(absolute=(1, 50), good=(5, 20))\n",
    "slope_bound = Bounds(absolute=(-0.2, 0.2), good=(-0.12, 0.12))\n",
    "rfi_bound = Bounds(absolute=(0, 0.15), good=(0, 0.1))\n",
    "\n",
    "for k, v in autos.items():\n",
    "    mean = np.mean(v, axis=0) / intcnt\n",
    "    hi_pwr = np.median(mean[hc.freqs > CEN_FREQ])\n",
    "    lo_pwr = np.median(mean[hc.freqs <= CEN_FREQ])\n",
    "    pwr = 0.5 * (hi_pwr + lo_pwr)\n",
    "    slope = (hi_pwr - lo_pwr) / pwr\n",
    "    rfi = np.abs(mean[1:-1] - 0.5 * (mean[:-2] + mean[2:])) / mean[1:-1]\n",
    "    rfi_frac = np.mean(np.where(rfi > RFI_THRESH, 1, 0))\n",
    "    pwr_bound.classify(k, pwr)\n",
    "    slope_bound.classify(k, slope)\n",
    "    rfi_bound.classify(k, rfi_frac)\n",
    "\n",
    "ant_class = AntennaClassification(pwr_bound, slope_bound, rfi_bound)\n",
    "print(ant_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26e7db",
   "metadata": {},
   "source": [
    "# Determine RFI Flagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feae695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First-pass RFI flagging done with channel differencing\n",
    "\n",
    "SIG_THRESH = 20\n",
    "ARRAY_FLAG_THRESH = 0.05\n",
    "        \n",
    "rfi_wgts = {}\n",
    "\n",
    "for k, v in autos.items():\n",
    "    if not ant_class.is_good((k[0], 'Jee')) or not ant_class.is_good((k[0], 'Jnn')):\n",
    "        continue\n",
    "    sig = v / np.sqrt(intcnt / 2)  # factor of 2 for autos\n",
    "    w = np.ones(v.shape)\n",
    "\n",
    "    # A priori RFI flags\n",
    "    w[:, np.logical_and(222e6 < hc.freqs, hc.freqs < 224e6)] = 0\n",
    "\n",
    "    # First pass: difference with average on either side and flag positive outliers\n",
    "    for width in (1, 2, 4):\n",
    "        ker = np.ones(2 * width + 1)\n",
    "        wv = v * w\n",
    "        f_res = np.zeros_like(v)\n",
    "        for t in range(v.shape[0]):\n",
    "            d1 = np.convolve(wv[t], ker, mode='valid') - wv[t, width:-width]\n",
    "            w1 = np.convolve( w[t], ker, mode='valid') -  w[t, width:-width]\n",
    "            f_res[t, width:-width] = wv[t, width:-width] - d1 / w1.clip(1, np.Inf)\n",
    "            ker_std = np.sqrt(1**2 + 1 / (2 * width))\n",
    "            w[t, width:-width] = np.where(f_res[t, width:-width] > sig[t, width:-width] * ker_std * SIG_THRESH, 0, w[t, width:-width])\n",
    "\n",
    "    rfi_wgts[k] = w\n",
    "\n",
    "flags = sum([1 - v for k, v in rfi_wgts.items()]) / len(rfi_wgts)\n",
    "data_wgts = np.where(flags > ARRAY_FLAG_THRESH, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8924372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second-pass RFI flagging done with DPSS filters\n",
    "\n",
    "def dpss_filter(y, amat, fmat):\n",
    "    '''Apply the provided DPSS filter matrices to data.'''\n",
    "    model = np.array([amat @ (fmat[i] @ y[i]) for i in range(y.shape[0])])\n",
    "    return model.real\n",
    "\n",
    "SIG_THRESH = 4\n",
    "FILTER_WIDTH = 250e-9\n",
    "CENTERS = [0, 2700e-9, -2700e-9]\n",
    "\n",
    "filter_kwargs = {'filter_centers': CENTERS,\n",
    "                 'filter_half_widths': [FILTER_WIDTH] * len(CENTERS),\n",
    "                 'eigenval_cutoff': [1e-9] * len(CENTERS)} \n",
    "\n",
    "amat, _ = hera_filters.dspec.dpss_operator(hc.freqs, **filter_kwargs)\n",
    "fmat = np.array([hera_filters.dspec.fit_solution_matrix(np.diag(w), amat) for w in data_wgts])\n",
    "\n",
    "rfi_wgts = {}\n",
    "\n",
    "for k, v in autos.items():\n",
    "    if ant_class.is_bad(k):\n",
    "        continue\n",
    "    mdl = dpss_filter(v * data_wgts, amat, fmat)\n",
    "    sig = mdl / np.sqrt(intcnt / 2)\n",
    "    rfi_wgts[k] = np.where(v - mdl > sig * SIG_THRESH, 0, 1)\n",
    "\n",
    "flags = sum([1 - v for k, v in rfi_wgts.items()]) / len(rfi_wgts)\n",
    "\n",
    "# Array-wide RFI weights\n",
    "data_wgts = np.where(flags > ARRAY_FLAG_THRESH, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "098bbe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RFI flags versus frequency\n",
    "if PLOT:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(hc.freqs / 1e6, flags[0], 'c.')\n",
    "    plt.plot(hc.freqs / 1e6, flags[1], 'm.')\n",
    "    plt.fill_between(hc.freqs / 1e6, 1-data_wgts[0], color='c', alpha=0.5)\n",
    "    plt.fill_between(hc.freqs / 1e6, 1-data_wgts[1], color='m', alpha=0.5)\n",
    "\n",
    "    plt.plot(hc.freqs / 1e6, np.ones(hc.freqs.size) * ARRAY_FLAG_THRESH, 'k:')\n",
    "    plt.grid()\n",
    "    plt.ylabel('Antenna Fraction')\n",
    "    plt.title('RFI Flags')\n",
    "    _ = plt.xlabel('Frequency [MHz]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557377fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good: 45n,73n,85n,88n,98n,100e,101e,103e,104n,118n,135e,136e,140e,142e,143e,144e,145e,156e,156n,157e,157n,163e,164e,164n,165e,165n,166n,178e,179e,179n,183e,184n,185n,187n\n",
      "\n",
      "Suspect: 0e,2e,11e,11n,13n,14n,24e,24n,25e,39e,39n,44e,44n,46e,46n,58e,59n,75e,82e,82n,83e,83n,85e,86e,87e,87n,88e,89n,91e,91n,92e,92n,94e,94n,98e,99e,99n,100n,102e,102n,103n,104e,105e,105n,107e,107n,108e,108n,109e,109n,111e,111n,112n,117e,117n,118e,120e,120n,122n,124e,124n,127e,127n,128e,128n,129e,129n,130e,130n,135n,136n,140n,141e,141n,143n,144n,158e,160e,160n,161e,162e,162n,163n,166e,176e,176n,177e,177n,178n,181e,181n,182n,183n,185e,186e,186n,187e\n",
      "\n",
      "Bad: 0n,1e,1n,2n,12e,12n,13e,14e,23e,23n,25n,26e,26n,36e,36n,37e,37n,38e,38n,45e,50e,50n,51e,51n,52e,52n,53e,53n,58n,59e,65e,65n,66e,66n,67e,67n,68e,68n,73e,75n,81e,81n,84e,84n,86n,89e,90e,90n,93e,93n,101n,110e,110n,112e,116e,116n,119e,119n,121e,121n,122e,123e,123n,137e,137n,138e,138n,142n,145n,155e,155n,158n,161n,180e,180n,182e,184e\n"
     ]
    }
   ],
   "source": [
    "# Second-pass antenna classification based on RFI\n",
    "\n",
    "RFI2_SIG_THRESH = 3  # sigma threshold for flagging RFI\n",
    "rfi2_bound = Bounds(absolute=(-np.Inf, 5), good=(-np.Inf, 1))\n",
    "\n",
    "amat, _ = hera_filters.dspec.dpss_operator(hc.freqs, **filter_kwargs)\n",
    "fmat = np.array([hera_filters.dspec.fit_solution_matrix(np.diag(w), amat) for w in data_wgts])\n",
    "\n",
    "smooth_mdl = {}\n",
    "rfi_wgts = {}\n",
    "\n",
    "for k, v in autos.items():\n",
    "    if ant_class.is_bad(k):\n",
    "        continue\n",
    "    smooth_mdl[k] = dpss_filter(v * data_wgts, amat, fmat)\n",
    "    sig = smooth_mdl[k] / np.sqrt(intcnt / 2)\n",
    "    rfi_wgts[k] = np.where(v - smooth_mdl[k] > sig * RFI2_SIG_THRESH, 0, 1)\n",
    "\n",
    "flag_frac = {k: np.sum((1 - v) * data_wgts) for k, v in rfi_wgts.items()}\n",
    "ff = np.array(list(flag_frac.values()))\n",
    "ff_median = np.median(ff)\n",
    "ff_std = np.median(np.abs(ff - ff_median)) / 0.675\n",
    "    \n",
    "for k, v in autos.items():\n",
    "    if ant_class.is_bad(k):\n",
    "        rfi2_bound.bad.add(k)\n",
    "    else:\n",
    "        zscore = (flag_frac[k] - ff_median) / ff_std\n",
    "        rfi2_bound.classify(k, zscore)\n",
    "\n",
    "ant_class = AntennaClassification(pwr_bound, slope_bound, rfi_bound, rfi2_bound)\n",
    "print(ant_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "639c248b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot RMS residuals of good high-passed autos versus frequency\n",
    "if PLOT:\n",
    "    plot_pols = ['Jee', 'Jnn']\n",
    "    fig, axes = plt.subplots(figsize=(8,6), ncols=1, nrows=len(plot_pols), sharex=True)\n",
    "\n",
    "    for k, v in autos.items():\n",
    "        if ant_class.is_bad(k):\n",
    "            continue\n",
    "        ax = axes[plot_pols.index(k[-1])]\n",
    "        mdl = smooth_mdl[k][0]\n",
    "        sig = mdl / np.sqrt(intcnt / 2)\n",
    "        residual = (v[0] - mdl) / sig\n",
    "        mask = np.where(data_wgts[0])\n",
    "        ax.plot(hc.freqs[mask] / 1e6, residual[mask], 'k', label=str(k[0]), alpha=0.1)\n",
    "\n",
    "    for cnt, pol in enumerate(plot_pols):\n",
    "        ax = axes[plot_pols.index(pol)]\n",
    "        ax.set_title(f'Good Antennas, Polarization: {pol}')\n",
    "        ax.set_ylabel('Z Score')\n",
    "        ax.set_ylim(-5, 5)\n",
    "    _ = axes[-1].set_xlabel('Frequency [MHz]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924c5b37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot antenna positions with good and bad antennas highlighted\n",
    "if PLOT:\n",
    "    fig, axes = plt.subplots(figsize=(7,14), ncols=1, nrows=2)\n",
    "    for cnt, pol in enumerate(('Jee', 'Jnn')):\n",
    "        plt.sca(axes[cnt])\n",
    "        ex_ants = [k[0] for k in ant_class.bad if k[-1] == pol]\n",
    "        hl_ants = [k[0] for k in ant_class.good if k[-1] == pol]\n",
    "        uvtools.plot.plot_antpos(antpos, ex_ants=ex_ants, hl_ants=hl_ants)\n",
    "        plt.title(f'Polarization: {pol}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dba38d8",
   "metadata": {},
   "source": [
    "# Estimate Absolute Amplitude from Autocorrelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e39d302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First estimate of antenna gains from autos\n",
    "\n",
    "# polynomial fit to x=log10(freq) y=log10(abscal_gain / auto) for H4C\n",
    "abscal_loglog_poly = np.array([159.60511509346617, -6411.680706063783, 102993.61331972879, -826937.7537351248, 3318643.7541476665, -5325564.542530925])\n",
    "auto_scalar = 10**np.polyval(abscal_loglog_poly, np.log10(hc.freqs))\n",
    "inpainted_autos = {k: data_wgts * v + (1 - data_wgts) * smooth_mdl[k] for k, v in smooth_mdl.items()}\n",
    "noise_mdl = {k: v / np.sqrt(intcnt / 2) for k, v in smooth_mdl.items()}\n",
    "#mean_pwr = np.mean([v for k, v in inpainted_autos.items() if k in good_ants], axis=0)\n",
    "#auto_gains = {k: np.sqrt(auto_scalar * v / mean_pwr) for k, v in inpainted_autos.items()}\n",
    "auto_gains = {k: np.sqrt(auto_scalar * v) for k, v in inpainted_autos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6589ce7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot shape of in-painted autos versus frequency\n",
    "if PLOT:\n",
    "    plot_pols = ['Jee', 'Jnn']\n",
    "    fig, axes = plt.subplots(figsize=(8,6), ncols=1, nrows=len(plot_pols), sharex=True)\n",
    "\n",
    "    for k, v in inpainted_autos.items():\n",
    "        if ant_class.is_good(k):\n",
    "            continue\n",
    "        ax = axes[plot_pols.index(k[-1])]\n",
    "        ax.plot(hc.freqs / 1e6, np.mean(v, axis=0) / np.mean(v), label=str(k[0]))\n",
    "\n",
    "    for cnt, pol in enumerate(plot_pols):\n",
    "        ax = axes[plot_pols.index(pol)]\n",
    "        ax.set_title(f'Polarization: {pol}')\n",
    "        ax.set_ylabel('Calibrated Power')\n",
    "        ax.grid()\n",
    "    _ = axes[-1].set_xlabel('Frequency [MHz]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae2af2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start->auto_flags:  9.10\n"
     ]
    }
   ],
   "source": [
    "timer.clock('auto_flags')\n",
    "print(timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460f005b",
   "metadata": {},
   "source": [
    "# Firstcal Delays from Stable RFI Transmitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dee43530",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hc.read(read_data=True, read_flags=False, read_nsamples=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257b6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of FM Radio Headings, ch: (fq, ang, chisq)\n",
    "phs_sol = {\n",
    "     #359: ( 90744018.5546875, 0.785398, 23.39),\n",
    "     360: ( 90866088.8671875, 0.785398, 10.85),\n",
    "     369: ( 91964721.6796875, 0.106814, 34.81),\n",
    "     386: ( 94039916.9921875, 0.785398, 18.12),\n",
    "     #391: ( 94650268.5546875, 3.581415, 47.47),\n",
    "     392: ( 94772338.8671875, 3.587698, 40.78),\n",
    "     #399: ( 95626831.0546875, 6.063273, 36.57),\n",
    "     400: ( 95748901.3671875, 6.063273, 24.07),\n",
    "     441: (100753784.1796875, 0.785398, 21.72),\n",
    "     447: (101486206.0546875, 3.587698, 43.82),\n",
    "     #455: (102462768.5546875, 6.063273, 18.87),\n",
    "     456: (102584838.8671875, 6.063273, 8.811),\n",
    "     471: (104415893.5546875, 0.785398, 13.39),\n",
    "     477: (105148315.4296875, 3.587698, 19.82),\n",
    "     485: (106124877.9296875, 6.063273, 4.041),\n",
    "    1182: (191207885.7421875, 0.785398, 27.06),\n",
    "#    1444: (223190307.6171875, 1.426283, 54.68),\n",
    "#    1445: (223312377.9296875, 2.607521, 52.55),\n",
    "#    1494: (229293823.2421875, 5.560618, 51.34),\n",
    "}\n",
    "\n",
    "chs = np.array(sorted(list(phs_sol.keys())))\n",
    "ch_wgts = np.where(hc.freqs[chs] > 150e6, 10, 1)  # upwgt high-band station to offset FM overrepresentation\n",
    "sum_ch_wgts = np.sum(ch_wgts)\n",
    "lams = 3e8 / hc.freqs[chs]\n",
    "_angs = np.array([phs_sol[ch][1] for ch in chs])\n",
    "fm_headings = np.array([np.cos(_angs), np.sin(_angs), np.zeros_like(_angs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c2716bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build redundancy lists from antenna position and filter out bad antennas\n",
    "reds = hera_cal.redcal.get_reds(antpos, pols=['ee','nn'], pol_mode='2pol')\n",
    "freds = hera_cal.redcal.filter_reds(reds, ex_ants=ant_class.bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba643fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good: 45n,73n,88n,98n,100e,101e,103e,104n,118n,135e,136e,140e,142e,143e,144e,145e,156e,157e,163e,164e,165e,178e,179e,183e,184n,185n,187n\n",
      "\n",
      "Suspect: 0e,2e,11e,11n,13n,14n,24e,24n,25e,39e,39n,44e,44n,46e,46n,58e,59n,75e,82e,82n,83e,83n,85e,85n,86e,88e,89n,91e,91n,92e,92n,94e,94n,98e,99e,99n,100n,102e,102n,103n,104e,105e,105n,107e,107n,108e,108n,109e,109n,111e,111n,112n,117e,117n,118e,120e,120n,122n,124e,124n,127e,127n,128e,128n,129e,129n,130e,130n,135n,136n,140n,141e,141n,143n,144n,156n,157n,158e,161e,162e,162n,163n,164n,165n,166e,166n,176e,176n,177e,177n,178n,179n,181e,181n,182n,183n,185e,186e,186n,187e\n",
      "\n",
      "Bad: 0n,1e,1n,2n,12e,12n,13e,14e,23e,23n,25n,26e,26n,36e,36n,37e,37n,38e,38n,45e,50e,50n,51e,51n,52e,52n,53e,53n,58n,59e,65e,65n,66e,66n,67e,67n,68e,68n,73e,75n,81e,81n,84e,84n,86n,87e,87n,89e,90e,90n,93e,93n,101n,110e,110n,112e,116e,116n,119e,119n,121e,121n,122e,123e,123n,137e,137n,138e,138n,142n,145n,155e,155n,158n,160e,160n,161n,180e,180n,182e,184e\n"
     ]
    }
   ],
   "source": [
    "# Attempt to geometrically phase baselines to RFI channels, and toss out\n",
    "# baselines that don't phase (a sign of broken cross-correlation)\n",
    "\n",
    "_phs_bl_bound = Bounds(absolute=(-np.Inf, 0.3), good=(-np.Inf, 0.1))\n",
    "phs_bound = Bounds(absolute=(-np.Inf, 0.5), good=(-np.Inf, 0.1))\n",
    "                       \n",
    "# Because freq sampling is sparse, a brute-force search for best delay is\n",
    "# both faster and more robust\n",
    "MAX_DLY = 250  # maximum delay to try, in ns\n",
    "dlys_try = np.linspace(-MAX_DLY, MAX_DLY, 4 * MAX_DLY + 1) * 1e-9\n",
    "dlys_try.shape = (-1, 1)\n",
    "fqs = hc.freqs[chs]\n",
    "fqs.shape = (1, -1)\n",
    "phasor = np.exp(-2j * np.pi * fqs * dlys_try)  # brute force RFI phasors by delay\n",
    "\n",
    "ant_cnt = {}  # counts how many times an antenna appears in baselines\n",
    "bl_dly = {}  # stores best-fit delay for each baseline\n",
    "# some antennas phase best with a 180-deg rotated phasor, a sign of swapped dipoles on the feed\n",
    "ant_swapped = {}  # stores ants if best-fit phasor for a baseline was 180-deg rotated\n",
    "\n",
    "for grp in freds:\n",
    "    bl = grp[0]\n",
    "    # generate predicted geometric phases for each RFI station\n",
    "    bl_xyz = antpos[bl[1]] - antpos[bl[0]]\n",
    "    phs = np.exp(-2j * np.pi * np.dot(bl_xyz, fm_headings) / lams)\n",
    "\n",
    "    for bl in grp:\n",
    "        a_i, a_j = split_bl(bl)\n",
    "        d_phs = np.sum(data[bl][:,chs] * phs, axis=0)\n",
    "        ant_cnt[a_i] = ant_cnt.get(a_i, 0) + 1\n",
    "        ant_cnt[a_j] = ant_cnt.get(a_j, 0) + 1\n",
    "        d_phs /= np.abs(d_phs).clip(1, np.Inf)\n",
    "        _chi = np.sum(ch_wgts * np.abs(d_phs * phasor - 1)**2, axis=1) / sum_ch_wgts\n",
    "        _chi180 = np.sum(ch_wgts * np.abs(d_phs * phasor + 1)**2, axis=1) / sum_ch_wgts # 180-deg phase offset\n",
    "        # if swapped 180-deg phasor is best fit, add \n",
    "        if _chi180.min() < _chi.min():\n",
    "            ant_swapped[a_i] = ant_swapped.get(a_i, 0) + 1\n",
    "            ant_swapped[a_j] = ant_swapped.get(a_j, 0) + 1\n",
    "            _chi = _chi180\n",
    "        i = np.argmin(_chi)\n",
    "        _phs_bl_bound.classify(bl, _chi[i])\n",
    "        #print(bl, chisq[i], dlys[i, 0] / 1e-9, mx)\n",
    "        bl_dly[bl] = dlys_try[i, 0]\n",
    "\n",
    "# Calculate fraction with bad chisq on phasing      \n",
    "bad_cnt = {}\n",
    "for bl in _phs_bl_bound.bad:\n",
    "    for ant in split_bl(bl):\n",
    "        bad_cnt[ant] = bad_cnt.get(ant, 0) + 1\n",
    "\n",
    "# Classify antennas based on fraction of baselines that have bad phasing\n",
    "for ant, cnt in bad_cnt.items():\n",
    "    bad_frac = cnt / ant_cnt[ant]\n",
    "    phs_bound.classify(ant, bad_frac)\n",
    "\n",
    "ant_class = AntennaClassification(pwr_bound, slope_bound, rfi_bound, rfi2_bound, phs_bound)\n",
    "print(ant_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a259c0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed: 11e,11n,25e,45n,58e,85e,88n,89n,100n,101e,102e,102n,104e,143e,143n,178n\n"
     ]
    }
   ],
   "source": [
    "# Identify antennas that have 180-deg dipole rotations; they will be corrected\n",
    "_swap_bound = Bounds(absolute=(-np.Inf, 0.5), good=(-np.Inf, 0.5))\n",
    "\n",
    "# Calculate fraction with swapped dipoles\n",
    "for ant, cnt in ant_swapped.items():\n",
    "    bad_frac = cnt / ant_cnt[ant]\n",
    "    _swap_bound.classify(ant, bad_frac)\n",
    "\n",
    "swap_ants = _swap_bound.bad\n",
    "swap_ants.difference_update(ant_class.bad)\n",
    "print(f'Reversed: {_antenna_str(swap_ants)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72d1be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 2min 35s\n",
    "# freds = hera_cal.redcal.filter_reds(reds, ex_ants=bad_ants)\n",
    "# info = hera_cal.redcal.RedundantCalibrator(freds)\n",
    "# meta0, sol0 = info.firstcal(data, hc.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "345340d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solve firstcal delays for non-bad antennas\n",
    "\n",
    "freds = hera_cal.redcal.filter_reds(reds, ex_ants=ant_class.bad)\n",
    "\n",
    "# Encode equations for non-bad antennas\n",
    "eqs1 = {}\n",
    "for bl, dly in bl_dly.items():\n",
    "    a_i, a_j = split_bl(bl)\n",
    "    if ant_class.is_bad(a_i) or ant_class.is_bad(a_j):\n",
    "        continue\n",
    "    eqs1['dly_%d_%s - dly_%d_%s' % (a_i + a_j)] = dly\n",
    "\n",
    "ls = linsolve.LinearSolver(eqs1)\n",
    "_sol1 = ls.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81f6bcc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fine-tune FM delays after first round of per-ant solutions\n",
    "\n",
    "freqs = hc.freqs.copy()\n",
    "freqs.shape = (1, -1)\n",
    "dlys = {ai: _sol1['dly_%d_%s' % ai] for ai in ant_cnt.keys() if not ant_class.is_bad(ai)}\n",
    "gains = {ai: np.exp(2j * np.pi * freqs * dly) for ai, dly in dlys.items()}\n",
    "for ai in swap_ants:\n",
    "    gains[ai] *= -1\n",
    "\n",
    "# fine-tuning loop. multiple passes appear unnecessary\n",
    "for max_dly in (15,):\n",
    "    dlys_try = np.linspace(-max_dly, max_dly, 20 * max_dly + 1) * 1e-9\n",
    "    dlys_try.shape = (-1, 1)\n",
    "    fqs = hc.freqs[chs]\n",
    "    fqs.shape = (1, -1)\n",
    "    phasor = np.exp(-2j * np.pi * fqs * dlys_try)  # brute force RFI phasors by delay\n",
    "    \n",
    "    _eqs = {}\n",
    "    for grp in freds:\n",
    "        bl = grp[0]\n",
    "        # generate predicted geometric phases for each RFI station\n",
    "        bl_xyz = antpos[bl[1]] - antpos[bl[0]]\n",
    "        phs = np.exp(-2j * np.pi * np.dot(bl_xyz, fm_headings) / lams)\n",
    "\n",
    "        for bl in grp:\n",
    "            a_i, a_j = split_bl(bl)\n",
    "            g_ij = gains[a_i][:,chs] * gains[a_j][:,chs].conj()\n",
    "            d_phs = np.sum(data[bl][:,chs] * phs / g_ij, axis=0)\n",
    "            d_phs /= np.abs(d_phs).clip(1, np.Inf)\n",
    "            # gain inversion above for swapped antennas means no need to check 180-deg swap here\n",
    "            _chi = np.mean(np.abs(d_phs * phasor - 1)**2, axis=1)\n",
    "            i = np.argmin(_chi)\n",
    "            _eqs['dly_%d_%s - dly_%d_%s' % (a_i + a_j)] = dlys_try[i, 0]\n",
    "\n",
    "    ls = linsolve.LinearSolver(_eqs)\n",
    "    _sol2 = ls.solve()\n",
    "    dlys = {ai: dly + _sol2['dly_%d_%s' % ai] for ai, dly in dlys.items()}\n",
    "    gains = {ai: np.exp(2j * np.pi * freqs * dly) for ai, dly in dlys.items()}\n",
    "    for ai in swap_ants:\n",
    "        gains[ai] *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91fb7c",
   "metadata": {},
   "source": [
    "# Finalize Firstcal Delays from Sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ec5633b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Final polish on delays using full-band (non-RFI) data\n",
    "\n",
    "CH_STEP = 200  # every nth channel to include in fit\n",
    "_chs = np.arange(0, hc.freqs.size, CH_STEP)\n",
    "fqs = hc.freqs[_chs]\n",
    "fqs.shape = (1, -1)\n",
    "\n",
    "# fine-tuning loop. multiple passes appear unnecessary\n",
    "for dly_rng in (15,):\n",
    "    dlys_try = np.linspace(-dly_rng, dly_rng, 20 * dly_rng + 1) * 1e-9\n",
    "    dlys_try.shape = (-1, 1)\n",
    "\n",
    "    phasor = np.exp(-2j * np.pi * fqs * dlys_try)  # brute force phasors by delay\n",
    "\n",
    "    _eqs = {}\n",
    "    for grp in freds:\n",
    "        _chisq = np.Inf\n",
    "        # pick a representative baseline for a redundant group based on flatness of phase\n",
    "        # XXX ARP: why is this the right metric?\n",
    "        for bl in grp:\n",
    "            a_i, a_j = split_bl(bl)\n",
    "            g_ij = gains[a_i][:,_chs] * gains[a_j][:,_chs].conj()\n",
    "            d_phs = np.sum(data[bl][:,_chs] / g_ij, axis=0)\n",
    "            d_phs /= np.abs(d_phs).clip(1, np.Inf)\n",
    "            _chi = np.mean(np.abs(d_phs - 1)**2)\n",
    "            if _chi < _chisq:\n",
    "                min_bl = bl\n",
    "                phs = d_phs.conj()\n",
    "                _chisq = _chi\n",
    "        # compute phase relative to representative baseline and encode 4-point phase equation\n",
    "        ma_i, ma_j = split_bl(min_bl)\n",
    "        for bl in grp:\n",
    "            a_i, a_j = split_bl(bl)\n",
    "            g_ij = gains[a_i][:,_chs] * gains[a_j][:,_chs].conj()\n",
    "            d_phs = np.sum(data[bl][:,_chs] * phs / g_ij, axis=0)\n",
    "            d_phs /= np.abs(d_phs).clip(1, np.Inf)\n",
    "            chisq = np.mean(np.abs(d_phs * phasor - 1)**2, axis=1)\n",
    "            i = np.argmin(chisq)\n",
    "            _eqs['dly_%d_%s - dly_%d_%s - dly_%d_%s + dly_%d_%s' % (a_i + a_j + ma_i + ma_j)] = dlys_try[i, 0]\n",
    "\n",
    "    ls = linsolve.LinearSolver(_eqs)\n",
    "    _sol = ls.solve()\n",
    "    dlys = {ai: dly + _sol['dly_%d_%s' % ai] for ai, dly in dlys.items()}\n",
    "    # add auto_gains as first estimate of gain amplitudes\n",
    "    sol0 = {ai: auto_gains[ai] * np.exp(2j * np.pi * freqs * dly) for ai, dly in dlys.items()}\n",
    "    for ai in swap_ants:\n",
    "        sol0[ai] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1d952f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given final firstcal gain solutions, compute unique baseline solutions\n",
    "\n",
    "all_bls = set(hera_cal.utils.join_bl(ai, aj) for ai in sol0.keys() for aj in sol0.keys())\n",
    "info = hera_cal.redcal.RedundantCalibrator(freds)\n",
    "sol0.update(info.compute_ubls(data, sol0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f786f16a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot firstcal calibrated visibilities for a redundant group\n",
    "\n",
    "def plot_red_gp(data, sol, gp, t=0, title=None):\n",
    "    '''Plot all calibrated visibility data in a redundant group given redcal solutions.'''\n",
    "    fig, axes = plt.subplots(figsize=(8,6), ncols=1, nrows=2, sharex=True)\n",
    "    ubl = [bl for bl in gp if bl in sol][0]  # find how this group is indexed in solutions\n",
    "    mask = np.where(data_wgts[t])\n",
    "    u = sol[ubl][t]\n",
    "    for cnt, bl in enumerate(gp):\n",
    "        a_i, a_j = split_bl(bl)\n",
    "        g_ij = sol[a_i][t] * sol[a_j][t].conj()\n",
    "        _dat = data[bl][t]\n",
    "        axes[0].plot(hc.freqs / 1e6, np.angle(_dat / g_ij), label=str(bl))\n",
    "        axes[1].semilogy(hc.freqs[mask] / 1e6, np.abs(_dat / g_ij)[mask], label=str(bl))\n",
    "    axes[0].plot(hc.freqs / 1e6, np.angle(u), 'k', linewidth=3, label=str(ubl))\n",
    "    axes[1].semilogy(hc.freqs[mask] / 1e6, np.abs(u)[mask], 'k', linewidth=3, label=str(ubl))\n",
    "    if title is None:\n",
    "        title = str(ubl)\n",
    "    axes[0].set_title(title)\n",
    "    axes[0].set_ylabel('Phase')\n",
    "    axes[1].set_ylabel('Amplitude')\n",
    "    axes[1].set_xlabel('Frequency [MHz]')\n",
    "    axes[1].grid()\n",
    "\n",
    "if PLOT:\n",
    "    plot_red_gp(data, sol0, freds[0], title='Firstcal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7f323d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start->firstcal: 22.02, auto_flags->firstcal: 12.91\n"
     ]
    }
   ],
   "source": [
    "timer.clock('firstcal')\n",
    "print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c903103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping logcal as an unnecessary step\n",
    "# %%time\n",
    "# roughly 15s\n",
    "# meta1, sol1 = info.logcal(data, {k: v for k, v in sol0.items() if len(k) == 2})\n",
    "# sol1 = info.remove_degen(sol1, degen_sol=sol0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6130a",
   "metadata": {},
   "source": [
    "# Omnical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1eba5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish inverse variance weighting estimated from smoothed autocorrelations\n",
    "\n",
    "wgts = {}\n",
    "for bl in all_bls:\n",
    "    a_i, a_j = split_bl(bl)\n",
    "    noise = np.sqrt(noise_mdl[a_i] * noise_mdl[a_j])\n",
    "    wgts[bl] = 1 / (noise / np.sqrt(2))**2 # crosses have 1/2 variance of autos\n",
    "wgts = hera_cal.io.DataContainer(wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d386894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.1 s, sys: 3.22 s, total: 45.4 s\n",
      "Wall time: 45.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run Omnical\n",
    "\n",
    "#def wgt_func(abs2):\n",
    "#    return np.where(abs2 > 0, 5 * np.tanh(abs2 / 5) / abs2, 1)\n",
    "#meta2, sol2 = info.omnical(use_data, deepcopy(sol1), wgts=use_wgts, conv_crit=1e-10, gain=.4, maxiter=10000,\n",
    "#                         check_after=500, check_every=100) # standard pipeline, takes 15.5 min\n",
    "# wgt func reduces sensitivity to outliers; unclear what impact is for preflagged antennas\n",
    "#meta2, sol2 = info.omnical(use_data, deepcopy(sol1), wgts=use_wgts, conv_crit=1e-5, gain=.4, maxiter=100,\n",
    "#                         check_after=50, check_every=10, wgt_func=wgt_func)\n",
    "meta2, sol2 = info.omnical(data, deepcopy(sol0), wgts=wgts, conv_crit=1e-5, gain=.4, maxiter=100,\n",
    "                         check_after=100, check_every=10) # hardcoded to run 100 iterations w/o checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79506f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace degeneracies in omnical solutions with firstcal degeneracies, which\n",
    "# inherited a nominal absolute calibration from H4C\n",
    "\n",
    "sol2 = info.remove_degen(sol2, degen_sol=sol0)\n",
    "# Slow\n",
    "#vis_sols = {k: v for k, v in sol2.items() if len(k) == 3}\n",
    "#gain_sols = {k: v for k, v in sol2.items() if len(k) == 2}\n",
    "#chisq2_pol, chisq2_per_ant = hera_cal.redcal.normalized_chisq(use_data, use_wgts, freds, vis_sols, gain_sols)\n",
    "#chisq2 = 0.5 * (chisq2_pol['Jee'] + chisq2_pol['Jnn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7e1cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot firstcal calibrated visibilities for a redundant group\n",
    "if PLOT:\n",
    "    plot_red_gp(data, sol2, freds[0], title='Omnical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "241ab85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine how redundant solution for a group changed between firstcal & omnical\n",
    "if PLOT:\n",
    "    fig, axes = plt.subplots(figsize=(8,6), ncols=1, nrows=2, sharex=True)\n",
    "    gp = freds[0]\n",
    "    ubl = [bl for bl in gp if bl in sol0][0]\n",
    "    mask = np.where(data_wgts[0])\n",
    "    for cnt, sol in enumerate((sol0, sol2)):\n",
    "        u = sol[ubl][0]\n",
    "        axes[0].plot(hc.freqs / 1e6, np.angle(u), label=f'sol{2*cnt}')\n",
    "        axes[1].semilogy(hc.freqs[mask] / 1e6, np.abs(u[mask]), label=f'sol{2*cnt}')\n",
    "    title = str(ubl)\n",
    "    axes[0].set_title(title)\n",
    "    axes[0].set_ylabel('Phase')\n",
    "    axes[0].legend()\n",
    "    axes[1].set_ylabel('Amplitude')\n",
    "    axes[1].set_xlabel('Frequency [MHz]')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6576032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot chisq and # of iterations from omnical\n",
    "if PLOT:\n",
    "    plt.figure()\n",
    "    plt.semilogy(hc.freqs / 1e6, meta2['chisq'][0] / len(all_bls) * 4) # XXX fix this scaling\n",
    "    plt.semilogy(hc.freqs / 1e6, meta2['iter'][0])\n",
    "    plt.xlabel('Frequency [MHz]')\n",
    "    plt.ylabel('$\\chi_r^2$')\n",
    "    plt.ylim(3e-1, 1e3)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5fdb2f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if PLOT:\n",
    "#     plt.figure()\n",
    "#     for k, _chi in chisq2_per_ant.items():\n",
    "#         #print(k, np.median(_chi), np.where(_chi > 2)[0].size, np.median(chisq2b_per_ant[k]), np.where(chisq2b_per_ant[k] > 2)[0].size)\n",
    "#         if np.where(_chi > 2)[0].size / _chi.size > 0.2:\n",
    "#             continue\n",
    "#         plt.semilogy(hc.freqs / 1e6, (_chi * data_wgts)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c813ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start->omnical: 69.20, firstcal->omnical: 47.18\n"
     ]
    }
   ],
   "source": [
    "timer.clock('omnical')\n",
    "print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6090a99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if PLOT:\n",
    "#     plt.figure()\n",
    "#     hist, bins = np.histogram([np.where(_chi > 2)[0].size / _chi.size for _chi in chisq2_per_ant.values()])\n",
    "#     plt.plot(0.5 * (bins[1:] + bins[:-1]), hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "739cae87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tack on solutions to \"bad\" antennas given existing redundant bl solution\n",
    "\n",
    "gsum = {}\n",
    "gwgt = {}\n",
    "sol3 = deepcopy(sol2)\n",
    "\n",
    "for grp in reds:\n",
    "    try:\n",
    "        ubl = [bl for bl in grp if bl in sol3][0]\n",
    "    except(IndexError):\n",
    "        continue\n",
    "    u = sol3[ubl]\n",
    "    for bl in grp:\n",
    "        a_i, a_j = split_bl(bl)\n",
    "        noise = np.sqrt(autos[a_i] * autos[a_j])\n",
    "        wgt = 1 / (noise / np.sqrt(2))**2 # crosses have 1/2 variance of autos\n",
    "        if a_i not in sol3:\n",
    "            if a_j not in sol3:\n",
    "                continue\n",
    "            gsum[a_i] = gsum.get(a_i, 0) + data[bl] * (u * sol3[a_j].conj()).conj() * wgt\n",
    "            gwgt[a_i] = gwgt.get(a_i, 0) + np.abs(u)**2 * np.abs(sol3[a_j])**2 * wgt\n",
    "        elif a_j not in sol3:\n",
    "            gsum[a_j] = gsum.get(a_j, 0) + data[bl].conj() * (u.conj() * sol3[a_i].conj()).conj() * wgt\n",
    "            gwgt[a_j] = gwgt.get(a_j, 0) + np.abs(u)**2 * np.abs(sol3[a_i])**2 * wgt\n",
    "sol3.update({k: np.nan_to_num(gsum[k] / gwgt[k]) for k in gsum.keys()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9bc61b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start->badcal: 70.33, omnical->badcal:  1.13\n"
     ]
    }
   ],
   "source": [
    "timer.clock('badcal')\n",
    "print(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05214bb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot omnical gains versus first-guess gains from auto-correlations\n",
    "if PLOT:\n",
    "    plt.figure()\n",
    "    mask = np.where(data_wgts[0])\n",
    "    for k, v in auto_gains.items():\n",
    "        if k not in sol3:\n",
    "            continue\n",
    "            \n",
    "        plt.plot(v[0][mask], np.abs(sol3[k][0][mask]), ',', alpha=0.2)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.xlabel('Auto Gain')\n",
    "    plt.ylabel('Omnical Gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ee9fce9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot all gains (good and bad)\n",
    "if PLOT:\n",
    "    fig, axes = plt.subplots(figsize=(8,6), ncols=1, nrows=2, sharex=True)\n",
    "    mask = np.where(data_wgts[0])\n",
    "    for k, gain in sol3.items():\n",
    "        if len(k) == 3:\n",
    "            continue\n",
    "        if k[-1] == 'Jee':\n",
    "            ax = axes[0]\n",
    "        else:\n",
    "            ax = axes[1]\n",
    "        ax.semilogy(hc.freqs[mask] / 1e6, np.abs(gain[0][mask]), label=str(k))\n",
    "    axes[0].grid()\n",
    "    axes[0].set_ylabel('Gain')\n",
    "    axes[0].set_title('Omnical Gain Solutions')\n",
    "    axes[1].grid()\n",
    "    axes[1].set_ylabel('Gain')\n",
    "    plt.xlabel('Frequency [MHz]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5229948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7de59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_hera",
   "language": "python",
   "name": "python_hera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

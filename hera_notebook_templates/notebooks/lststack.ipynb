{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48edc0db",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Configuration</a></span></li><li><span><a href=\"#Do-the-binning\" data-toc-modified-id=\"Do-the-binning-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Do the binning</a></span></li><li><span><a href=\"#LST-bin-the-Autos\" data-toc-modified-id=\"LST-bin-the-Autos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>LST-bin the Autos</a></span><ul class=\"toc-item\"><li><span><a href=\"#In-painted-Mode\" data-toc-modified-id=\"In-painted-Mode-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>In-painted Mode</a></span></li><li><span><a href=\"#Flagged-Mode\" data-toc-modified-id=\"Flagged-Mode-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Flagged-Mode</a></span></li><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#Cross-Pairs\" data-toc-modified-id=\"Cross-Pairs-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Cross-Pairs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84a7b1",
   "metadata": {},
   "source": [
    "# LST-Bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543efff3",
   "metadata": {},
   "source": [
    "**by Steven Murray, Tyler Cox and Josh Dillon**, last updated 31st July, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96338e3d",
   "metadata": {},
   "source": [
    "This notebook performs LST-binning, producing a **single output file**. The input to this notebook consists of two configuration files, and one index:\n",
    "\n",
    "1. A `fileconf`, which is *produced* by `hera_cal.lstbin_simple.make_lst_bin_config_file()` run over a set of raw files. This file lists all the raw files that correspond to all the particular bins, which makes it quick for this notebook to read them in.\n",
    "2. A binning configuration file, `config`, that specifies all the parameters to use when performing the binning itself.\n",
    "3. The file index that corresponds to the LST bins that will be saved to the output file in _this_ notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f6474",
   "metadata": {},
   "source": [
    "The notebook then proceeds to do essentially the same thing as `hera_cal.lstbin_simple.lst_bin_files_single_outfile`, but with extra plotting and inspection stops along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e45f4c5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731e8f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from time import time as _time\n",
    "import resource\n",
    "from collections import UserDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import attrs\n",
    "\n",
    "from scipy import linalg, constants, signal\n",
    "from hera_filters import dspec\n",
    "\n",
    "from pyuvdata import UVData\n",
    "from hera_cal.abscal import complex_phase_abscal\n",
    "from hera_cal import lst_stack as lstbin\n",
    "from hera_cal.lst_stack.config import LSTConfig\n",
    "from hera_cal.red_groups import RedundantGroups\n",
    "from hera_cal.lst_stack import metrics as lstmet\n",
    "from hera_cal.lst_stack import stats as lststat\n",
    "from hera_cal.lst_stack.calibration import lstbin_absolute_calibration, _expand_degeneracies_to_ant_gains\n",
    "from hera_cal.lst_stack import averaging as avg\n",
    "from hera_cal import vis_clean, redcal, abscal, utils\n",
    "from hera_qm.time_series_metrics import true_stretches\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a48ff-2605-42a7-b3e3-5eeb97bbf031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = _time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfcdbd2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d16c3d",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "fileconf: str = \"/lustre/aoc/projects/hera/h6c-analysis/IDR2/lstbin-outputs/redavg-smoothcal-inpaint/file-config.h5\"\n",
    "fileidx: int = 380\n",
    "blchunk: int = 0\n",
    "\n",
    "papermill_input_path: str = \"\"\n",
    "papermill_output_path: str = \"\"\n",
    "\n",
    "# The following are defaults that can be overwritten at execution time (preferably by a YAML file)\n",
    "save_lstbin_data: bool = True\n",
    "save_metric_data: bool = True\n",
    "plot_n_worst: int = 5\n",
    "do_simultaneous_inpainting: bool = True\n",
    "do_extra_flagging: bool = False\n",
    "do_lstcal: bool = True\n",
    "lstcal_path: str = None\n",
    "\n",
    "outdir: str = Path(\"~/lststack-outputs\").expanduser()\n",
    "bl_chunk_size: int = 0\n",
    "rephase: bool = True\n",
    "fname_format: str = '{inpaint_mode}/zen.{kind}.{lst:7.5f}.{blchunk}.sum.uvh5'\n",
    "overwrite: bool = True\n",
    "write_med_mad: bool = False\n",
    "do_inpainted_average: bool = False\n",
    "freq_min: float = 0.0\n",
    "freq_max: float = 0.0\n",
    "history: str = \"\"\n",
    "plot_every: int = 1\n",
    "\n",
    "# In-painting config\n",
    "inpaint_horizon: float = 1.0\n",
    "inpaint_standoff: float = 0.0    # ns\n",
    "inpaint_eigencutoff: float = 1e-12\n",
    "inpaint_mindelay: float = 500.0  # ns\n",
    "inpaint_max_gap_factor: float = 2.0\n",
    "inpaint_max_convolved_flag_frac: float = 0.667\n",
    "inpaint_sample_cov_fraction: float = 0.0 # Default zero uses variance, one uses full sample covariance\n",
    "inpaint_use_unbiased_estimator: bool = False # Default False slight over estimate of the covariance, but guaranteed to be non-negative\n",
    "\n",
    "fm_low_freq: float = 87.5 # in MHz\n",
    "fm_high_freq: float = 108.0 # in MHz\n",
    "\n",
    "# Flagging Configuration\n",
    "zscore_threshold: float = 5              # Value of |Z| above which data are flagged. \n",
    "iterative_flagging_factor: float = 1.5   # When flagging on |Z|^2, the worst offender (W) is flagged, and any other offenders > W/iterative_flagging_factor\n",
    "watershed_threshold: float = 3           # Value of |Z| above which data surrounding other flagged data will be flagged.     \n",
    "max_flagging_iterations: int = 15             # Maximum number of iterations to perform when flagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd23f5e-2cb1-4771-a0fb-ab8c78a88435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameter changes for typing\n",
    "outdir = Path(outdir)\n",
    "if freq_max <= 0.0:\n",
    "    freq_max = None\n",
    "if freq_min <= 0.0:\n",
    "    freq_min = None\n",
    "if bl_chunk_size <= 0:\n",
    "    bl_chunk_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce6ca2-29ec-4b7a-a599-36992e8795fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"{blchunk}\" not in fname_format:\n",
    "    raise ValueError(\"The fname_format is missing a {blchunk} format option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2e877-b304-4c2f-8b92-2e82e9323d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_plots = (fileidx % plot_every) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117ac48-9b06-4362-b6e5-954fe4e0ac89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots or save_metric_data:\n",
    "    get_metrics = True\n",
    "else:\n",
    "    get_metrics = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396d118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fileconf = Path(fileconf)\n",
    "assert fileconf.exists() and fileconf.is_file(), \"The input file-configuration file is not a file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25effb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stackconf = LSTConfig.from_file(fileconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a5f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The LST grid was configured with these parameters: \\n\")\n",
    "for key, val in attrs.asdict(stackconf.config).items():\n",
    "    if key != 'data_files':\n",
    "        print(f\"  {key:>36}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcfdf53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The raw files have the following properties: \\n\")\n",
    "for key, val in stackconf.properties.items():\n",
    "    print(f\"  {key:>25}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f5b1c-dcd2-49c1-b40e-de401b8a3bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stackconf = stackconf.at_single_outfile(fileidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc5f4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"LST bin edges considered in this notebook (file index {fileidx}):\")\n",
    "print(f\"  {stackconf.lst_grid_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ad3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Raw files used in this notebook (for all bins): \\n\")\n",
    "for fl in stackconf.matched_files:\n",
    "    print(fl.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fda3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"The data has {len(stackconf.autopairs + stackconf.antpairs)} ant-pairs, and {stackconf.pols} polarizations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815429a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outdir = Path(outdir)\n",
    "if not outdir.exists():\n",
    "    outdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff075977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Writing output files to: \\n  {outdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf225cc-f865-4945-9986-83bd9375938b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_simultaneous_inpainting and do_inpainted_average:\n",
    "    raise ValueError(\"Cannot do both simultaneous inpainting and per-day inpainted averaging\")\n",
    "    \n",
    "if do_inpainted_average and stackconf.inpaint_files is None:\n",
    "    raise ValueError(\"Cannot do per-night inpainted average without inpainted files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298493de-7f6a-4e24-bdc6-b62340e7a7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split up the baselines into chunks that will be LST-binned together.\n",
    "# This is just to save on RAM.\n",
    "if bl_chunk_size is None:\n",
    "    bl_chunk_size = len(stackconf.antpairs)\n",
    "else:\n",
    "    bl_chunk_size = min(bl_chunk_size, len(stackconf.antpairs))\n",
    "\n",
    "n_bl_chunks = int(np.ceil(len(stackconf.antpairs) / bl_chunk_size))\n",
    "\n",
    "print(f\"This notebook is processing chunk {blchunk+1} of {n_bl_chunks} baseline chunks, each with {bl_chunk_size} baselines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e07f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lstcal_path is None and n_bl_chunks > 1 and do_lstcal:\n",
    "    raise ValueError(\n",
    "        \"Cannot run LSTCal when only a subset of the baselines are loaded and lstcal_path is not provided\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9274f-ed67-44a0-ac36-4e5a42b672ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reds_with_pols = RedundantGroups.from_antpos(\n",
    "    antpos={i: pos for i, pos in enumerate(stackconf.config.datameta.antpos_enu)}, \n",
    "    pols=stackconf.pols,\n",
    "    bl_error_tol=2.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04b13d-1793-4169-ba1c-0d069ba31ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_metadata():\n",
    "    # A function that prints metadata about the notebook\n",
    "    print(\"Software Versions Used: \")\n",
    "    for repo in ['numpy', 'scipy', 'astropy', 'hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata']:\n",
    "        mdl = importlib.import_module(repo)\n",
    "        print(f'{repo:>25}: {mdl.__version__}')\n",
    "        \n",
    "    print(\"Run by: \", end='')\n",
    "    os.system(\"whoami\");\n",
    "\n",
    "    print(f\"Run on {datetime.now()}\")\n",
    "    print(f\"Execution of notebook took: {(_time() - start_time)/60.0:.2f} minutes\")\n",
    "    print(f\"Peak memory in this notebook run: {resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024**2:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e26d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(set(sum((x.tolist() for x in stackconf.time_indices), start=[]))) != stackconf.n_lsts:\n",
    "    print(\"LST-Stacking for files where not all of the LST-bins have associated data is not yet supported.\")\n",
    "    print_metadata()\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6530710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If this notebook is making plots, and is being run through PAPERMILL, output an empty\n",
    "# file that tells the execution script to save a copy of the output notebook to the\n",
    "# public-facing notebook directory.\n",
    "if papermill_output_path and make_plots:\n",
    "    pth = Path(f\"{papermill_output_path}.hasplots\")\n",
    "    pth.touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c956a0-4fa8-49a9-b866-ac1f2ec29e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_is_redundantly_averaged = stackconf.config.is_redundantly_averaged\n",
    "print(f\"This data {'is' if data_is_redundantly_averaged else 'is not'} redundantly averaged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8380a-775c-4d77-9049-60e308e246db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partial function that makes it simpler to create files of the correct format.\n",
    "get_fname = partial(\n",
    "    lstbin.io.format_outfile_name,\n",
    "    lst=stackconf.lst_grid_edges[0],\n",
    "    pols=stackconf.pols,\n",
    "    inpaint_mode=True,\n",
    "    lst_branch_cut=stackconf.properties[\"lst_branch_cut\"],\n",
    "    fname_format=fname_format.replace(\"{blchunk}\", \"{blchunk:03}\"),\n",
    "    blchunk=blchunk\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb2696",
   "metadata": {},
   "source": [
    "## Define Stacking/Averaging Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cfdd5",
   "metadata": {},
   "source": [
    "Define and initialize the output files that we will write in this notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d17ae",
   "metadata": {},
   "source": [
    "Now, define a function that uses the configuration we've established and performs LST-binning for a subset of baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572b3ad-fc1f-4818-9887-34f18ba537fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stack_blchunk(bl_chunk: int | str):\n",
    "    \"\"\"Process a single chunk of baselines.\"\"\"\n",
    "    stacks: list[UVData] = lstbin.binning.lst_bin_files_from_config(\n",
    "        stackconf,\n",
    "        bl_chunk_to_load=bl_chunk,\n",
    "        nbl_chunks=n_bl_chunks,\n",
    "    )\n",
    "\n",
    "    rdcs = []\n",
    "    for lstidx, stack in enumerate(stacks):\n",
    "\n",
    "        rdc = lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=False,\n",
    "            get_mad=write_med_mad and not (do_inpainted_average or do_simultaneous_inpainting),  # MED/MAD gotten later if doing inpainting\n",
    "        )\n",
    "        rdcs.append(rdc)\n",
    "                     \n",
    "    return stacks, rdcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f96f4e-cb89-436f-ac12-f220e6661f38",
   "metadata": {},
   "source": [
    "## Plotting Style Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ea566-e388-4c5a-b330-3a1db23290ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_jd_ints = sorted({int(meta.times[0]) for meta in stackconf.matched_metas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f4fb7-5c04-478a-a715-f6ef0b30df6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "styles = {}\n",
    "\n",
    "for i, jdint in enumerate(data_jd_ints):\n",
    "    styles[jdint] = {'color': f\"C{i%10}\", 'ls': ['-', '--', ':', '-.'][i//10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae129d-3428-4234-b999-b4f19e25b2f8",
   "metadata": {},
   "source": [
    "## Define Subsets of Data to Consider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c277fa0-7c76-408a-a77e-970e18c2d9fe",
   "metadata": {},
   "source": [
    "### Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba6509-376b-4878-b791-6130337dc9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bands_considered = [\n",
    "    (0, 200), (200, 400), (400, 600), (600, 800), (800, 1000), (1000, 1200), (1200, 1400), (1400, 1536),\n",
    "    (0, 450),    # low band\n",
    "    (450, 1536), # high band\n",
    "    (0, 1536),   # full band\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc89519-8062-4b90-82c5-9fda9fe6f0c8",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e42212-606d-4ecf-925b-eaba46f9e122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_antenna_sectors():\n",
    "    antpos = stackconf.config.datameta.antenna_positions\n",
    "    zero_pos = np.mean([antpos[165], antpos[166], antpos[145]], axis=0)\n",
    "    \n",
    "    sectors = {}\n",
    "    for ant, pos in enumerate(antpos):\n",
    "        rec = pos - zero_pos\n",
    "        theta = np.arctan2(rec[1], rec[0])\n",
    "        bllen = np.sqrt(rec[0]**2 + rec[1]**2)\n",
    "        if bllen > 200:\n",
    "            sectors[ant] = 4  # outrigger\n",
    "        elif -np.pi / 3 <= theta < np.pi / 3:\n",
    "            sectors[ant] = 1\n",
    "        elif np.pi / 3 <= theta < np.pi:\n",
    "            sectors[ant] = 2\n",
    "        elif -np.pi <= theta < -np.pi/3:\n",
    "            sectors[ant] = 3\n",
    "    return sectors\n",
    "\n",
    "sectors = get_all_antenna_sectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0ccc9-194d-445e-8fcf-c973a55286c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getblvec(a, b):\n",
    "    return auto_stacks[0].antenna_positions[a] - auto_stacks[0].antenna_positions[b]\n",
    "def getbllen(a,b):\n",
    "    return np.sqrt(np.sum(np.square(getblvec(a,b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be9df6-4726-4b2c-9a64-7722fc8d7e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ee = lambda bl: bl[2] == 'ee'\n",
    "all_nn = lambda bl: bl[2] == 'nn'\n",
    "short_bls = lambda bl: getbllen(bl[0], bl[1])<=60.0 and len(set(bl[2]))==1\n",
    "long_bls = lambda bl: getbllen(bl[0], bl[1])>60.0 and len(set(bl[2]))==1\n",
    "intersector_bls = lambda bl: sectors[bl[0]] != sectors[bl[1]] and len(set(bl[2]))==1\n",
    "intrasector_bls = lambda bl: sectors[bl[0]] == sectors[bl[1]] and len(set(bl[2]))==1\n",
    "\n",
    "subsets = {\n",
    "    'all': lambda bl: True,\n",
    "    'ee-only': all_ee,\n",
    "    'nn-only': all_nn,\n",
    "    'Short (<60 m) baselines': short_bls,\n",
    "    'Long (>60 m) baselines': long_bls,\n",
    "    'Inter-sector baselines': intersector_bls,\n",
    "    \"Intra-sector baselines\": intrasector_bls,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d270e0-fc06-475f-9f3b-9b939b6346fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inpaint_bands = [(0, fm_low_freq), (fm_high_freq, np.inf)]  # default below and above FM\n",
    "\n",
    "# Get slices for the inpaint bands\n",
    "_inp = []\n",
    "for _bnd in inpaint_bands:\n",
    "    idx = np.nonzero((stackconf.config.datameta.freq_array >= _bnd[0] * 1e6) & (stackconf.config.datameta.freq_array < _bnd[1]*1e6))[0]\n",
    "    _inp.append(slice(idx[0], idx[-1] + 1))\n",
    "inpaint_bands = _inp\n",
    "print(\"Using the following bands for inpainting (channels):\")\n",
    "for bnd in inpaint_bands:\n",
    "    print(bnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a1e4d-42c6-4800-824f-1e190d114e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T18:20:46.071514Z",
     "iopub.status.busy": "2024-06-04T18:20:46.070413Z",
     "iopub.status.idle": "2024-06-04T18:20:46.084305Z",
     "shell.execute_reply": "2024-06-04T18:20:46.081600Z",
     "shell.execute_reply.started": "2024-06-04T18:20:46.071441Z"
    }
   },
   "source": [
    "## Perform Initial Stacking of Autos and Crosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759dfcac-3eb9-41d6-a7ed-ca640bbb9047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auto_stacks, autos_lstavg = stack_blchunk('autos') # Auto-stacks\n",
    "cross_stacks, cross_lstavg = stack_blchunk(blchunk) # Cross-stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1501b7-2715-4821-8775-0a9b87e38fd5",
   "metadata": {},
   "source": [
    "## LST-Bin Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c855c9-0869-4d91-bd45-9dd7e21a6599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if do_lstcal and n_bl_chunks==1: # can't fit all the baselines in memory if not redavg'd, and need all of them at once to do lstcal\n",
    "    all_calibration_parameters = {}\n",
    "    for i, (stack, lstavg_model, auto_model) in enumerate(zip(cross_stacks, cross_lstavg, autos_lstavg)):\n",
    "        calibration_parameters, gains = lstbin_absolute_calibration(\n",
    "            stack=stack, \n",
    "            model=lstavg_model['data'], \n",
    "            all_reds=reds_with_pols, \n",
    "            inpaint_bands=inpaint_bands,\n",
    "            auto_stack=auto_stacks[i],\n",
    "            auto_model=auto_model['data'],\n",
    "            calibrate_inplace=True, # calibrate inplace\n",
    "            run_amplitude_cal=True, # run amplitude calibration\n",
    "            run_phase_cal=True, # run phase calibration\n",
    "            run_cross_pol_phase_cal=True\n",
    "        )\n",
    "            \n",
    "        # Write out calibration parameters and metadata\n",
    "        calibration_parameters[\"freqs\"] = stack.freq_array\n",
    "        calibration_parameters[\"flags\"] = stack.flags[:, 0, :]\n",
    "        calibration_parameters[\"times\"] = stack.times\n",
    "        calibration_parameters[\"antpairs\"] = stack.antpairs\n",
    "        calibration_parameters[\"lst\"] = stackconf.lst_grid[i]\n",
    "        \n",
    "        all_calibration_parameters[stackconf.lst_grid[i]] = calibration_parameters\n",
    "        \n",
    "    # Get the calibration filename\n",
    "    cal_fname = get_fname(\n",
    "        fname_format=fname_format.replace(\"{blchunk}\", \"{blchunk:03}\").replace(\".sum.uvh5\", \".pkl\"),\n",
    "        kind='LSTCAL',\n",
    "    )\n",
    "    outfile = outdir / cal_fname\n",
    "        \n",
    "    # Write out calibration parameters\n",
    "    with open(outfile, 'wb') as handle:\n",
    "        pickle.dump(all_calibration_parameters, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        \n",
    "    # Recompute auto and cross averages after calibration - needed for STD files \n",
    "    cross_lstavg = [\n",
    "        lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=False,\n",
    "            get_mad=write_med_mad,\n",
    "        ) for stack in cross_stacks\n",
    "    ]\n",
    "    autos_lstavg = [\n",
    "        lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=False,\n",
    "            get_mad=write_med_mad,\n",
    "        ) for stack in auto_stacks\n",
    "    ]\n",
    "elif do_lstcal and n_bl_chunks > 1:    \n",
    "    # turn LSTCal calibration path into Path object\n",
    "    lstcal_path = Path(lstcal_path)\n",
    "    \n",
    "    # Get the calibration filename\n",
    "    cal_fname = get_fname(\n",
    "        fname_format=fname_format.replace(\"{blchunk}\", \"{blchunk:03}\").replace(\".sum.uvh5\", \".pkl\"),\n",
    "        kind='LSTCAL', blchunk=0\n",
    "    )\n",
    "    \n",
    "    with open(lstcal_path / cal_fname, 'rb') as calibration_file:\n",
    "        all_calibration_parameters = pickle.load(calibration_file)\n",
    "        \n",
    "    for i, (stack, auto_stack) in enumerate(zip(cross_stacks, auto_stacks)):\n",
    "        # Check that current LST-grid point matches the grid found in the calibration file\n",
    "        if stackconf.lst_grid[i] not in all_calibration_parameters:\n",
    "            raise KeyError(f\"LST-grid value {stackconf.lst_grid[i]} not found in calibration parameter file\")\n",
    "        \n",
    "        # Load in calibration parameters for given LST-grid\n",
    "        calibration_parameters = all_calibration_parameters[stackconf.lst_grid[i]]\n",
    "                \n",
    "        # Get unique antennas in stack\n",
    "        gain_ants = set()\n",
    "        for ap in stack.antpairs:\n",
    "            gain_ants.update(ap)\n",
    "        gain_ants = list(gain_ants)\n",
    "    \n",
    "        # Add tip-tilt gain parameters to calibration_parameters\n",
    "        unique_pols = list(\n",
    "            set(sum(map(list, [utils.split_pol(pol) for pol in stack.pols]), []))\n",
    "        )\n",
    "\n",
    "        # Get the grid\n",
    "        transformed_antpos = redcal.reds_to_antpos(reds_with_pols)\n",
    "        abscal._put_transformed_array_on_integer_grid(transformed_antpos)\n",
    "\n",
    "        # turn solution into per-antenna gains\n",
    "        phase_gains = {}\n",
    "        for (ant, pol) in itertools.product(gain_ants, unique_pols):\n",
    "            # Calculate gains from tip-tilt calibration parameters\n",
    "            tip_tilt = calibration_parameters[f\"T_{pol}\"]\n",
    "            tip_tilt = np.where(np.isfinite(tip_tilt), tip_tilt, 0)\n",
    "            phase_gains[(ant, pol)] = np.exp(1j * np.squeeze(np.dot(tip_tilt, transformed_antpos[ant])))\n",
    "\n",
    "            # If relative phase calibration was done, apply gains\n",
    "            if \"delta\" in calibration_parameters and pol == \"Jee\":\n",
    "                phase_gains[(ant, pol)] *= np.exp(1j * calibration_parameters[\"delta\"])\n",
    "                \n",
    "        \n",
    "        # Compute gains and smooth\n",
    "        gains = _expand_degeneracies_to_ant_gains(\n",
    "            stack,\n",
    "            amplitude_parameters={\n",
    "                f\"A_{pol}\": calibration_parameters[f\"A_{pol}\"] for pol in unique_pols\n",
    "            },\n",
    "            phase_gains=phase_gains,\n",
    "            inpaint_bands=inpaint_bands,\n",
    "            auto_stack=auto_stack\n",
    "        )\n",
    "        \n",
    "        # Apply calibration solutions\n",
    "        for polidx, pol in enumerate(stack.pols):\n",
    "            # Loop through baselines\n",
    "            for apidx, (ant1, ant2) in enumerate(stack.antpairs):\n",
    "                antpol1, antpol2 = utils.split_bl((ant1, ant2, pol))\n",
    "\n",
    "                # Compute gain and calibrate out\n",
    "                bl_gain = gains[antpol1] * gains[antpol2].conj()\n",
    "                stack.data[:, apidx, :, polidx] /= bl_gain\n",
    "\n",
    "            # Loop through autos\n",
    "            for apidx, (ant1, ant2) in enumerate(auto_stack.antpairs):\n",
    "                antpol1, antpol2 = utils.split_bl((ant1, ant2, pol))\n",
    "\n",
    "                # Compute gain and calibrate out\n",
    "                auto_gain = gains[antpol1] * gains[antpol2].conj()\n",
    "                auto_stack.data[:, apidx, :, polidx] /= auto_gain\n",
    "\n",
    "        \n",
    "    # Recompute auto and cross averages after calibration - needed for STD files \n",
    "    cross_lstavg = [\n",
    "        lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=False,\n",
    "            get_mad=write_med_mad,\n",
    "        ) for stack in cross_stacks\n",
    "    ]\n",
    "    autos_lstavg = [\n",
    "        lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=False,\n",
    "            get_mad=write_med_mad,\n",
    "        ) for stack in auto_stacks\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b55b2",
   "metadata": {},
   "source": [
    "## Autos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646623f",
   "metadata": {},
   "source": [
    "### Compute Stats for Autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48853eb-611a-463c-966f-6435da5312aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auto_stats = [\n",
    "    lstmet.LSTBinStats.from_reduced_data(\n",
    "        rdc=rdc, antpairs=stackconf.autopairs, pols=stackconf.pols, reds=reds_with_pols if data_is_redundantly_averaged else None\n",
    "    ) for rdc in autos_lstavg\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea584858",
   "metadata": {},
   "source": [
    "### Inpaint Autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b3534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_INPAINT_CACHE_ = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6906c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_simultaneous_inpainting:\n",
    "    auto_inpaint_dpss_models = []\n",
    "\n",
    "    for i, stack in enumerate(auto_stacks):\n",
    "        \n",
    "        _avg, dpss_models = avg.average_and_inpaint_simultaneously(\n",
    "            stack,\n",
    "            stack,\n",
    "            inpaint_bands = inpaint_bands,\n",
    "            return_models = make_plots,\n",
    "            cache = _INPAINT_CACHE_,\n",
    "            filter_properties = {\n",
    "                \"min_dly\": inpaint_mindelay, \n",
    "                \"horizon\": inpaint_horizon,\n",
    "                \"standoff\": inpaint_standoff, \n",
    "            },\n",
    "            eigenval_cutoff=[inpaint_eigencutoff], \n",
    "            max_gap_factor=inpaint_max_gap_factor,\n",
    "            max_convolved_flag_frac=inpaint_max_convolved_flag_frac,\n",
    "            use_unbiased_estimator=inpaint_use_unbiased_estimator,\n",
    "            sample_cov_fraction=inpaint_sample_cov_fraction,\n",
    "        )\n",
    "\n",
    "        auto_inpaint_dpss_models.append(dpss_models)\n",
    "        autos_lstavg[i]['data'] = _avg['data']\n",
    "        autos_lstavg[i]['flags'] = _avg['flags']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2d0d6",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccd669-53d7-4888-8382-831e028966a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_auto_plot(auto_stacks: list[UVData], lstbin: list[dict]):\n",
    "    \n",
    "    fig, ax = plt.subplots(\n",
    "        len(stackconf.autopairs)*len(stackconf.pols), len(auto_stacks), \n",
    "        sharex=True, squeeze=False, constrained_layout=True,\n",
    "        figsize=(12, 6)\n",
    "    )\n",
    "\n",
    "    for i, (stack, avg) in enumerate(zip(auto_stacks, lstbin)):\n",
    "        for j, autopair in enumerate(stackconf.autopairs):\n",
    "            for p, pol in enumerate(stackconf.pols):\n",
    "                axx = ax[j*len(stackconf.pols) + p, i]\n",
    "                \n",
    "                for k, t in enumerate(stack.times):\n",
    "                    flg = stack.get_flags(autopair + (pol,))[k]\n",
    "                    d = stack.get_data(autopair+(pol,))[k]\n",
    "                    axx.plot(\n",
    "                        stack.freq_array / 1e6,\n",
    "                        np.where(flg, np.nan, np.abs(d)),\n",
    "                        label=f\"{int(t)}\" if not p else None,\n",
    "                        **styles[int(t)]\n",
    "                    )\n",
    "                    axx.set_yscale('log')\n",
    "                    axx.set_title(f\"Pair {autopair}, pol={pol}, LST {stackconf.lst_grid[i]*12/np.pi:.3f} hr\")\n",
    "\n",
    "                # plot the mean\n",
    "                axx.plot(\n",
    "                    stack.freq_array / 1e6,\n",
    "                    np.where(avg['flags'][j, :, p], np.nan, np.abs(avg['data'][j, :, p])),\n",
    "                    label='LSTBIN',\n",
    "                    color='k', lw=2\n",
    "                )\n",
    "                \n",
    "    ax[0,0].legend(ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34526c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    make_auto_plot(auto_stacks, autos_lstavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae48cd95",
   "metadata": {},
   "source": [
    "## Cross-Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44389478-fc7e-4a0f-950a-4678cbe04b6e",
   "metadata": {},
   "source": [
    "### Improve Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ffe94-0954-4b6d-a075-1faf1df62053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "\n",
    "def watershed_ndim(metrics: np.ndarray, flags: np.ndarray, axis: int, threshold: float, size: int = 1):\n",
    "    \"\"\"Perform a watershed filter over one axis of a multi-dimensional array.\"\"\"\n",
    "    assert metrics.shape == flags.shape\n",
    "    outflags = flags.copy()\n",
    "    is_neighbour_flagged = np.zeros_like(outflags)\n",
    "    \n",
    "    ndim = metrics.ndim\n",
    "    shape = np.ones(ndim, dtype=int)\n",
    "    shape[axis] = 2*size + 1\n",
    "    kernel = np.zeros(shape)\n",
    "        \n",
    "    while True:\n",
    "        nflags = np.sum(outflags)\n",
    "        is_neighbor_flagged = convolve(outflags, kernel, mode='same', method='direct').astype(bool)        \n",
    "        outflags |= (is_neighbor_flagged & (metrics >= threshold))\n",
    "        if np.sum(outflags) == nflags:\n",
    "            break\n",
    "    \n",
    "    return outflags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95af9b-e653-4596-aebe-5919745710dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iterative_flagger(func, stack, variance, max_iter=10):\n",
    "    niter = 0\n",
    "    nflags = np.sum(stack.flags)\n",
    "    \n",
    "    while niter < max_iter:\n",
    "        print(f\"    iter {niter}: nflags = {nflags} ({nflags*100/stack.flag_array.size:.2f} %)\")\n",
    "        zsq = lstmet.get_squared_zscores_flagged(stack, variance=variance)\n",
    "        func(stack, zsq)\n",
    "        new_nflags = np.sum(stack.flags)\n",
    "        if  new_nflags == nflags:\n",
    "            break\n",
    "        nflags = new_nflags\n",
    "        niter += 1\n",
    "    \n",
    "    return zsq\n",
    "\n",
    "def do_flagging(funcs, stacks, auto_stats, max_iter=10):\n",
    "    out_zsq = []\n",
    "    for i, (stack, stat) in enumerate(zip(stacks, auto_stats)):\n",
    "        print(f\"Stack {i}\")\n",
    "        variance = lstmet.get_nightly_predicted_variance_stack(stack, stat, flag_if_inpainted=True) / 2\n",
    "        \n",
    "        for fnc in funcs:\n",
    "            print(f\"  Flagger: {fnc.__name__}\")\n",
    "            zsq = iterative_flagger(fnc, stack, variance, max_iter=max_iter)\n",
    "            \n",
    "        out_zsq.append(zsq)\n",
    "    return out_zsq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26389a-681b-418c-94c3-3e4798d1c68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def direct_zscore_pruning(stack,zsq):\n",
    "    stack.flags |= ((zsq.metrics > zscore_threshold**2) & (zsq.metrics >= np.nanmax(zsq.metrics, axis=0) / iterative_flagging_factor))\n",
    "    \n",
    "def watershed(stack, zsq):\n",
    "    stack.flags |= watershed_ndim(zsq.metrics, stack.flags, axis=-2, threshold=watershed_threshold**2, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f51883-9596-4fc1-992e-847d719e9719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zsquare = [lstmet.get_squared_zscores_flagged(stack, auto_stats=stats) for stack, stats in zip(cross_stacks, auto_stats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c2544-09c4-400d-b89c-0c000d89e58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_extra_flagging:\n",
    "    # Keep a copy of the original flags and Z^2 so we can check for differences later\n",
    "    original_flags = [stack.flag_array.copy() for stack in cross_stacks]\n",
    "    original_zsquare = zsquare\n",
    "    zsquare = do_flagging([direct_zscore_pruning, watershed], cross_stacks, auto_stats, max_iter=max_flagging_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98fc9f-a22e-4a2d-8ff1-8bccfdb453f5",
   "metadata": {},
   "source": [
    "### Inpaint Crosses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a78dc-d227-4479-8ebb-546e6ac5568e",
   "metadata": {},
   "source": [
    "We simultaneously inpaint and average the data with the flags we're given, using the covariance of a DPSS fit to the mean as a constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221ddbc-b7a1-4352-afda-852cbc762ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    # We need this if we want to make a plot comparing the new simultaneous inpaint\n",
    "    original_data_mean = [lstavg['data'].copy() for lstavg in cross_lstavg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049096c-3d53-4929-b594-cb683a226132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if do_simultaneous_inpainting:\n",
    "    inpaint_dpss_models = []\n",
    "\n",
    "    for i, (stack, auto_stack) in enumerate(zip(cross_stacks, auto_stacks)):\n",
    "        _avg, dpss_models = avg.average_and_inpaint_simultaneously(\n",
    "            stack,\n",
    "            auto_stack,\n",
    "            inpaint_bands = inpaint_bands,\n",
    "            return_models = make_plots,\n",
    "            cache = _INPAINT_CACHE_,\n",
    "            filter_properties = {\n",
    "                \"min_dly\": inpaint_mindelay, \n",
    "                \"horizon\": inpaint_horizon,\n",
    "                \"standoff\": inpaint_standoff, \n",
    "            },\n",
    "            eigenval_cutoff=[inpaint_eigencutoff], \n",
    "            max_gap_factor=inpaint_max_gap_factor,\n",
    "            max_convolved_flag_frac=inpaint_max_convolved_flag_frac,\n",
    "            use_unbiased_estimator=inpaint_use_unbiased_estimator,\n",
    "            sample_cov_fraction=inpaint_sample_cov_fraction,\n",
    "        )\n",
    "        inpaint_dpss_models.append(dpss_models)\n",
    "        cross_lstavg[i]['data'] = _avg['data']\n",
    "        cross_lstavg[i]['flags'] = _avg['flags']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805bcaf-040e-4bd4-93de-a735cccccabc",
   "metadata": {},
   "source": [
    "Let's make some plots to inspect how the inpainting did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced3356-0394-4ec0-8574-8475f85d3abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_biggest_inpaint_differences(band, n: int = 5):\n",
    "    inpdata = cross_lstavg[0]['data'][:, band]\n",
    "    flgdata = np.where(\n",
    "        cross_lstavg[0]['nsamples'][:, band] == 0, np.nan, original_data_mean[0][:, band]\n",
    "    )\n",
    "    diff = np.nanmax(np.abs(inpdata - flgdata), axis=1).flatten()\n",
    "    diff[np.isnan(diff)] = -1\n",
    "    idx = np.argsort(diff)\n",
    "\n",
    "    baselines_with_biggest_differences = []\n",
    "    for ii in idx[::-1][:n]:\n",
    "        pol_idx = ii % len(cross_stacks[0].pols)\n",
    "        ap_idx = ii // len(cross_stacks[0].pols)\n",
    "        baselines_with_biggest_differences.append((*cross_stacks[0].antpairs[ap_idx], cross_stacks[0].pols[pol_idx]))\n",
    "    return baselines_with_biggest_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57e4f7-5b11-44f4-8aca-015a89150e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots and do_simultaneous_inpainting:\n",
    "    biggest_inpaint_diffs = {}\n",
    "    n_biggest_diffs = 5\n",
    "\n",
    "    for band in inpaint_bands:\n",
    "        biggest_inpaint_diffs[(band.start, band.stop)] = get_biggest_inpaint_differences(band, n=n_biggest_diffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3fdbc-12d3-4364-bb47-74b8151b7d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots and do_simultaneous_inpainting:\n",
    "    fig, ax = plt.subplots(len(biggest_inpaint_diffs)*n_biggest_diffs, 1, figsize=(15, 2.5*len(biggest_inpaint_diffs)*n_biggest_diffs), layout='constrained')\n",
    "\n",
    "    kk = 0\n",
    "\n",
    "    complete_flags = cross_stacks[0].flagged_or_inpainted()\n",
    "\n",
    "    for jj, (band, blpol_list) in enumerate(biggest_inpaint_diffs.items()):\n",
    "        band = slice(*band)\n",
    "        for ii, blpol in enumerate(blpol_list):\n",
    "\n",
    "            apidx = cross_stacks[0].antpairs.index(blpol[:2])\n",
    "            polidx = cross_stacks[0].pols.index(blpol[2])\n",
    "\n",
    "            diff = np.abs(\n",
    "                np.where(\n",
    "                    cross_lstavg[0]['flags'][apidx, band, polidx], np.nan, original_data_mean[0][apidx, band, polidx]\n",
    "                ) - cross_lstavg[0]['data'][apidx, band, polidx]\n",
    "            )\n",
    "\n",
    "            worst_idx = np.argmax(diff[np.isfinite(diff)])\n",
    "            subband = slice(max(worst_idx - 50, 0), min(worst_idx+50, len(diff)))\n",
    "\n",
    "            fq = cross_stacks[0].freq_array[band][subband] / 1e6\n",
    "            ax[kk].plot(\n",
    "                fq, \n",
    "                np.abs(\n",
    "                    np.where(\n",
    "                        cross_lstavg[0]['flags'][apidx, band, polidx], np.nan, original_data_mean[0][apidx, band, polidx]\n",
    "                    )[subband]\n",
    "                ), \n",
    "                lw=3, ls='-', color='k', label='flagged mean'\n",
    "            )\n",
    "            ax[kk].plot(fq, np.abs(cross_lstavg[0]['data'][apidx, band, polidx][subband]), lw=3, ls='--', color='red', label='simul. inpaint')\n",
    "\n",
    "            #ax[kk].plot(fq, np.abs(inpaint_dpss_models[0][blpol][band][subband]), lw=2, color='purple', ls=':', label='model')\n",
    "\n",
    "            gotlabel = False\n",
    "            for i, jd in enumerate(cross_stacks[0].nights):\n",
    "                flg = complete_flags[i, apidx, band, polidx][subband]\n",
    "                if np.all(flg):\n",
    "                    continue\n",
    "\n",
    "                d = np.abs(cross_stacks[0].data[i, apidx, band, polidx][subband])\n",
    "                ax[kk].plot(fq, d, lw=1, alpha=0.6, color=styles[jd]['color'])\n",
    "\n",
    "                if np.any(flg):\n",
    "                    ax[kk].scatter(fq[flg], d[flg], marker='o', edgecolors=styles[jd]['color'], facecolors='none', alpha=0.4, label='flagged datum' if not gotlabel else None)\n",
    "                    gotlabel = True\n",
    "            ax[kk].legend(ncols=2)\n",
    "            ax[kk].set_title(str(blpol))\n",
    "\n",
    "            kk += 1\n",
    "    fig.suptitle(\"Examples of Biggest Differences in Inpainted Solutions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd58cc9-70c4-46a7-a893-fdc38b41d3a1",
   "metadata": {},
   "source": [
    "### Write Out Averaged Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538e308-d4da-48ca-a511-603266e2236a",
   "metadata": {},
   "source": [
    "So far, we have the `cross_lstavg` as _either_ a flagged-mode average, or a simultaneously-inpainted average (if `do_simultaneous_inpainting==True`). If the configuration requests\n",
    "old-style per-night inpainting, then do it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860918b3-e0fa-4ea0-be3b-2ddd28e69a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_inpainted_average:\n",
    "    cross_lstavg = [\n",
    "        lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=True,\n",
    "            get_mad=write_med_mad,\n",
    "        ) for stack in cross_stacks\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6db06-c4a8-4776-8f46-c4c264cae9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make it a bit easier to create the outfiles\n",
    "create_empty_uvd = partial(\n",
    "    lstbin.io.create_empty_uvd,\n",
    "    pols=stackconf.pols,\n",
    "    file_list=stackconf.matched_metas,\n",
    "    history=history,\n",
    "    start_jd=stackconf.properties['first_jd'],\n",
    "    freq_min=freq_min,\n",
    "    freq_max=freq_max,\n",
    "    lst_branch_cut=stackconf.properties[\"lst_branch_cut\"],\n",
    "    lsts=stackconf.lst_grid,\n",
    ")\n",
    "\n",
    "create_file = partial(\n",
    "    lstbin.io.create_lstbin_output_file,\n",
    "    outdir=outdir,\n",
    "    overwrite=overwrite,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0bb4a-b45c-476f-9d17-11111ac03d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save_lstbin_data:\n",
    "    out_files = {}\n",
    "    kinds = [\"LST\", \"STD\"]\n",
    "    if write_med_mad:\n",
    "        kinds += [\"MED\", \"MAD\"]\n",
    "    \n",
    "    for kind in kinds:\n",
    "        if blchunk == 0:\n",
    "            # Save the autos as well.\n",
    "            fname = get_fname(\n",
    "                fname_format = fname_format.replace(\"{blchunk}\", \"autos\"), kind=kind\n",
    "            )\n",
    "            auto_uvd_template = create_empty_uvd(antpairs=auto_stacks[0].antpairs)\n",
    "            out_files[(kind, 'autos')] = create_file(fname=fname, uvd_template=auto_uvd_template)\n",
    "\n",
    "        fname = get_fname(kind=kind)\n",
    "        cross_uvd_template = create_empty_uvd(antpairs=cross_stacks[0].antpairs)\n",
    "        out_files[(kind, 'cross')] = create_file(fname=fname, uvd_template=cross_uvd_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a99068-e637-48b9-85cc-661fe48ad8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_data(rdc: dict, stack: lstbin.LSTStack, lstidx: int, pairs: str, template):\n",
    "    chunk_size = stack.Nbls\n",
    "\n",
    "    write = partial(\n",
    "        template.write_uvh5_part,\n",
    "        blt_inds=np.arange(chunk_size) * stackconf.n_lsts + lstidx,\n",
    "        flag_array=rdc['flags'],\n",
    "    )\n",
    "    \n",
    "    write(\n",
    "        filename=out_files[(\"LST\", pairs)],\n",
    "        data_array=rdc[\"data\"],\n",
    "        nsample_array=rdc[\"nsamples\"],\n",
    "    )\n",
    "    print(f\"Wrote {out_files[('LST', pairs)]}\")\n",
    "    \n",
    "    write(\n",
    "        filename=out_files[(\"STD\", pairs)],\n",
    "        data_array=rdc[\"std\"],\n",
    "        nsample_array=rdc[\"days_binned\"],\n",
    "    )\n",
    "    print(f\"Wrote {out_files[('STD', pairs)]}\")\n",
    "    \n",
    "    if write_med_mad:\n",
    "        write(\n",
    "            filename=out_files[(\"MED\", pairs)],\n",
    "            data_array=rdc[\"median\"],\n",
    "            nsample_array=rdc[\"nsamples\"],\n",
    "        )\n",
    "        print(f\"Wrote {out_files[('MED', pairs)]}\")\n",
    "        \n",
    "        write(\n",
    "            filename=out_files[(\"MAD\", pairs)],\n",
    "            data_array=rdc[\"mad\"],\n",
    "            nsample_array=rdc[\"days_binned\"],\n",
    "        )\n",
    "        print(f\"Wrote {out_files[('MAD', pairs)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d0343-c469-4f87-af27-3570827627e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save_lstbin_data:\n",
    "    for lstidx in range(stackconf.n_lsts):\n",
    "        if blchunk==0:\n",
    "            write_data(autos_lstavg[lstidx], auto_stacks[lstidx], lstidx, 'autos', template=auto_uvd_template)\n",
    "        write_data(cross_lstavg[lstidx], cross_stacks[lstidx], lstidx, 'cross', template=cross_uvd_template)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00f546-da75-4d7e-9252-0b06920aa26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not get_metrics:\n",
    "    # The rest of the notebook is simply getting metrics and inspecting them.\n",
    "    print_metadata()\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1829d46e-b428-4740-9ff9-07ad3aa9cd26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:54:35.025659Z",
     "iopub.status.busy": "2024-03-20T12:54:35.025016Z",
     "iopub.status.idle": "2024-03-20T12:54:35.061107Z",
     "shell.execute_reply": "2024-03-20T12:54:35.060118Z",
     "shell.execute_reply.started": "2024-03-20T12:54:35.025611Z"
    }
   },
   "source": [
    "### Distributions of $Z^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd99bf6-6ee7-4a42-bea3-534debf15060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_stats = [\n",
    "    lstmet.LSTBinStats.from_reduced_data(\n",
    "        rdc=rdc, antpairs=cross_stacks[0].antpairs, pols=stackconf.pols, reds=reds_with_pols if data_is_redundantly_averaged else None\n",
    "    ) for rdc in cross_lstavg\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854206a-7886-4556-9a4a-d390bb3a1bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zdist_pred = lststat.zsquare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ecc99-b476-417e-8f6d-74a5a0efe88a",
   "metadata": {},
   "source": [
    "#### Simple Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92491f93-a985-460e-86ad-23610757802e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autoplot(zsquare):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    x = np.logspace(-5, 7, 200)\n",
    "\n",
    "    xc = 10**((np.log10(x[1:]) + np.log10(x[:-1]))/2)\n",
    "    dndzsq = zdist_pred.pdf(xc)\n",
    "\n",
    "    for i, zsq in enumerate(zsquare):\n",
    "        for j, pol in enumerate(zsq.pols):\n",
    "            ax[0].hist(zsq.metrics[..., j].flatten(), bins=x, label=f\"LST Bin {i}. Pol '{pol}'\", density=True, histtype='step', lw=3 if pol[0]==pol[1] else 1, ls=['-', ':'][i], color=f'C{j}', alpha=0.7)\n",
    "\n",
    "    ax[0].plot(xc, dndzsq, color='k', ls ='--', label='Predicted')\n",
    "    ax[0].set_xscale('log')\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].set_ylim(1e-12, 1e4)\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel(r\"Log10 $Z^2$\")\n",
    "    ax[0].set_title(\"PDF of $Z^2$\")\n",
    "\n",
    "    # Plot the CDF\n",
    "    x = np.logspace(-5, np.log10(max(np.nanmax(zsq.metrics) for zsq in zsquare)), 100)\n",
    "\n",
    "    for zsq in zsquare:\n",
    "        for j, pol in enumerate(zsq.pols):\n",
    "            zsqm = zsq.metrics[..., j]\n",
    "            zsqm = zsqm[np.isfinite(zsqm)]\n",
    "            size = zsqm.size\n",
    "\n",
    "            cdf_data = [np.sum(zsqm < c)/size for c in x]\n",
    "            ax[1].plot(x, cdf_data, lw=3 if pol[0]==pol[1] else 1, ls=['-', ':'][i], color=f'C{j}', alpha=0.7)\n",
    "    \n",
    "    ax[1].plot(x, zdist_pred.cdf(x), color='k', ls='--')\n",
    "    ax[1].set_xlabel(r\"$Z^2$\")\n",
    "    ax[1].set_title(\"CDF of $Z^2$\")\n",
    "    ax[1].set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c371fc5-f119-4de8-8a52-ba4c505103ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    autoplot(zsquare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d0bee-a457-4794-81cf-c82672740338",
   "metadata": {},
   "source": [
    "#### Get list of bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57eed1-eb95-44cb-b0d9-e940b065934c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def consecutive(data: np.ndarray, stepsize: int=1) -> list[tuple[int, int]]:\n",
    "    \"\"\"From https://stackoverflow.com/a/46606745/1467820\"\"\"\n",
    "    sequences = np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "    \n",
    "    l = []\n",
    "    for s in sequences:\n",
    "        if len(s) > 1:\n",
    "            l.append((s[0], s[-1]))\n",
    "        else:\n",
    "            l.append((s[0], s[0]+1))\n",
    "            \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd5c40-400a-4224-8a21-e1dd584d67c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allbad = {}\n",
    "inpainted_regions = {}\n",
    "\n",
    "for lstidx, (zuv, stack) in enumerate(zip(zsquare, cross_stacks)):\n",
    "    inpaint_flags = stack.inpainted()\n",
    "    for iap, (a, b) in enumerate(zuv.antpairs):\n",
    "        for ipol, pol in enumerate(zuv.pols):\n",
    "\n",
    "            for night, zsqn in enumerate(zuv.metrics[:, iap, :, ipol]):\n",
    "                key = (lstidx, a, b, ipol, jdint)\n",
    "\n",
    "                jdint = zuv.nights[night]\n",
    "\n",
    "                # Get contiguous regions of bad (|Z| > 3) data\n",
    "                badfreqs = np.nonzero(zsqn > 9)[0]\n",
    "                if len(badfreqs) > 0:\n",
    "                    ranges = consecutive(badfreqs)\n",
    "\n",
    "                    for rng in ranges:\n",
    "                        allbad[key+(rng[0], rng[1])] = zsqn[rng[0]:rng[1]]\n",
    "\n",
    "                if stackconf.inpaint_files is not None:\n",
    "                    badfreqs = np.nonzero(inpaint_flags[night, iap, :, ipol])\n",
    "                    if len(badfreqs) > 0:\n",
    "                        ranges = consecutive(badfreqs)\n",
    "\n",
    "                        for rng in ranges:\n",
    "                            allbad[key+(rng[0], rng[1])] = zsqn[rng[0]:rng[1]]\n",
    "    \n",
    "                else:\n",
    "                    # Get contiguous regions of inpainted data (anything that is flagged outside FM)\n",
    "                    for band in inpaint_bands:\n",
    "                        badfreqs = np.nonzero(stack.flags[night, iap, band, ipol])[0]\n",
    "\n",
    "                        if len(badfreqs) > 0:\n",
    "                            ranges = consecutive(badfreqs)\n",
    "\n",
    "                            for rng in ranges:\n",
    "                                inpainted_regions[key+(rng[0], rng[1])] = zsqn[band][rng[0]:rng[1]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61998a93-638a-4f4b-9e54-161ecc543691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save_metric_data:\n",
    "    # Write out the \"bad\" data\n",
    "    fname = get_fname(kind=\"HIGHZ\")\n",
    "\n",
    "    with h5py.File(outdir / fname, 'w') as fl:\n",
    "        fl['indices'] = np.array(list(allbad.keys()))  # integer array\n",
    "        fl['zsq'] = (np.concatenate(tuple(allbad.values())) if len(allbad) > 0 else np.array([]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f321de-8fd9-41b5-a2fb-92d5ff4d94db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_lengths_all = [\n",
    "    [b - a for _, _, _, polidx, _, a, b in allbad.keys() if polidx==i]\n",
    "    for i in range(len(cross_stacks[0].pols))\n",
    "]\n",
    "\n",
    "for i, chunk_lengths in enumerate(chunk_lengths_all):\n",
    "    if len(chunk_lengths) > 0:\n",
    "        print(f\"Biggest Frequency Chunk With |Z|>3 for Pol {cross_stacks[0].pols[i]}: \", np.max(chunk_lengths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce532f-fa59-4d6e-90bd-9737b71c9c8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T14:31:20.304124Z",
     "iopub.status.busy": "2024-03-20T14:31:20.303539Z",
     "iopub.status.idle": "2024-03-20T14:31:20.310295Z",
     "shell.execute_reply": "2024-03-20T14:31:20.308960Z",
     "shell.execute_reply.started": "2024-03-20T14:31:20.304075Z"
    }
   },
   "source": [
    "#### Histogram of freq-chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab2c4c-8b5c-4847-bf56-ebda5e1bad1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    for i, chunk_lengths in enumerate(chunk_lengths_all):\n",
    "        if len(chunk_lengths) > 0:\n",
    "            plt.hist(chunk_lengths, bins=np.arange(np.min(chunk_lengths), np.max(chunk_lengths)+1), label=cross_stacks[0].pols[i], histtype='step')\n",
    "            plt.yscale('log')\n",
    "            plt.xlabel(\"Channel-Chunk Length with |Z|>3\")\n",
    "            plt.ylabel(\"Number of Occurences\");\n",
    "        elif make_plots:\n",
    "            print(f\"No |Z| > 3 data found for pol {cross_stacks[0].pols[i]}\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106c9f8-052d-4231-847d-935b3641fed2",
   "metadata": {},
   "source": [
    "#### BoxPlots of Z^2 across axis chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a624ebb-096a-46bf-8eaa-c09e0abdb1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _set_boxplot_ax_props(nboxes: int, ax):\n",
    "    ax.axhline(zdist_pred.ppf(0.5), ls='-', color='gray')\n",
    "    ax.fill_between([-0.5, nboxes-0.5], [zdist_pred.ppf(0.16)]*2, [zdist_pred.ppf(0.84)]*2, color='gray', alpha=0.2)\n",
    "    ax.fill_between([-0.5, nboxes-0.5], [zdist_pred.ppf(0.02)]*2, [zdist_pred.ppf(0.98)]*2, color='gray', alpha=0.2)\n",
    "    \n",
    "    ax.axhline(1, ls='--', color='C3', lw=1)\n",
    "    ax.set_ylim(1e-1, None)\n",
    "    ax.set_xlim(-0.5, nboxes-0.5)\n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel(r\"$Z^2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45617ebd-403f-42e0-9b7d-7af8ae6ddf08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zsq_flags = [(stack.flagged_or_inpainted() | (~np.isfinite(zsq.metrics))) for zsq, stack in zip(zsquare, cross_stacks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaccced-bd4b-4fef-b429-a3265ee6ead0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def box_plot_all_groups(zscores, stacks):\n",
    "    fig, axx = plt.subplots(len(subsets), 1, sharex=True, figsize=(12, 3*len(subsets)), layout='constrained')\n",
    "\n",
    "    allbls = [(a, b, p) for a, b in stackconf.antpairs for p in stackconf.pols]\n",
    "\n",
    "    for j, (name, selector) in enumerate(subsets.items()):\n",
    "        ax = axx[j]\n",
    "            \n",
    "        for i, band in enumerate(bands_considered):\n",
    "            for n, night in enumerate(data_jd_ints):\n",
    "                allz = lstmet.get_compressed_zscores(\n",
    "                    zscores, band=band, nights=night, bl_selectors=selector,\n",
    "                    flags = zsq_flags\n",
    "                )\n",
    "                \n",
    "                bplot = ax.boxplot(\n",
    "                    allz, positions = [i-0.3 + 0.05*n], \n",
    "                    showfliers=False, whis=(0,100), showmeans=True,\n",
    "                    tick_labels=[f\"chs {band[0]}-{band[1]}\" if (n==len(data_jd_ints)//2 and j==(len(subsets)-1)) else \"\"], \n",
    "                )\n",
    "                bplot['boxes'][0].set_color(styles[night]['color'])\n",
    "                bplot['boxes'][0].set_linestyle(styles[night]['ls'])\n",
    "                bplot['whiskers'][0].set_color(styles[night]['color'])\n",
    "                bplot['whiskers'][0].set_linestyle(styles[night]['ls'])\n",
    "                bplot['whiskers'][1].set_color(styles[night]['color'])\n",
    "                bplot['whiskers'][1].set_linestyle(styles[night]['ls'])\n",
    "                \n",
    "                bplot['caps'][0].set_color(styles[night]['color'])\n",
    "                bplot['caps'][1].set_color(styles[night]['color'])\n",
    "                \n",
    "                bplot['means'][0].set_marker(\"*\")\n",
    "                bplot['means'][0].set_markerfacecolor(styles[night]['color'])\n",
    "                bplot['means'][0].set_markeredgecolor(styles[night]['color'])\n",
    "                bplot['means'][0].set_markersize(10)\n",
    "                \n",
    "                if i==0 and j==0:\n",
    "                    # Dummy lines for legend\n",
    "                    ax.plot([1,2], [np.nan, np.nan], **styles[night], label=str(night))\n",
    "                    \n",
    "        _set_boxplot_ax_props(len(bands_considered), ax)\n",
    "        ax.set_ylabel(name.replace(\" baselines\", \"\"))\n",
    "    \n",
    "    axx[0].legend(ncols=3)\n",
    "    \n",
    "    return axx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415df566-008c-411a-bcf0-652a530d703d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    box_plot_all_groups(zsquare, cross_stacks);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f54eab-7e8b-4f2d-9f56-9cd4d616aaa9",
   "metadata": {},
   "source": [
    "### Mean Z^2 Over Different Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933726e7-b4e1-4a36-a54d-33a56ee9feb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c298a-7a97-4976-84dd-68c7f89c145b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_zsquare(axis, **kw):\n",
    "    return [\n",
    "        lstmet.reduce_stack_over_axis(\n",
    "            np.ma.mean, lstmet.downselect_zscores(zsq, flags=flg, **kw), axis=axis\n",
    "        )  for zsq, flg in zip(zsquare, zsq_flags)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907412f-4d20-4473-a913-8a1503775394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['band_reduced_mean'] = {}\n",
    "for band in bands_considered:\n",
    "    metrics['band_reduced_mean'][band] = reduce_zsquare(band=band, axis='freqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1494c6b-a640-4b3d-8a8f-a6a5122a09cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['bl_reduced_mean'] = {}\n",
    "allbls = [(a,b,p) for a,b in stackconf.antpairs for p in stackconf.pols]\n",
    "\n",
    "for j, (name, selector) in enumerate(subsets.items()):\n",
    "    metrics['bl_reduced_mean'][name] = reduce_zsquare(bl_selectors=selector, axis='bls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10debe1f-74dc-4f9f-8aa5-596b749f8454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['night_reduced_mean'] = reduce_zsquare(axis='nights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593f6ae-e3f4-4d05-b789-27b384b4ffa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['night_and_bl_reduced_mean'] = {}\n",
    "\n",
    "for j, (name, selector) in enumerate(subsets.items()):    \n",
    "    metrics['night_and_bl_reduced_mean'][name] = reduce_zsquare(bl_selectors=selector, axis=(\"nights\", \"bls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fec29c-2154-4b44-91fb-8448d1eac73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['night_and_band_reduced_mean'] = {}\n",
    "\n",
    "for band in bands_considered:\n",
    "    metrics['night_and_band_reduced_mean'][band] = reduce_zsquare(band=band, axis=('nights', 'freqs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cacff58-e86f-46e0-adae-31c734491603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['bl_and_band_reduced_mean'] = {}\n",
    "\n",
    "for j, (name, selector) in enumerate(subsets.items()):\n",
    "    for band in bands_considered:\n",
    "        metrics['bl_and_band_reduced_mean'][(band, name)] = reduce_zsquare(band=band, bl_selectors=selector, axis=('bls', 'freqs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edd1b0-a47e-4f78-b27d-c88cf5ffbaff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['all_reduced_mean'] = {}\n",
    "\n",
    "for j, (name, selector) in enumerate(subsets.items()):    \n",
    "    for band in bands_considered:\n",
    "        metrics['all_reduced_mean'][(band, name)] = reduce_zsquare(band=band, bl_selectors=selector, axis=('bls', 'freqs', 'nights'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298113bf-abbb-456a-ad51-13c151f1cefe",
   "metadata": {},
   "source": [
    "#### Plot Totally Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872050f-7a20-4839-bcd5-1ad135875e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_styles = {name: {'color': f\"C{i%len(subsets)}\", 'ls': ['-', '--', ':', '-.'][i//4]} for i, name in enumerate(subsets.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87967b6-baf0-4b2d-8e80-0cb59851ef1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    done = set()\n",
    "    for (band, subset_name), means in metrics['all_reduced_mean'].items():\n",
    "        mid = np.mean(band)\n",
    "        size=0 if band[1]-band[0]==200 else (1 if band[1]-band[0] < 1500 else 2)\n",
    "\n",
    "        plt.errorbar(\n",
    "            [np.mean(band)], \n",
    "            means[0], \n",
    "            xerr=[[mid - band[0]]], \n",
    "            marker='ox*'[size], \n",
    "            markersize=8, \n",
    "            **subset_styles[subset_name], \n",
    "            label=subset_name.replace(\"baselines\", \"\") if subset_name not in done else None\n",
    "        )\n",
    "        done.add(subset_name)\n",
    "    plt.legend(ncols=2)\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dcd393-f774-458b-a714-b30fcde3cd0a",
   "metadata": {},
   "source": [
    "#### Plot Reduced over Nights + Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c6f4b-5a3f-4c6b-8371-25adbb6a7b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_baseline_zsq_plot(zscores, stack):\n",
    "    # TODO: need a better cmap to easily see what's \"good\" and \"bad\"\n",
    "    \n",
    "    fig, axx = plt.subplots(len(bands_considered)-3, len(stackconf.pols), sharey=True, figsize=(24, 5*(len(bands_considered)-3)), layout='constrained')\n",
    "    \n",
    "    cmap = mpl.colors.ListedColormap([\"C0\", f\"C1\", f\"C3\"])\n",
    "    for i, band in enumerate(bands_considered):\n",
    "        if band[1] - band[0] > 200:\n",
    "            continue\n",
    "\n",
    "        ax = axx[i]\n",
    "        \n",
    "        mean_zsq = metrics['night_and_band_reduced_mean'][band][0]\n",
    "    \n",
    "        uvws = stack.uvw_array[:stack.Nbls][:, :2]\n",
    "        uvws[uvws[:, 1] < 0] *= -1\n",
    "\n",
    "        for ipol, pol in enumerate(stackconf.pols):\n",
    "            cbar = ax[ipol].scatter(uvws[:, 0], uvws[:, 1], c=mean_zsq[:, ipol], norm=mpl.colors.LogNorm( vmin=1, vmax=1000), marker='H', s=60, cmap=cmap)\n",
    "            ax[ipol].set_title(pol)\n",
    "            ax[ipol].set_aspect(\"equal\", 'datalim')\n",
    "            ax[ipol].set_xlim(-200, 200)\n",
    "            ax[ipol].grid(True)\n",
    "        \n",
    "        ax[0].set_ylabel(str(band))\n",
    "        \n",
    "        plt.colorbar(cbar, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c1f27-2b69-491a-8910-6e67a7acc9f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    make_baseline_zsq_plot(zsquare, cross_stacks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661fba7-a599-4fa4-b308-9ea0cd94eec0",
   "metadata": {},
   "source": [
    "#### Plot Reduced over Nights and bls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4740d-28eb-4394-b32e-1aacda366bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_excess_variance_wrt_freq():\n",
    "    for subset, zsq in metrics['night_and_bl_reduced_mean'].items():\n",
    "        # do the mean over the two LST bins here...\n",
    "        zsq = np.nanmean(zsq, axis=0)\n",
    "        \n",
    "        plt.plot(stackconf.config.datameta.freq_array / 1e6, zsq, label=subset.replace(\"baselines\", \"\"), **subset_styles[subset])\n",
    "        \n",
    "    plt.xlabel(\"Freq [MHz]\")\n",
    "    plt.ylabel(r\"Mean $Z^2$ across Nights, LSTs and Baselines\")\n",
    "    plt.legend(ncols=2)\n",
    "    plt.ylim(7e-1, 100)\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b636d-a4ce-431c-a15f-144a5b22d9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    plot_excess_variance_wrt_freq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaefd51-59e9-40bb-9ace-029db67450ff",
   "metadata": {},
   "source": [
    "#### Plot Reduced over Bls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b067b0-0f47-473f-849e-48b8cb91b8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_reduced_over_bls(zstack):\n",
    "    images = {}\n",
    "\n",
    "    for subset, zsqs in metrics['bl_reduced_mean'].items():\n",
    "        images[subset] = np.ones((len(data_jd_ints), len(zstack.freq_array)), dtype=float) * np.nan\n",
    "\n",
    "        for ijd, jd in enumerate(data_jd_ints):\n",
    "            if jd not in zstack.nights:\n",
    "                continue\n",
    "\n",
    "            jdidx = zstack.nights.tolist().index(jd)\n",
    "            images[subset][ijd] = zsqs[0][jdidx]\n",
    "\n",
    "    nrows = int(np.ceil(len(subsets)/3))\n",
    "\n",
    "    fig, ax = plt.subplots(nrows, 3, sharex=True, sharey=True, layout='constrained', figsize=(14, 3*nrows))\n",
    "\n",
    "    cmap = mpl.colors.ListedColormap([\"C0\", \"C1\", \"C3\"])\n",
    "\n",
    "    for i, (key, img) in enumerate(images.items()):\n",
    "        axx = ax.flatten()[i]\n",
    "        plt.sca(axx)\n",
    "\n",
    "        cbar = plt.imshow(\n",
    "            img, norm=mpl.colors.LogNorm( vmin=1, vmax=1000),\n",
    "            origin='lower',\n",
    "            extent=(\n",
    "                zstack.freq_array.min()/1e6, \n",
    "                zstack.freq_array.max()/1e6,\n",
    "                0,\n",
    "                len(data_jd_ints)\n",
    "            ),\n",
    "            cmap=cmap, aspect='auto',\n",
    "            interpolation='none',\n",
    "        )\n",
    "\n",
    "        axx.yaxis.set_ticks(np.arange(img.shape[0]) +0.5)\n",
    "        axx.yaxis.set_ticklabels(data_jd_ints)\n",
    "\n",
    "        axx.set_title(key.replace(\"baselines\", \"\"), pad=-3)\n",
    "\n",
    "        if i < 3:\n",
    "            axx.tick_params('x', labeltop=True, labelbottom=False, top=True)\n",
    "\n",
    "    for j in range(i+1, ax.size):\n",
    "        ax.flatten()[j].axis('off')\n",
    "\n",
    "    cbar = plt.colorbar(cbar, ax = ax)\n",
    "    cbar.set_label(r\"Mean $Z^2$ over bl subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee644b1c-0ae0-4e0c-a7f7-c6e7f4d860e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    plot_reduced_over_bls(zsquare[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66744163-0286-4fbd-a26f-d0774b3baa71",
   "metadata": {},
   "source": [
    "### Plot Selection of the Worst Visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a6d8e-99c7-4456-b42e-2a376cbac976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_visibilities_per_type(\n",
    "    lstbin_blpols: list[tuple[int, tuple[int, int, str]]], \n",
    "    stacks: list[UVData],\n",
    "    stats: list[lstmet.LSTBinStats],\n",
    "    auto_stats: list[lstmet.LSTBinStats],\n",
    "    comments: list[str],\n",
    "    zscores: list[lstbin.binning.LSTStack],\n",
    "    freq_range=None | tuple[float, float] | list[tuple[int, int]], \n",
    "    label=None, \n",
    "    yrange=None,\n",
    "    alpha=0.5,\n",
    "):\n",
    "    all_figs = []\n",
    "    \n",
    "    lststyle = dict(color='k', lw=3, zorder=-1)\n",
    "    meta = stackconf.config.datameta\n",
    "    \n",
    "    # Get a mask that says which channels are *simultaneously* inpainted.\n",
    "    simul_inpmask = np.zeros(meta.Nfreqs, dtype=bool)\n",
    "    for band in inpaint_bands:\n",
    "        simul_inpmask[band] = True\n",
    "\n",
    "    if isinstance(freq_range, tuple):\n",
    "        mask = (meta.freq_array >= freq_range[0]) & (meta.freq_array < freq_range[1])\n",
    "        freqs=meta.freq_array[mask]/1e6\n",
    "    else:\n",
    "        mask = slice(None)\n",
    "        freqs = meta.freq_array/1e6\n",
    "\n",
    "    handles = []\n",
    "    for jdint, style in styles.items():\n",
    "        handles.append(mpl.lines.Line2D([0], [0], label=str(jdint), alpha=alpha, **style))\n",
    "\n",
    "            \n",
    "    for i, (comment, (lstidx, blpol)) in enumerate(zip(comments, lstbin_blpols)):\n",
    "        if isinstance(freq_range, list):\n",
    "            this_range = freq_range[i]\n",
    "            \n",
    "            # pad the range a bit\n",
    "            this_range = (max(this_range[0] - 100, 0), min(this_range[1]+100, 1536))\n",
    "            mask = slice(this_range[0], this_range[1])\n",
    "            freqs = meta.freq_array[mask]/1e6\n",
    "            \n",
    "        stack = stacks[lstidx]\n",
    "        zscore = zscores[lstidx]\n",
    "        \n",
    "        rawd = stack.get_data(blpol)[:, mask]        \n",
    "        rawf = stack.get_flags(blpol)[:, mask]\n",
    "        rawn = stack.get_nsamples(blpol)[:, mask]\n",
    "        \n",
    "        if np.all(rawn >= 0):\n",
    "            inp = rawf & simul_inpmask[mask]\n",
    "        else:\n",
    "            inp = rawn < 0\n",
    "        \n",
    "        lstf = stats[lstidx].flags[blpol][mask]\n",
    "        lstd = stats[lstidx].mean[blpol][mask]\n",
    "        \n",
    "        lstmed = lstd  # actually mean\n",
    "        \n",
    "        iap = zscore.antpairs.index(blpol[:2])\n",
    "        ipol = zscore.pols.index(blpol[2])\n",
    "        \n",
    "        zsq = zscore.metrics[:, iap, mask, ipol]\n",
    "        \n",
    "        if np.all(lstf):\n",
    "            print(\"ALL FLAGGED\")\n",
    "            continue\n",
    "            \n",
    "        fig, ax = plt.subplots(\n",
    "            4, 2, \n",
    "            sharex=True, figsize=(15, 8), \n",
    "            constrained_layout=True, gridspec_kw={'height_ratios': (2,1,2,1)}\n",
    "        )\n",
    "        \n",
    "        mag = np.where(rawf, np.nan, np.abs(rawd))\n",
    "        rl = np.where(rawf, np.nan, rawd.real)\n",
    "        im = np.where(rawf, np.nan, rawd.imag)\n",
    "        \n",
    "        maglstbin = np.where(lstf, np.nan, np.abs(lstd))\n",
    "        rllstbin = np.where(lstf, np.nan, lstd.real)\n",
    "        imlstbin = np.where(lstf, np.nan, lstd.imag)\n",
    "        \n",
    "        rllstbin_med = np.where(lstf, np.nan, lstmed.real)\n",
    "        imlstbin_med = np.where(lstf, np.nan, lstmed.imag)\n",
    "                \n",
    "        pred_std = np.sqrt(lstmet.get_nightly_predicted_variance(blpol, stack=stack, auto_stats = auto_stats[lstidx]) / 2)[:, mask]\n",
    "        \n",
    "        ax[0, 0].plot(freqs, maglstbin, **lststyle)\n",
    "        ax[0, 1].plot(freqs, rllstbin, **lststyle)                \n",
    "        ax[2, 1].plot(freqs, imlstbin, **lststyle)\n",
    "        \n",
    "        for jdidx, jdint in enumerate(stack.nights):\n",
    "            style = styles[jdint]\n",
    "\n",
    "            if np.all(rawf[jdidx]):\n",
    "                continue\n",
    "\n",
    "            thisinp = inp[jdidx]\n",
    "            if np.any(thisinp):\n",
    "                inp_ranges = consecutive(np.nonzero(thisinp)[0])\n",
    "            else:\n",
    "                inp_ranges = []\n",
    "            \n",
    "            # Amplitude and Phase\n",
    "            ax[0, 0].plot(freqs, mag[jdidx], **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[0, 0].fill_between(freqs[rng[0]:rng[1]], mag[jdidx, rng[0]:rng[1]], maglstbin[rng[0]:rng[1]], color=style['color'], alpha=0.2)\n",
    "                \n",
    "            ax[1, 0].plot(freqs, mag[jdidx] - maglstbin, **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[1, 0].fill_between(freqs[rng[0]:rng[1]], mag[jdidx, rng[0]:rng[1]] - maglstbin[rng[0]:rng[1]], 0, color=style['color'], alpha=0.2)\n",
    "            \n",
    "            ax[2, 0].plot(freqs, zsq[jdidx], **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[2, 0].fill_between(freqs[rng[0]:rng[1]], zsq[jdidx, rng[0]:rng[1]], 0, color=style['color'], alpha=0.2)\n",
    "\n",
    "            # Real / Imag\n",
    "            ax[0, 1].plot(freqs, rl[jdidx], **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[0, 1].fill_between(freqs[rng[0]:rng[1]], rl[jdidx, rng[0]:rng[1]], rllstbin[rng[0]:rng[1]], color=style['color'], alpha=0.2)\n",
    "            \n",
    "            rldiff = (rl[jdidx] - rllstbin_med)/pred_std[jdidx]\n",
    "            ax[1, 1].plot(freqs, rldiff, **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[1,1].fill_between(freqs[rng[0]:rng[1]], rldiff[rng[0]:rng[1]], 0, color=style['color'], alpha=0.2)\n",
    "            \n",
    "            ax[2, 1].plot(freqs, im[jdidx], **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[2, 1].fill_between(freqs[rng[0]:rng[1]], im[jdidx, rng[0]:rng[1]], imlstbin[rng[0]:rng[1]], color=style['color'], alpha=0.2)\n",
    "            \n",
    "            imdiff = (im[jdidx] - imlstbin_med)/pred_std[jdidx]\n",
    "            ax[3, 1].plot(freqs, imdiff, **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[3,1].fill_between(freqs[rng[0]:rng[1]], imdiff[rng[0]:rng[1]], 0, color=style['color'], alpha=0.2)\n",
    "\n",
    "            if yrange:\n",
    "                ax[0, 0].set_ylim(yrange)\n",
    "\n",
    "        ax[1,1].axhline(4, color='gray', ls='--')\n",
    "        ax[1,1].axhline(-4, color='gray', ls='--')\n",
    "\n",
    "        ax[3,1].axhline(4, color='gray', ls='--')\n",
    "        ax[3,1].axhline(-4, color='gray', ls='--')\n",
    "            \n",
    "        bl_coords = stackconf.config.datameta.antpos_enu[blpol[0]] - stackconf.config.datameta.antpos_enu[blpol[1]]\n",
    "        \n",
    "        fig.suptitle(\n",
    "            f\"Baseline: {blpol} [{bl_coords[0]:.1f}-EW, {bl_coords[1]:.1f}-NS]. \"\n",
    "            f\"LST = {stackconf.lst_grid[0]*12/np.pi:.5f} hr.\"\n",
    "        )\n",
    "        ax[-1, 0].set_xlabel(\"Frequency [MHz]\")\n",
    "        ax[-1, 1].set_xlabel(\"Frequency [MHz]\")\n",
    "        \n",
    "        ax[0, 0].set_ylabel(\"Magnitude\")\n",
    "        ax[0, 1].set_ylabel(\"Real Part\")\n",
    "        \n",
    "        ax[1, 0].set_ylabel(\"Magnitude Diff\")\n",
    "        ax[1, 1].set_ylabel(\"Real Z-score\")\n",
    "        ax[1, 1].set_ylim(-7, 7)\n",
    "        \n",
    "        ax[2, 0].set_ylabel(r\"$Z^2$\")\n",
    "        ax[2, 0].set_yscale('log')\n",
    "        ax[2, 0].set_ylim(1e-1,)\n",
    "        \n",
    "        ax[2, 1].set_ylabel(\"Imag Part\")\n",
    "        \n",
    "        #ax[3, 0].set_ylabel(\"Phase Diff\")\n",
    "        ax[3, 1].set_ylabel(\"Imag Z-score\")\n",
    "        ax[3, 1].set_ylim(-7, 7)\n",
    "        ax[0, 0].legend(handles=handles, ncols=5)\n",
    "\n",
    "        ax[0,1].text(0.95, 0.95, comment, transform=ax[0,1].transAxes, ha='right', va='top')\n",
    "\n",
    "        for axx in ax.flatten():\n",
    "            for line in range(0, 1536, 200):\n",
    "                axx.axvline(meta.freq_array[line]/1e6, color='gray', alpha=0.4)\n",
    "            axx.set_xlim(freqs[0], freqs[-1])\n",
    "            \n",
    "        all_figs.append(fig)\n",
    "        \n",
    "    return all_figs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe47d99-b5b3-4efa-aa53-25ee8429717e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_worst_mean_over_each_band(zscores, n=1, autopols_only=True):\n",
    "    bad_fellas = {}\n",
    "\n",
    "    nights0 = [data_jd_ints.index(jd) for jd in zscores[0].time_array[::zscores[0].Nbls].astype(int)]\n",
    "    nights1 = [data_jd_ints.index(jd) for jd in zscores[1].time_array[::zscores[1].Nbls].astype(int)]\n",
    "    \n",
    "    if autopols_only:\n",
    "        polidx = [i for i, p in enumerate(stackconf.pols) if len(set(p))==1]\n",
    "    else:\n",
    "        polidx = np.arange(len(stackconf.pols))\n",
    "        \n",
    "    npols = len(polidx)\n",
    "    \n",
    "    newmeans = {band: np.ones((len(zscores), len(data_jd_ints), len(stackconf.antpairs), npols))*np.nan for band in metrics['band_reduced_mean']}\n",
    "    \n",
    "    for band, zsqs in metrics['band_reduced_mean'].items():\n",
    "        # zsqs is length(lstbins), where each is an array of shape (nights, antpairs, pols)\n",
    "        # however, the number of nights for each lstbin could be different, so make them the same here....\n",
    "        newmeans[band][0, nights0] = zsqs[0][..., polidx]\n",
    "        newmeans[band][1, nights1] = zsqs[1][..., polidx]\n",
    "        \n",
    "    lst_night_bl_pols = [(lst, jd, bl + (pol,)) for lst in range(len(zscores)) for jd in data_jd_ints for bl in stackconf.antpairs for j, pol in enumerate(stackconf.pols) if j in polidx]\n",
    "    \n",
    "    for band, zsq in newmeans.items():\n",
    "        zsq = np.where(np.isnan(zsq.flatten()), -1, zsq.flatten())\n",
    "        \n",
    "        worst_idx = np.argpartition(zsq, -n)[-n:]\n",
    "        worst_zsq = zsq[worst_idx]\n",
    "        worst_idx = worst_idx[np.argsort(-worst_zsq)]\n",
    "        \n",
    "        for idx, z in zip(worst_idx, worst_zsq):\n",
    "            lst, jd, bl = lst_night_bl_pols[idx]\n",
    "            \n",
    "            if (lst, bl) not in bad_fellas:\n",
    "                bad_fellas[(lst, bl)] = []\n",
    "                \n",
    "            bad_fellas[(lst, bl)].append((jd, z, fr\"Worst $Z^2$ in band {band[0]}-{band[1]}\", band))\n",
    "\n",
    "    return bad_fellas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa5d88-9894-4ad1-87cc-e8bc2d0ae345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_worst_mean_for_continuously_bad_stuff(zscores, n=1, autopols_only=True):\n",
    "    \n",
    "    bad_fellas = {}\n",
    "    \n",
    "    chsizes = [(1, 2), (2, 10), (10, 20), (20, 50), (50, 100), (100, 1536)]\n",
    "    sized = {ch: {} for ch in chsizes}\n",
    "    for k, v in allbad.items():\n",
    "        s = k[-1] - k[-2]  # size of chunk\n",
    "        if s == 1:\n",
    "            continue\n",
    "        \n",
    "        for i, ch in enumerate(chsizes):\n",
    "            if ch[0] <= s < ch[1]:\n",
    "                sized[ch][k] = v\n",
    "\n",
    "    if autopols_only:\n",
    "        polidx = set([i for i, p in enumerate(stackconf.pols) if len(set(p))==1])\n",
    "    else:\n",
    "        polidx = set(range(len(stackconf.pols)))\n",
    "        \n",
    "    for chsize, thesebads in sized.items():\n",
    "        if not thesebads:\n",
    "            continue\n",
    "            \n",
    "        keys = [k for k in thesebads.keys() if k[3] in polidx]\n",
    "        meanz = np.array([np.nanmean(v) for k, v in thesebads.items() if k[3] in polidx])\n",
    "        \n",
    "        nn = min(n, len(meanz))\n",
    "        worst_idx = np.argpartition(meanz, -nn)[-nn:]\n",
    "        worst_zsq = meanz[worst_idx]\n",
    "        worst_idx = worst_idx[np.argsort(-worst_zsq)]\n",
    "\n",
    "        for idx, z in zip(worst_idx, worst_zsq):\n",
    "            lst, a, b, pol, jdint, low, high = keys[idx]\n",
    "            bl = (a, b, stackconf.pols[pol])\n",
    "            \n",
    "            if (lst, bl) not in bad_fellas:\n",
    "            \n",
    "                bad_fellas[(lst, bl)] = []\n",
    "\n",
    "            bad_fellas[(lst, bl)].append((int(jdint), z, fr\"Worst $Z^2$ over {chsize[0]}-{chsize[1]} channels\",(low, high)))\n",
    "    return bad_fellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09d780-5163-4167-9f2f-823c2ad75fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_worst_continuous_bad_zscore(zscores, n=1, autopols_only=True):\n",
    "    bad_fellas = {}\n",
    "    nights0 = [data_jd_ints.index(jd) for jd in zscores[0].time_array[::zscores[0].Nbls].astype(int)]\n",
    "    nights1 = [data_jd_ints.index(jd) for jd in zscores[1].time_array[::zscores[1].Nbls].astype(int)]\n",
    "    \n",
    "    smallbands = [b for b in bands_considered if b[1] - b[0] <= 200]\n",
    "    \n",
    "    if autopols_only:\n",
    "        polidx = [i for i, p in enumerate(stackconf.pols) if len(set(p))==1]\n",
    "    else:\n",
    "        polidx = np.arange(len(stackconf.pols))\n",
    "        \n",
    "    npols = len(polidx)\n",
    "\n",
    "    newmeans = np.ones(\n",
    "        (len(smallbands), len(zscores), len(data_jd_ints), len(stackconf.antpairs), npols)\n",
    "    )*np.nan\n",
    "    \n",
    "    for i, band in enumerate(smallbands):\n",
    "        zsqs = metrics['band_reduced_mean'][band]\n",
    "        # zsqs is length(lstbins), where each is an array of shape (nights, antpairs, pols)\n",
    "        # however, the number of nights for each lstbin could be different, so make them the same here....\n",
    "        newmeans[i, 0, nights0] = zsqs[0][..., polidx]\n",
    "        newmeans[i, 1, nights1] = zsqs[1][..., polidx]\n",
    "\n",
    "    lst_night_bl_pols = [(lst, jd, bl + (pol,)) for lst in range(len(zscores)) for jd in data_jd_ints for bl in stackconf.antpairs for j, pol in enumerate(stackconf.pols) if j in polidx]\n",
    "\n",
    "    zsq = np.nanmin(newmeans, axis=0)\n",
    "    \n",
    "    zsq = np.where(np.isnan(zsq).flatten(), -1, zsq.flatten())\n",
    "    \n",
    "    nn = min(n, len(zsq))\n",
    "    worst_idx = np.argpartition(zsq, -nn)[-nn:]\n",
    "    worst_zsq = zsq[worst_idx]\n",
    "    worst_idx = worst_idx[np.argsort(-worst_zsq)]\n",
    "\n",
    "    for idx, z in zip(worst_idx, worst_zsq):\n",
    "        lst, jd, bl = lst_night_bl_pols[idx]\n",
    "\n",
    "        if (lst, bl) not in bad_fellas:\n",
    "            bad_fellas[(lst, bl)] = []\n",
    "\n",
    "        bad_fellas[(lst, bl)].append((jd, z, fr\"Worst min($Z^2$) over entire band\", (0, 1536)))\n",
    "\n",
    "    return bad_fellas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c78779-851d-4fc5-aa11-dfc9eeafa809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bad_inpaints(zscores, n=1, autopols_only=True):\n",
    "    \n",
    "    bad_fellas = {}\n",
    "    \n",
    "    nights = [zsq.nights.tolist() for zsq in zscores]\n",
    "\n",
    "    if autopols_only:\n",
    "        polidx = set([i for i, p in enumerate(stackconf.pols) if len(set(p))==1])\n",
    "    else:\n",
    "        polidx = set(range(len(stackconf.pols)))\n",
    "\n",
    "    chsizes = [(2, 5), (5, 10), (10, 20)]    \n",
    "    sized = {ch: {} for ch in chsizes}\n",
    "    for k, v in inpainted_regions.items():\n",
    "        s = k[-1] - k[-2]  # size of chunk\n",
    "        if s == 1:\n",
    "            continue\n",
    "        \n",
    "        for i, ch in enumerate(chsizes):\n",
    "            if ch[0] <= s < ch[1]:\n",
    "                sized[ch][k] = v\n",
    "                \n",
    "    for chsize, bads in sized.items():\n",
    "        \n",
    "        \n",
    "        keys = [k for k in bads.keys() if k[3] in polidx]\n",
    "        \n",
    "        meanz = np.array([\n",
    "            np.nanmean(zscores[lst].metrics[nights[lst].index(jdint), zscores[lst].antpairs.index((a,b)), low:high, pol]) \n",
    "            for (lst, a, b, pol, jdint, low, high) in bads.keys() if pol in polidx\n",
    "        ])\n",
    "        \n",
    "        nn = min(n, len(meanz))\n",
    "        worst_idx = np.argpartition(meanz, -nn)[-nn:]\n",
    "        worst_zsq = meanz[worst_idx]\n",
    "        worst_idx = worst_idx[np.argsort(-worst_zsq)]\n",
    "\n",
    "        for idx, z in zip(worst_idx, worst_zsq):\n",
    "            lst, a, b, pol, jdint, low, high = keys[idx]\n",
    "            bl = (a, b, stackconf.pols[pol])\n",
    "            \n",
    "            if (lst, bl) not in bad_fellas:\n",
    "            \n",
    "                bad_fellas[(lst, bl)] = []\n",
    "\n",
    "            bad_fellas[(lst, bl)].append((int(jdint), z, fr\"Worst inpainted $Z^2$ for {chsize[0]}-{chsize[1]} chans\", (low, high)))\n",
    "    return bad_fellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dd92c-8099-45fe-91e8-6ecc727a9f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    worst_mean_over_each_band = get_worst_mean_over_each_band(zsquare, n=plot_n_worst)\n",
    "    worst_mean_for_continously_bad = get_worst_mean_for_continuously_bad_stuff(zsquare, n=plot_n_worst)\n",
    "    worst_minimum_zscores_over_bands = get_worst_continuous_bad_zscore(zsquare, n=plot_n_worst)\n",
    "    worst_inpainted_regions = get_bad_inpaints(zsquare, n=plot_n_worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e810f-721a-4113-a94a-c58488e12999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    # Merge all the things that we want to take a closer look at\n",
    "    badstuff = {}\n",
    "\n",
    "    for dct in (worst_mean_over_each_band, worst_mean_for_continously_bad, worst_minimum_zscores_over_bands, worst_inpainted_regions):\n",
    "        for k, v in dct.items():\n",
    "            if k not in badstuff:\n",
    "                badstuff[k] = []\n",
    "\n",
    "            badstuff[k].extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d30300-47df-4748-b139-bc65dd026490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    freq_ranges = [sum((vv[-1] for vv in v), start=()) for v in badstuff.values()]\n",
    "    freq_ranges = [(min(v), max(v)) for v in freq_ranges]\n",
    "\n",
    "    plot_visibilities_per_type(\n",
    "        lstbin_blpols= list(badstuff.keys()), \n",
    "        stacks= cross_stacks,\n",
    "        stats= cross_stats,\n",
    "        comments=[\"\\n\".join([f\"{vv[-2]}: {vv[0]}\" for vv in v]) for v in badstuff.values()],\n",
    "        freq_range=freq_ranges,\n",
    "        alpha=0.5,\n",
    "        zscores=zsquare,\n",
    "        auto_stats=auto_stats\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41bf66-9ebe-45dd-8c68-0a85754f5494",
   "metadata": {},
   "source": [
    "### Write Out Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f0b66-50b5-4557-af8f-98276692c89d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write out the \"bad\" data\n",
    "fname = get_fname(kind='LSTBIN-METRICS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c73052-e21e-4863-a918-53bf6b3583a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save_metric_data:\n",
    "    def write_metric(grp, metric: dict[str, list[np.ndarray]]):\n",
    "        for key in metric:\n",
    "            _grp = grp.create_group(str(key))\n",
    "\n",
    "            for i, lstbin in enumerate(metric[key]):\n",
    "                _grp[f'zsqmean-{i}'] = lstbin\n",
    "\n",
    "\n",
    "    with h5py.File(outdir / fname, 'w') as fl:\n",
    "\n",
    "        meta = fl.create_group(\"meta\")\n",
    "        meta['pols'] = stackconf.pols\n",
    "        meta['ant1'] = np.array([a for a, b in stackconf.antpairs])\n",
    "        meta['ant2'] = np.array([b for a, b in stackconf.antpairs])\n",
    "        meta['freqs'] = stackconf.config.datameta.freq_array\n",
    "        nights = meta.create_group(\"nights\")\n",
    "        for i, zsq in enumerate(zsquare):\n",
    "            nights[str(i)] = zsq.nights\n",
    "\n",
    "        mgrp = fl.create_group(\"metrics\")\n",
    "\n",
    "        for name, mtrc in metrics.items():\n",
    "            if name=='night_reduced_mean':\n",
    "                # night reduced mean is different -- simply an array\n",
    "                nrm = mgrp.create_group(\"night_reduced_mean\")\n",
    "                for i, val in enumerate(mtrc):\n",
    "                    nrm[f'zsqmean-{i}'] = val\n",
    "            else:\n",
    "                write_metric(mgrp.create_group(name), mtrc)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f27a43-3dfe-4823-a73b-42f01ff0c823",
   "metadata": {},
   "source": [
    "## Notebook Metadata and Software Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002e09a-a26a-4aaa-a29b-e5d64279b0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_metadata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

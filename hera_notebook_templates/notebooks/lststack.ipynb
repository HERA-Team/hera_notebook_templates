{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48edc0db",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Configuration</a></span></li><li><span><a href=\"#Do-the-binning\" data-toc-modified-id=\"Do-the-binning-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Do the binning</a></span></li><li><span><a href=\"#LST-bin-the-Autos\" data-toc-modified-id=\"LST-bin-the-Autos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>LST-bin the Autos</a></span><ul class=\"toc-item\"><li><span><a href=\"#In-painted-Mode\" data-toc-modified-id=\"In-painted-Mode-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>In-painted Mode</a></span></li><li><span><a href=\"#Flagged-Mode\" data-toc-modified-id=\"Flagged-Mode-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Flagged-Mode</a></span></li><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#Cross-Pairs\" data-toc-modified-id=\"Cross-Pairs-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Cross-Pairs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84a7b1",
   "metadata": {},
   "source": [
    "# LST-Bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543efff3",
   "metadata": {},
   "source": [
    "**by Steven Murray**, last updated 27th Mar, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96338e3d",
   "metadata": {},
   "source": [
    "This notebook performs LST-binning, producing a **single output file**. The input to this notebook consists of two configuration files, and one index:\n",
    "\n",
    "1. A `fileconf`, which is *produced* by `hera_cal.lstbin_simple.make_lst_bin_config_file()` run over a set of raw files. This file lists all the raw files that correspond to all the particular bins, which makes it quick for this notebook to read them in.\n",
    "2. A binning configuration file, `config`, that specifies all the parameters to use when performing the binning itself.\n",
    "3. The file index that corresponds to the LST bins that will be saved to the output file in _this_ notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f6474",
   "metadata": {},
   "source": [
    "The notebook then proceeds to do essentially the same thing as `hera_cal.lstbin_simple.lst_bin_files_single_outfile`, but with extra plotting and inspection stops along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e45f4c5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731e8f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from time import time as _time\n",
    "import resource\n",
    "from collections import UserDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import h5py\n",
    "import attrs\n",
    "\n",
    "from scipy import linalg\n",
    "from hera_filters import dspec\n",
    "\n",
    "from pyuvdata import UVData\n",
    "from hera_cal import lst_stack as lstbin\n",
    "from hera_cal.lst_stack.config import LSTConfig\n",
    "from hera_cal.red_groups import RedundantGroups\n",
    "from hera_cal.lst_stack import metrics as lstmet\n",
    "from hera_cal.lst_stack import stats as lststat\n",
    "from hera_cal import vis_clean, redcal, abscal, utils\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a48ff-2605-42a7-b3e3-5eeb97bbf031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = _time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfcdbd2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d16c3d",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "fileconf: str = \"/lustre/aoc/projects/hera/h6c-analysis/IDR2/lstbin-outputs/redavg-smoothcal-notebook/file-config.h5\"\n",
    "fileidx: int = 380\n",
    "\n",
    "papermill_input_path: str = \"\"\n",
    "papermill_output_path: str = \"\"\n",
    "\n",
    "# The following are defaults that can be overwritten at execution time (preferably by a YAML file)\n",
    "save_lstbin_data: bool = True\n",
    "save_metric_data: bool = True\n",
    "plot_n_worst: int = 5\n",
    "do_simultaneous_inpainting: bool = True\n",
    "do_extra_flagging: bool = True\n",
    "do_lstcal: bool = True\n",
    "\n",
    "outdir: str = \".\"\n",
    "bl_chunk_size: int = 0\n",
    "rephase: bool = True\n",
    "vis_units: str = \"Jy\"\n",
    "fname_format: str = '{inpaint_mode}/zen.{kind}.{lst:7.5f}.sum.uvh5'\n",
    "overwrite: bool = True\n",
    "write_med_mad: bool = False\n",
    "do_inpainted_average: bool = False\n",
    "freq_min: float = 0.0\n",
    "freq_max: float = 0.0\n",
    "history: str = \"\"\n",
    "plot_every: int = 1\n",
    "\n",
    "# In-painting config\n",
    "delay_filter_horizon: float     = 1.0\n",
    "delay_filter_standoff: float    = 0.0    # ns\n",
    "delay_filter_mindelay: float    = 150.0  # ns\n",
    "delay_filter_eigencutoff: float = 1e-12\n",
    "# inpaint_regularization: float   = 1e-5   # reasonable values are between 1e-2 and 1e-5\n",
    "inpaint_mindelay: float         = 500.0  # ns\n",
    "inpaint_cache_dir: str         = \"\"  # leave empty to NOT write cache to file. If a file, all LST-bins should use the same file so they can take advantage of it.\n",
    "\n",
    "# Flagging Configuration\n",
    "zscore_threshold: float = 5              # Value of |Z| above which data are flagged. \n",
    "iterative_flagging_factor: float = 1.5   # When flagging on |Z|^2, the worst offender (W) is flagged, and any other offenders > W/iterative_flagging_factor\n",
    "watershed_threshold: float = 3           # Value of |Z| above which data surrounding other flagged data will be flagged.     \n",
    "max_flagging_iterations: int = 15             # Maximum number of iterations to perform when flagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f777f41-737c-441d-a7dc-6f02ac402959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: using the filter cache doesn't work yet, because the keys are tuples, not strings\n",
    "class FilterCache(UserDict):\n",
    "    def __init__(self, cachedir: str | Path | None = None, *args, **kwargs):\n",
    "        if cachedir:\n",
    "            self._cachedir = Path(cachedir)\n",
    "        else:\n",
    "            self._cachedir = None\n",
    "        \n",
    "        super().__init__(*args,**kwargs)\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        try:\n",
    "            return super().__getitem__(item)\n",
    "        except KeyError as e:\n",
    "            if self._cachedir is None:\n",
    "                raise\n",
    "            \n",
    "            possible_keys = [pth.name for pth in self._cachedir.glob(\"*\")]\n",
    "            \n",
    "            if item in possible_keys:\n",
    "                with (self._cachedir / item).open('rb') as fl:\n",
    "                    out = pickle.load(fl)\n",
    "                self[item] = out\n",
    "                return out\n",
    "            \n",
    "            raise\n",
    "                 \n",
    "    def __setitem__(self, item, value):\n",
    "        if self._cachedir is not None:\n",
    "            with (self._cachedir / item).open('wb') as fl:\n",
    "                pickle.dump(fl, value)\n",
    "            \n",
    "        super().__setitem__(item, value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd23f5e-2cb1-4771-a0fb-ab8c78a88435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameter changes for typing\n",
    "outdir = Path(outdir)\n",
    "if freq_max <= 0.0:\n",
    "    freq_max = None\n",
    "if freq_min <= 0.0:\n",
    "    freq_min = None\n",
    "if bl_chunk_size <= 0:\n",
    "    bl_chunk_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2e877-b304-4c2f-8b92-2e82e9323d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_plots = (fileidx % plot_every) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117ac48-9b06-4362-b6e5-954fe4e0ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_plots or save_metric_data:\n",
    "    get_metrics = True\n",
    "else:\n",
    "    get_metrics = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396d118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fileconf = Path(fileconf)\n",
    "assert fileconf.exists() and fileconf.is_file(), \"The input file-configuration file is not a file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25effb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stackconf = LSTConfig.from_file(fileconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a5f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The LST grid was configured with these parameters: \\n\")\n",
    "for key, val in attrs.asdict(stackconf.config).items():\n",
    "    if key != 'data_files':\n",
    "        print(f\"  {key:>36}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcfdf53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The raw files have the following properties: \\n\")\n",
    "for key, val in stackconf.properties.items():\n",
    "    print(f\"  {key:>25}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f5b1c-dcd2-49c1-b40e-de401b8a3bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stackconf = stackconf.at_single_outfile(fileidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc5f4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"LST bin edges considered in this notebook (file index {fileidx}):\")\n",
    "print(f\"  {stackconf.lst_grid_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ad3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Raw files used in this notebook (for all bins): \\n\")\n",
    "for fl in stackconf.matched_files:\n",
    "    print(fl.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fda3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"The data has {len(stackconf.autopairs + stackconf.antpairs)} ant-pairs, and {stackconf.pols} polarizations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815429a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outdir = Path(outdir)\n",
    "if not outdir.exists():\n",
    "    outdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff075977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Writing output files to: \\n  {outdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf225cc-f865-4945-9986-83bd9375938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_simultaneous_inpainting and do_inpainted_average:\n",
    "    raise ValueError(\"Cannot do both simultaneous inpainting and per-day inpainted averaging\")\n",
    "    \n",
    "if do_inpainted_average and stackconf.inpaint_files is None:\n",
    "    raise ValueError(\"Cannot do per-night inpainted average without inpainted files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298493de-7f6a-4e24-bdc6-b62340e7a7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split up the baselines into chunks that will be LST-binned together.\n",
    "# This is just to save on RAM.\n",
    "if bl_chunk_size is None:\n",
    "    bl_chunk_size = len(stackconf.antpairs)\n",
    "else:\n",
    "    bl_chunk_size = min(bl_chunk_size, len(stackconf.antpairs))\n",
    "\n",
    "n_bl_chunks = int(np.ceil(len(stackconf.antpairs) / bl_chunk_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d95ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_fname = lstbin.format_outfile_name(\n",
    "    fname_format=fname_format, lst=stackconf.lst_grid_edges[0], inpaint_mode=True,\n",
    "    pols=stackconf.pols, lst_branch_cut=stackconf.properties[\"lst_branch_cut\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0176d-1e50-45a6-a8c7-07b1f4737cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_INPAINT_CACHE_ = FilterCache(inpaint_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9274f-ed67-44a0-ac36-4e5a42b672ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reds_with_pols = RedundantGroups.from_antpos(antpos={i: pos for i, pos in enumerate(stackconf.config.datameta.antpos_enu)}, pols=stackconf.pols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04b13d-1793-4169-ba1c-0d069ba31ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_metadata():\n",
    "    # A function that prints metadata about the notebook\n",
    "    print(\"Software Versions Used: \")\n",
    "    for repo in ['numpy', 'scipy', 'astropy', 'hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata']:\n",
    "        mdl = importlib.import_module(repo)\n",
    "        print(f'{repo:>25}: {mdl.__version__}')\n",
    "        \n",
    "    print(\"Run by: \", end='')\n",
    "    os.system(\"whoami\");\n",
    "\n",
    "    print(f\"Run on {datetime.now()}\")\n",
    "    print(f\"Execution of notebook took: {(_time() - start_time)/60.0:.2f} minutes\")\n",
    "    print(f\"Peak memory in this notebook run: {resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024**2:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(set(sum((x.tolist() for x in stackconf.time_indices), start=[]))) != stackconf.n_lsts:\n",
    "    print(\"LST-Stacking for files where not all of the LST-bins have associated data is not yet supported.\")\n",
    "    print_metadata()\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6530710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this notebook is making plots, and is being run through PAPERMILL, output an empty\n",
    "# file that tells the execution script to save a copy of the output notebook to the\n",
    "# public-facing notebook directory.\n",
    "if papermill_output_path and make_plots:\n",
    "    pth = Path(f\"{papermill_output_path}.hasplots\")\n",
    "    pth.touch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb2696",
   "metadata": {},
   "source": [
    "## Define Stacking/Averaging Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cfdd5",
   "metadata": {},
   "source": [
    "Define and initialize the output files that we will write in this notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d17ae",
   "metadata": {},
   "source": [
    "Now, define a function that uses the configuration we've established and performs LST-binning for a subset of baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572b3ad-fc1f-4818-9887-34f18ba537fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stack_blchunk(bl_chunk: int | str):\n",
    "    \"\"\"Process a single chunk of baselines.\"\"\"\n",
    "    stacks: list[UVData] = lstbin.binning.lst_bin_files_from_config(\n",
    "        stackconf,\n",
    "        bl_chunk_to_load=bl_chunk,\n",
    "        nbl_chunks=n_bl_chunks,\n",
    "    )\n",
    "\n",
    "    rdcs = []\n",
    "    for lstidx, stack in enumerate(stacks):\n",
    "\n",
    "        rdc = lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=False,\n",
    "            get_mad=write_med_mad and not (do_inpainted_average or do_simultaneous_inpainting),  # MED/MAD gotten later if doing inpainting\n",
    "        )\n",
    "        rdcs.append(rdc)\n",
    "                     \n",
    "    return stacks, rdcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f96f4e-cb89-436f-ac12-f220e6661f38",
   "metadata": {},
   "source": [
    "## Plotting Style Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ea566-e388-4c5a-b330-3a1db23290ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_jd_ints = sorted({int(meta.times[0]) for meta in stackconf.matched_metas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f4fb7-5c04-478a-a715-f6ef0b30df6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "styles = {}\n",
    "\n",
    "for i, jdint in enumerate(data_jd_ints):\n",
    "    styles[jdint] = {'color': f\"C{i%10}\", 'ls': ['-', '--', ':', '-.'][i//10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae129d-3428-4234-b999-b4f19e25b2f8",
   "metadata": {},
   "source": [
    "## Define Subsets of Data to Consider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c277fa0-7c76-408a-a77e-970e18c2d9fe",
   "metadata": {},
   "source": [
    "### Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba6509-376b-4878-b791-6130337dc9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bands_considered = [\n",
    "    (0, 200), (200, 400), (400, 600), (600, 800), (800, 1000), (1000, 1200), (1200, 1400), (1400, 1536),\n",
    "    (0, 450),    # low band\n",
    "    (450, 1536), # high band\n",
    "    (0, 1536),   # full band\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc89519-8062-4b90-82c5-9fda9fe6f0c8",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e42212-606d-4ecf-925b-eaba46f9e122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_antenna_sectors():\n",
    "    antpos = stackconf.config.datameta.antenna_positions\n",
    "    zero_pos = np.mean([antpos[165], antpos[166], antpos[145]], axis=0)\n",
    "    \n",
    "    sectors = {}\n",
    "    for ant, pos in enumerate(antpos):\n",
    "        rec = pos - zero_pos\n",
    "        theta = np.arctan2(rec[1], rec[0])\n",
    "        bllen = np.sqrt(rec[0]**2 + rec[1]**2)\n",
    "        if bllen > 200:\n",
    "            sectors[ant] = 4  # outrigger\n",
    "        elif -np.pi / 3 <= theta < np.pi / 3:\n",
    "            sectors[ant] = 1\n",
    "        elif np.pi / 3 <= theta < np.pi:\n",
    "            sectors[ant] = 2\n",
    "        elif -np.pi <= theta < -np.pi/3:\n",
    "            sectors[ant] = 3\n",
    "    return sectors\n",
    "\n",
    "sectors = get_all_antenna_sectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0ccc9-194d-445e-8fcf-c973a55286c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getblvec(a, b):\n",
    "    return auto_stacks[0].antenna_positions[a] - auto_stacks[0].antenna_positions[b]\n",
    "def getbllen(a,b):\n",
    "    return np.sqrt(np.sum(np.square(getblvec(a,b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be9df6-4726-4b2c-9a64-7722fc8d7e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ee = lambda bl: bl[2] == 'ee'\n",
    "all_nn = lambda bl: bl[2] == 'nn'\n",
    "short_bls = lambda bl: getbllen(bl[0], bl[1])<=60.0\n",
    "long_bls = lambda bl: getbllen(bl[0], bl[1])>60.0\n",
    "intersector_bls = lambda bl: sectors[bl[0]] != sectors[bl[1]]\n",
    "intrasector_bls = lambda bl: sectors[bl[0]] == sectors[bl[1]]\n",
    "\n",
    "subsets = {\n",
    "    'all': lambda bl: True,\n",
    "    'ee-only': all_ee,\n",
    "    'nn-only': all_nn,\n",
    "    'Short (<60 m) baselines': short_bls,\n",
    "    'Long (>60 m) baselines': long_bls,\n",
    "    'Inter-sector baselines': intersector_bls,\n",
    "    \"Intra-sector baselines\": intrasector_bls,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b55b2",
   "metadata": {},
   "source": [
    "## LST-bin the Autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54691c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_auto_plot(auto_stacks: list[UVData], lstbin: list[dict]):\n",
    "    \n",
    "    fig, ax = plt.subplots(\n",
    "        len(stackconf.autopairs)*len(stackconf.pols), len(auto_stacks), \n",
    "        sharex=True, sharey=True, squeeze=False, constrained_layout=True,\n",
    "        figsize=(12, 6)\n",
    "    )\n",
    "\n",
    "    for i, (stack, avg) in enumerate(zip(auto_stacks, lstbin)):\n",
    "        for j, autopair in enumerate(stackconf.autopairs):\n",
    "            for p, pol in enumerate(stackconf.pols):\n",
    "                axx = ax[j*len(stackconf.pols) + p, i]\n",
    "                \n",
    "                for k, t in enumerate(stack.time_array[::stack.Nbls]):\n",
    "                    flg = stack.get_flags(autopair + (pol,))[k]\n",
    "                    d = stack.get_data(autopair+(pol,))[k]\n",
    "                    \n",
    "                    axx.plot(\n",
    "                        stack.freq_array / 1e6,\n",
    "                        np.where(flg, np.nan, d.real),\n",
    "                        label=f\"{int(t)}\" if not p else None,\n",
    "                        **styles[int(t)]\n",
    "                    )\n",
    "                    axx.set_yscale('log')\n",
    "                    axx.set_title(f\"Pair {autopair}, pol={pol}, LST {stackconf.lst_grid[i]*12/np.pi:.3f} hr\")\n",
    "\n",
    "                # plot the mean\n",
    "                axx.plot(\n",
    "                    stack.freq_array / 1e6,\n",
    "                    np.where(avg['flags'][j, :, p], np.nan, avg['data'][j, :, p].real),\n",
    "                    label='LSTBIN',\n",
    "                    color='k', lw=2\n",
    "                )\n",
    "                \n",
    "    ax[0,0].legend(ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c9e7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auto_stacks, autos_lstavg = stack_blchunk('autos') # Auto-stacks\n",
    "cross_stacks, cross_lstavg = stack_blchunk(0) # Cross-stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958c5e5",
   "metadata": {},
   "source": [
    "### LST-Bin Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf408972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_phase_abscal(data, model, reds, data_bls, model_bls, transformed_antpos=None):\n",
    "    \"\"\"\n",
    "    Modified version of the complex_phase_abscal function which allows user to pass if transformed_antpos\n",
    "    if already computed\n",
    "    \"\"\"\n",
    "    # Check that baselines selected are for the same polarization\n",
    "    pols = list(set([bl[2] for bls in (data_bls, model_bls) for bl in bls]))\n",
    "    assert len(pols) == 1, 'complex_phase_abscal() can only solve for one polarization at a time.'\n",
    "\n",
    "    # Get transformed antenna positions and baselines\n",
    "    if not transformed_antpos:\n",
    "        transformed_antpos = redcal.reds_to_antpos(reds)\n",
    "        abscal._put_transformed_array_on_integer_grid(transformed_antpos)\n",
    "        \n",
    "    transformed_b_vecs = np.rint(\n",
    "        [transformed_antpos[jj] - transformed_antpos[ii] for (ii, jj, pol) in data_bls]\n",
    "    ).astype(int)\n",
    "\n",
    "    # Get number of baselines and times/freqs\n",
    "    Ngroups = len(data_bls)\n",
    "    Ntimes, Nfreqs = data[data_bls[0]].shape\n",
    "\n",
    "    # Build up array of Fourier coefficients of the objective function\n",
    "    Z_coefficients = np.zeros((Ntimes, Nfreqs, Ngroups), dtype=complex)\n",
    "    for nn in range(Ngroups):\n",
    "\n",
    "        Vhat_n = data[data_bls[nn]]\n",
    "        Vbar_n = model[model_bls[nn]]\n",
    "\n",
    "        Z_coefficients[:, :, nn] = Vhat_n * np.conj(Vbar_n)\n",
    "\n",
    "    # Get solution for degenerate phase gradient vectors\n",
    "    Lambda_sol, Z_sol, newton_iterations = abscal._phase_gradient_solution(Z_coefficients, transformed_b_vecs)\n",
    "\n",
    "    # turn solution into per-antenna gains\n",
    "    phase_angle = {a: np.sum(Lambda_sol * r, axis=-1) for a, r in transformed_antpos.items()}\n",
    "    delta_gains = {(a, utils.split_pol(pols[0])[0]): np.exp(1j * (angle)) for a, angle in phase_angle.items()}\n",
    "    meta = {'Lambda_sol': Lambda_sol, 'Z_sol': Z_sol, 'newton_iterations': newton_iterations, \"transformed_antpos\": transformed_antpos}\n",
    "    return meta, delta_gains\n",
    "\n",
    "\n",
    "def lstbin_calibration(\n",
    "    stack,\n",
    "    model, \n",
    "    all_reds,\n",
    "    inpaint_bands,\n",
    "    run_amplitude_cal: bool=True, \n",
    "    run_phase_cal: bool=True, \n",
    "    smoothing_scale: float=10e6,\n",
    "    calibrate_inplace: bool=True,\n",
    "    return_gains: bool=True\n",
    "):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        stack : LSTStack\n",
    "        model : dictionary\n",
    "        inpaint_bands : tuple\n",
    "        run_amplitude_cal : bool\n",
    "        run_phase_cal : bool\n",
    "        smoothing_scale : float\n",
    "    \n",
    "    \"\"\"\n",
    "    # Assert some calibration done\n",
    "    assert run_amplitude_cal or run_phase_cal, \"At least one calibration mode must be used\"\n",
    "    assert stack.data.shape[1:] == model.shape, \"Model must have the same number of antpairs/freqs/pols as stack.data\"\n",
    "    \n",
    "    # Get variables used for both functions \n",
    "    antpairs = stack.antpairs[:]\n",
    "    pols = stack.pols\n",
    "    \n",
    "    # Function for storing calibration parameters\n",
    "    calibration_parameters = {}\n",
    "    \n",
    "    # Get DPSS for each band\n",
    "    smoothing_functions = []\n",
    "    for band in inpaint_bands:\n",
    "        smoothing_functions.append(\n",
    "            dspec.dpss_operator(\n",
    "                x=stack.freq_array[band], \n",
    "                filter_centers=[0], \n",
    "                filter_half_widths=[1 / smoothing_scale], \n",
    "                eigenval_cutoff=[delay_filter_eigencutoff]\n",
    "            )[0]\n",
    "        )\n",
    "        \n",
    "    # Dictionaries for storing data used in abscal functions\n",
    "    data_here = {}\n",
    "    wgts_here = {}\n",
    "    abscal_model = {}\n",
    "    amp_start = _time()\n",
    "    # Loop through baselines and polarizations\n",
    "    for polidx, pol in enumerate(pols):\n",
    "        for apidx, (ant1, ant2) in enumerate(antpairs):\n",
    "\n",
    "            blpol = (ant1, ant2, pol)\n",
    "            \n",
    "            # Move to the next blpol if there is not a model for the data or the entire baseline is flagged\n",
    "            if np.all(stack.flags[:, apidx, :, polidx]):\n",
    "                continue\n",
    "        \n",
    "            # Get model, weights, and data for each baseline \n",
    "            abscal_model[blpol] = model[apidx, :, polidx] * np.ones((len(stack.nights), 1))\n",
    "            data_here[blpol] = stack.data[:, apidx, :, polidx]\n",
    "            wgts_here[blpol] = stack.nsamples[:, apidx, :, polidx] * (~stack.flags[:, apidx, :, polidx]).astype(float)\n",
    "    \n",
    "    # Perform amplitude calibration\n",
    "    if run_amplitude_cal:            \n",
    "        # Store gain solutions in paramter dictionary\n",
    "        solution = abscal.abs_amp_lincal(\n",
    "            model=abscal_model, \n",
    "            data=data_here, \n",
    "            wgts=wgts_here, \n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        for pol in pols:\n",
    "            # Calibration parameters store in an N_nights by N_freqs array\n",
    "            amplitude_gain = np.where(np.isfinite(solution[f\"A_J{pol}\"]), solution[f\"A_J{pol}\"], 1.0 + 0.0j)\n",
    "            amplitude_gain = np.where(np.isclose(amplitude_gain, 0.0), 1.0 + 0.0j, amplitude_gain)\n",
    "            calibration_parameters[f\"A_J{pol}\"] = amplitude_gain    \n",
    "    else:\n",
    "        # Fill in amplitude w/ ones if no running amplitude calibration \n",
    "        for pol in pols:\n",
    "            calibration_parameters[f\"A_J{pol}\"] = np.ones((len(stack.nights), stacks.freq_array.size), dtype=complex)\n",
    "                        \n",
    "    phase_gains = {}\n",
    "    if run_phase_cal:\n",
    "        gain_ants = set()\n",
    "        for ap in antpairs:\n",
    "            gain_ants.update(ap)\n",
    "        gain_ants = list(gain_ants)\n",
    "        \n",
    "        transformed_antpos = None\n",
    "        \n",
    "        # Gains for phase\n",
    "        phase_gains = {(ant, \"J\" + pol): [] for ant in gain_ants for pol in pols}\n",
    "        \n",
    "        for nightidx, night in enumerate(stack.nights):\n",
    "            \n",
    "            # Store phase calibration parameters\n",
    "            phase_calibration_parameters = {(ant, pol): [] for ant in gain_ants for pol in pols}\n",
    "            \n",
    "            for polidx, pol in enumerate(pols):\n",
    "                cal_bls = []\n",
    "                \n",
    "                _data_here = {}\n",
    "                _abscal_model = {}\n",
    "                \n",
    "                if np.all(stack.flags[nightidx, :, :, polidx]):\n",
    "                    # Store \n",
    "                    for ant in gain_ants:\n",
    "                        phase_gains[(ant, f\"J{pol}\")].append(\n",
    "                            np.ones(stack.freq_array.shape, dtype=complex)\n",
    "                        )\n",
    "                    continue\n",
    "                \n",
    "                for apidx, (ant1, ant2) in enumerate(antpairs):\n",
    "                    blpol = (ant1, ant2, pol)\n",
    "                    \n",
    "                    if np.all(stack.flags[nightidx, apidx, :, polidx]):\n",
    "                        continue\n",
    "\n",
    "                    cal_bls.append((ant1, ant2, pol))\n",
    "                    _data_here[blpol] = stack.data[nightidx, apidx, :, polidx][np.newaxis]\n",
    "                    _abscal_model[blpol] = model[apidx, :, polidx][np.newaxis]\n",
    "                    \n",
    "                \n",
    "                metadata, delta_gains = complex_phase_abscal(\n",
    "                    data=_data_here, \n",
    "                    model=_abscal_model, \n",
    "                    reds=all_reds, \n",
    "                    model_bls=cal_bls, \n",
    "                    data_bls=cal_bls,\n",
    "                    transformed_antpos=transformed_antpos\n",
    "                )\n",
    "                \n",
    "                transformed_antpos = metadata['transformed_antpos']\n",
    "            \n",
    "                # Store \n",
    "                for ant in gain_ants:\n",
    "                    _gain_here = delta_gains.get((ant, f\"J{pol}\"), np.ones((1, stack.freq_array.shape[0]), dtype=complex))[0]\n",
    "                    phase_gains[(ant, f\"J{pol}\")].append(\n",
    "                        np.where(np.isfinite(_gain_here), _gain_here, 1.0 + 0.0j)\n",
    "                    )\n",
    "                    \n",
    "        for key in phase_gains:\n",
    "            phase_gains[key] = np.array(phase_gains[key])\n",
    "            \n",
    "            \n",
    "    # Pre-compute matrices for smoothing fits\n",
    "    fmats = {pol: [] for pol in pols}\n",
    "    for polidx, pol in enumerate(pols):\n",
    "        for bandidx, band in enumerate(inpaint_bands):\n",
    "            # Get weights and basis functions for the fit\n",
    "            wgts = np.logical_not(stack.flags[:, 0, band, polidx]).astype(float)\n",
    "            basis = smoothing_functions[bandidx]\n",
    "            \n",
    "            # Compute matrices for linear least-squares fits\n",
    "            xtxinv = np.linalg.pinv([np.dot(basis.T * wi, basis) for wi in wgts])\n",
    "            xy = basis.T.dot(wgts.T).T\n",
    "            fmat = np.array([np.dot(_xtxinv, basis.T) * _w for _xtxinv, _w in zip(xtxinv, wgts)])\n",
    "            fmats[pol].append(fmat)\n",
    "\n",
    "    # Dictionary for gain parameters\n",
    "    gains = {}\n",
    "\n",
    "    # Iterate for each baseline the array\n",
    "    for polidx, pol in enumerate(pols):\n",
    "        for apidx, (ant1, ant2) in enumerate(antpairs):\n",
    "            bl_gain = np.ones((stack.nights.size, stack.freq_array.size), dtype=complex)\n",
    "            for bandidx, band in enumerate(inpaint_bands):\n",
    "                basis = smoothing_functions[bandidx]\n",
    "                \n",
    "                # Construct the raw gain and remove nans and infs\n",
    "                raw_gain = calibration_parameters[f\"A_J{pol}\"] ** 2 * (\n",
    "                    phase_gains.get((ant1, \"J\" + pol), np.ones_like(calibration_parameters[f\"A_J{pol}\"])) * \\\n",
    "                    phase_gains.get((ant2, \"J\" + pol), np.ones_like(calibration_parameters[f\"A_J{pol}\"])).conj()\n",
    "                )\n",
    "                raw_gain = np.where(stack.flags[:, 0, band, polidx], 1.0 + 0.0j, raw_gain[:, band])\n",
    "\n",
    "                # Compute smooth gain for each parameter and remove zeros/nans/infs\n",
    "                bl_gain_here = np.array(\n",
    "                   [np.dot(basis, _fmat.dot(_raw_gain)) for _fmat, _raw_gain in zip(fmats[pol][bandidx], raw_gain)]\n",
    "                )\n",
    "                bl_gain_here = np.where(np.isfinite(bl_gain_here), bl_gain_here, 1.0 + 0.0j)\n",
    "                bl_gain_here = np.where(np.isclose(bl_gain_here, 0), 1.0 + 0.0j, bl_gain_here)\n",
    "                bl_gain[:, band] = bl_gain_here\n",
    "    \n",
    "            # Calibrate out smoothed gains\n",
    "            if calibrate_inplace:\n",
    "                stack.data[:, apidx, :, polidx] /= bl_gain\n",
    "            \n",
    "            # Store gains to return\n",
    "            if return_gains:\n",
    "                gains[(ant1, ant2, pol)] = bl_gain\n",
    "        \n",
    "    return gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d85ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if do_lstcal:\n",
    "    for i, (stack, lstavg_model) in enumerate(zip(cross_stacks, lstavg_models)):\n",
    "        gains = lstbin_calibration(\n",
    "            stack=stack, \n",
    "            model=lstavg_model, \n",
    "            all_reds=reds_with_pols, \n",
    "            inpaint_bands=inpaint_bands, \n",
    "            calibrate_inplace=True, # calibrate inplace\n",
    "            run_phase_cal=True, # run phase calibration\n",
    "            run_amplitude_cal=True, # run amplitude calibration\n",
    "            return_gains=True # return gains for \n",
    "        )\n",
    "        \n",
    "    # Recompute LST-average for crosses and autos after calibration\n",
    "    cross_lstavg = [\n",
    "        lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=False,\n",
    "            get_mad=write_med_mad,\n",
    "        ) for stack in cross_stacks\n",
    "    ]\n",
    "    \n",
    "    autos_lstavg = [\n",
    "        lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=False,\n",
    "            get_mad=write_med_mad,\n",
    "        ) for stack in auto_stacks\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e88b6",
   "metadata": {},
   "source": [
    "### Compute Stats for Autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48853eb-611a-463c-966f-6435da5312aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auto_stats = [\n",
    "    lstmet.LSTBinStats.from_reduced_data(rdc=rdc, antpairs=stackconf.autopairs, pols=stackconf.pols, reds=reds_with_pols) for rdc in autos_lstavg\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea584858",
   "metadata": {},
   "source": [
    "### Inpaint Autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4af378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_and_inpaint_simultaneously(\n",
    "    stack, \n",
    "    auto_stack, \n",
    "    inpaint_bands=(slice(0, None, None),), \n",
    "    return_models=True, \n",
    "    cache=None, \n",
    "    filter_properties=None, \n",
    "    alpha=0.0,\n",
    "    eigenval_cutoff=[1e-12]\n",
    "):\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    filter_properties = filter_properties or {}\n",
    "    cache = cache or {}\n",
    "\n",
    "    # Dictionary for model storage\n",
    "    all_models = {}\n",
    "\n",
    "    # Time axis is outer axis for all LSTStacks.\n",
    "    antpos, ants = stack.get_ENU_antpos(pick_data_ants=False)\n",
    "    antpos = dict(zip(ants, antpos))\n",
    "\n",
    "    complete_flags = stack.flagged_or_inpainted()\n",
    "\n",
    "    # First, perform a simple flagged-mode average over the nights.\n",
    "    # lstavg is a dict of arrays with keys being 'mean', 'std', 'nsamples', 'flags'.\n",
    "    lstavg = lstbin.averaging.reduce_lst_bins(\n",
    "        stack, get_std=False, get_mad=False, inpainted_mode=False, mean_fill_value=0.0\n",
    "    )\n",
    "\n",
    "    # Compute noise variance\n",
    "    assert (auto_stacks[0].data.shape)[1] == 1, 'This code only works with redundantly averaged data, which has only one unique auto per polarization'\n",
    "\n",
    "    # Arrays for inpainted mean and total samples\n",
    "    inpainted_mean = np.zeros(stack.Nfreqs, dtype=stack.data.dtype)\n",
    "    total_nsamples = np.zeros(stack.Nfreqs, dtype=float)\n",
    "        \n",
    "    for iap, antpair in enumerate(stack.antpairs, disable=False):\n",
    "        for polidx, pol in enumerate(stack.pols):\n",
    "            stackd = stack.data[:, iap, :, polidx] \n",
    "            stackf = complete_flags[:, iap, :, polidx]\n",
    "            stackn = np.abs(stack.nsamples[:, iap, :, polidx])\n",
    "\n",
    "            # Also get the lst-avg data, flags, and nsamples for this baseline-pol pair.\n",
    "            flagged_mean = lstavg['data'][iap, :, polidx]\n",
    "            avg_wgts = lstavg['nsamples'][iap, :, polidx]\n",
    "            flgs = lstavg['flags'][iap, :, polidx]\n",
    "\n",
    "            # Compute noise variance for all days in stack\n",
    "            base_noise_var = np.abs(auto_stack.data[:, 0, :, polidx]) ** 2 / (stack.dt * stack.df).value\n",
    "            mask = (~stackf).astype(float)\n",
    "            \n",
    "            # Shortcut early if there are no flags in the stack. In that case,\n",
    "            # the LST-average is the same as the flagged-mode mean.\n",
    "            if (not np.any(stackf)) or np.all(stackf):\n",
    "                continue\n",
    "\n",
    "            # Get the baseline vector and length\n",
    "            bl_vec = (antpos[antpair[1]] - antpos[antpair[0]])[:2]\n",
    "            bl_len = np.linalg.norm(bl_vec) / lstbin.averaging.constants.c\n",
    "            filter_centers, filter_half_widths = vis_clean.gen_filter_properties(\n",
    "                ax='freq',\n",
    "                bl_len=max(bl_len, 7.0 / lstbin.averaging.constants.c),\n",
    "                **filter_properties,\n",
    "            )\n",
    "            \n",
    "            # DPSS inpainting model\n",
    "            model = np.zeros_like(stackd)\n",
    "            \n",
    "            # Get median nsamples across the band\n",
    "            nsamples_by_night = np.median(stackn, axis=1, keepdims=True)\n",
    "            \n",
    "            assert np.all(nsamples_by_night == stackn), 'This code assumes that nsamples is constant over frequency for a given night and baseline.'\n",
    "\n",
    "            for band in inpaint_bands:\n",
    "                if np.all(stackf[:, band]):\n",
    "                    continue\n",
    "                \n",
    "                # Get basis functions\n",
    "                basis = dspec.dpss_operator(\n",
    "                    stack.freq_array[band],\n",
    "                    filter_centers=filter_centers,\n",
    "                    filter_half_widths=filter_half_widths,\n",
    "                    cache=cache,\n",
    "                    eigenval_cutoff=eigenval_cutoff\n",
    "                )[0].real\n",
    "\n",
    "                # compute fits for dpss basis functions\n",
    "                hash_key = dspec._fourier_filter_hash(\n",
    "                    filter_centers=filter_centers, \n",
    "                    filter_half_widths=filter_half_widths, \n",
    "                    x=stack.freq_array[band], \n",
    "                    w=base_noise_var\n",
    "                )\n",
    "                \n",
    "                # If key exists in cache, load in filter and invese\n",
    "                if hash_key in cache:\n",
    "                    CNinv_1sample_dpss, CNinv_1sample_dpss_inv = cache[hash_key]\n",
    "                else:\n",
    "                    CNinv_1sample_dpss = np.array([\n",
    "                        (basis.T * wgts).dot(basis) + np.eye(basis.shape[1]) * alpha \n",
    "                        for wgts in mask[:, band] / base_noise_var[:, band]]\n",
    "                    )\n",
    "                    CNinv_1sample_dpss_inv = np.linalg.pinv(CNinv_1sample_dpss)\n",
    "                    cache[hash_key] = (CNinv_1sample_dpss, CNinv_1sample_dpss_inv)\n",
    "                    \n",
    "                    \n",
    "                # Compute data covariance\n",
    "                max_allowed_gap_size = COV_INPAINT_MAX_GAP_FACTOR * filter_half_widths[0]**-1 / stack.df.value\n",
    "                to_include_night = np.logical_not(np.all(stackf[:, band], axis=1))\n",
    "                    \n",
    "                CNinv_dpss = CNinv_1sample_dpss * nsamples_by_night[:, np.newaxis]\n",
    "                CNinv_dpss_inv = CNinv_1sample_dpss_inv / nsamples_by_night[:, np.newaxis]\n",
    "\n",
    "                # compute matrix product + get per-day DPSS fits\n",
    "                noise_var = base_noise_var / nsamples_by_night\n",
    "                CNinv_data_dpss = np.array([\n",
    "                    basis.T.dot(weighted_data) for weighted_data in mask[:, band] / noise_var[:, band] * stackd[:, band]\n",
    "                ])\n",
    "                dpss_fits = np.array([\n",
    "                    a.dot(b) if np.all(np.isfinite(b)) else a.dot(np.zeros_like(b))\n",
    "                    for night_index, (a, b) in enumerate(zip(CNinv_dpss_inv, CNinv_data_dpss))\n",
    "                ])\n",
    "                                \n",
    "                # Not enough data to estimate covariance, flag the band/bl/pol\n",
    "                if np.sum(to_include_night) < 2:\n",
    "                    flgs[band] = True \n",
    "                    model[:, band] = np.dot(basis, dpss_fits.T).T\n",
    "                    continue\n",
    "         \n",
    "                # Compute prior mean from per-day DPSS-fits and noise-weighted covariance matrix\n",
    "                average_data_cov = np.linalg.pinv(np.sum(CNinv_dpss[to_include_night], axis=0))\n",
    "                prior_mean = (\n",
    "                    average_data_cov @ np.einsum('nde,nd->e', CNinv_dpss[to_include_night], dpss_fits[to_include_night])\n",
    "                )\n",
    "    \n",
    "                # Compute prior covariance\n",
    "                XTX = np.array([\n",
    "                    np.dot(CNinv_dpss[i].conj().dot(((dpss_fits[i] - prior_mean)[:, None].conj() * (dpss_fits[i] - prior_mean)[None])), CNinv_dpss[i])\n",
    "                    for i in range(CNinv_dpss.shape[0])\n",
    "                    if to_include_night[i]\n",
    "                ]).sum(0)\n",
    "                prior_data_cov = np.dot(np.dot(average_data_cov.conj(), XTX), average_data_cov) * np.sum(to_include_night)\n",
    "                prior_data_cov_inv = np.diag(1 / np.abs(np.diag(prior_data_cov))) # form freq/freq covariance in this basis, excluding too-flagged nights\n",
    "            \n",
    "                # Compute the per-night DPSS model\n",
    "                CNinv_data_dpss = np.where(np.isfinite(CNinv_data_dpss), CNinv_data_dpss, 0)\n",
    "                LU_decomp = [\n",
    "                    linalg.lu_factor(nightly_inv + prior_data_cov_inv) \n",
    "                    for nightly_inv in CNinv_dpss\n",
    "                ] # LU decomposition of Sigma_{N,i}^-1\n",
    "                prior_sig_inv_prior_mean = prior_data_cov_inv.dot(prior_mean)\n",
    "                post_mean = np.array([\n",
    "                    linalg.lu_solve(_LU_decomp, (nightly_weighted_data + prior_sig_inv_prior_mean)) \n",
    "                    for _LU_decomp, nightly_weighted_data in zip(LU_decomp, CNinv_data_dpss)\n",
    "                ])\n",
    "                bayes_fit = basis.dot(post_mean.T).T\n",
    "                model[:, band] = bayes_fit\n",
    "            \n",
    "                # If we've made it this far, set averaged flags to False\n",
    "                flgs[band] = False\n",
    "                \n",
    "\n",
    "            if return_models:\n",
    "                all_models[(antpair[0], antpair[1], pol)] = model.copy()\n",
    "\n",
    "            # Inpainted mean is going to be sum(n_i * {model if flagged else data_i}) / sum(n_i)\n",
    "            # where n_i is the nsamples for the i-th integration The total_nsamples is\n",
    "            # simply sum(n_i) for all i (originally flagged or not).\n",
    "            inpainted_mean[:] = 0.0\n",
    "            total_nsamples[:] = 0.0\n",
    "            for tind, (d, f, n) in enumerate(zip(stackd, stackf, stackn)):\n",
    "                # If an entire integration is flagged, don't use it at all\n",
    "                # in the averaging -- it doesn't contibute any knowledge.\n",
    "                if np.all(f):\n",
    "                    continue\n",
    "\n",
    "                # Make model variable here\n",
    "                inpainted_mean += n * np.where(f, model[tind], d)\n",
    "                total_nsamples += n\n",
    "\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                inpainted_mean /= total_nsamples\n",
    "                inpainted_mean[total_nsamples == 0] *= np.nan\n",
    "\n",
    "            # Overwrite the original averaged data with the inpainted mean.\n",
    "            # The nsamples remains the same for inpainted vs. flagged mean (we don't\n",
    "            # count inpainted samples as samples, but we do count them as data).\n",
    "            flagged_mean[:] = inpainted_mean\n",
    "            \n",
    "    # Set data that is flagged to nan\n",
    "    lstavg['data'][lstavg['flags']] = np.nan\n",
    "\n",
    "    return lstavg, all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc85fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpaint_bands = [(0, 87.5), (108.0, 250.0)]  # default below and above FM\n",
    "\n",
    "# Get slices for the inpaint bands\n",
    "_inp = []\n",
    "for _bnd in inpaint_bands:\n",
    "    idx = np.nonzero((stackconf.config.datameta.freq_array >= _bnd[0] * 1e6) & (stackconf.config.datameta.freq_array < _bnd[1]*1e6))[0]\n",
    "    _inp.append(slice(idx[0], idx[-1] + 1))\n",
    "inpaint_bands = _inp\n",
    "print(\"Using the following bands for inpainting (channels):\")\n",
    "for bnd in inpaint_bands:\n",
    "    print(bnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_simultaneous_inpainting:\n",
    "    auto_inpaint_dpss_models = []\n",
    "\n",
    "    for i, stack in enumerate(auto_stacks):\n",
    "        \n",
    "        _avg, dpss_models = average_and_inpaint_simultaneously(\n",
    "            stack,\n",
    "            stack,\n",
    "            inpaint_bands = inpaint_bands,\n",
    "            return_models = make_plots,\n",
    "            cache = _INPAINT_CACHE_,\n",
    "            filter_properties = {\n",
    "                \"min_dly\": inpaint_mindelay, \n",
    "                \"horizon\": delay_filter_horizon,\n",
    "                \"standoff\": delay_filter_standoff, \n",
    "            },\n",
    "            eigenval_cutoff=[delay_filter_eigencutoff], \n",
    "        )\n",
    "\n",
    "        auto_inpaint_dpss_models.append(dpss_models)\n",
    "        autos_lstavg[i]['data'] = _avg['data']\n",
    "        autos_lstavg[i]['flags'] = _avg['flags']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2d0d6",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34526c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    make_auto_plot(auto_stacks, autos_lstavg);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae48cd95",
   "metadata": {},
   "source": [
    "## Cross-Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44389478-fc7e-4a0f-950a-4678cbe04b6e",
   "metadata": {},
   "source": [
    "### Improve Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ffe94-0954-4b6d-a075-1faf1df62053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "\n",
    "def watershed_ndim(metrics: np.ndarray, flags: np.ndarray, axis: int, threshold: float, size: int = 1):\n",
    "    \"\"\"Perform a watershed filter over one axis of a multi-dimensional array.\"\"\"\n",
    "    assert metrics.shape == flags.shape\n",
    "    outflags = flags.copy()\n",
    "    is_neighbour_flagged = np.zeros_like(outflags)\n",
    "    \n",
    "    ndim = metrics.ndim\n",
    "    shape = np.ones(ndim, dtype=int)\n",
    "    shape[axis] = 2*size + 1\n",
    "    kernel = np.zeros(shape)\n",
    "        \n",
    "    while True:\n",
    "        nflags = np.sum(outflags)\n",
    "        is_neighbor_flagged = convolve(outflags, kernel, mode='same', method='direct').astype(bool)        \n",
    "        outflags |= (is_neighbor_flagged & (metrics >= threshold))\n",
    "        if np.sum(outflags) == nflags:\n",
    "            break\n",
    "    \n",
    "    return outflags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95af9b-e653-4596-aebe-5919745710dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iterative_flagger(func, stack, variance, max_iter=10):\n",
    "    niter = 0\n",
    "    nflags = np.sum(stack.flags)\n",
    "    \n",
    "    while niter < max_iter:\n",
    "        print(f\"    iter {niter}: nflags = {nflags} ({nflags*100/stack.flag_array.size:.2f} %)\")\n",
    "        zsq = lstmet.get_squared_zscores_flagged(stack, variance=variance)\n",
    "        func(stack, zsq)\n",
    "        new_nflags = np.sum(stack.flags)\n",
    "        if  new_nflags == nflags:\n",
    "            break\n",
    "        nflags = new_nflags\n",
    "        niter += 1\n",
    "    \n",
    "    return zsq\n",
    "\n",
    "def do_flagging(funcs, stacks, auto_stats, max_iter=10):\n",
    "    out_zsq = []\n",
    "    for i, (stack, stat) in enumerate(zip(stacks, auto_stats)):\n",
    "        print(f\"Stack {i}\")\n",
    "        variance = lstmet.get_nightly_predicted_variance_stack(stack, stat, flag_if_inpainted=True) / 2\n",
    "        \n",
    "        for fnc in funcs:\n",
    "            print(f\"  Flagger: {fnc.__name__}\")\n",
    "            zsq = iterative_flagger(fnc, stack, variance, max_iter=max_iter)\n",
    "            \n",
    "        out_zsq.append(zsq)\n",
    "    return out_zsq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26389a-681b-418c-94c3-3e4798d1c68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def direct_zscore_pruning(stack,zsq):\n",
    "    stack.flags |= ((zsq.metrics > zscore_threshold**2) & (zsq.metrics >= np.nanmax(zsq.metrics, axis=0) / iterative_flagging_factor))\n",
    "    \n",
    "def watershed(stack, zsq):\n",
    "    stack.flags |= watershed_ndim(zsq.metrics, stack.flags, axis=-2, threshold=watershed_threshold**2, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f51883-9596-4fc1-992e-847d719e9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "zsquare = [lstmet.get_squared_zscores_flagged(stack, auto_stats=stats) for stack, stats in zip(cross_stacks, auto_stats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c2544-09c4-400d-b89c-0c000d89e58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_extra_flagging:\n",
    "    # Keep a copy of the original flags and Z^2 so we can check for differences later\n",
    "    original_flags = [stack.flag_array.copy() for stack in cross_stacks]\n",
    "    original_zsquare = zsquare\n",
    "    zsquare = do_flagging([direct_zscore_pruning, watershed], cross_stacks, auto_stats, max_iter=max_flagging_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98fc9f-a22e-4a2d-8ff1-8bccfdb453f5",
   "metadata": {},
   "source": [
    "### Inpaint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a78dc-d227-4479-8ebb-546e6ac5568e",
   "metadata": {},
   "source": [
    "We simultaneously inpaint and average the data with the flags we're given. We don't try and inpaint the stack itself (i.e. on a nightly basis), since we have only one solution per LST bin (per freq and baseline), and there's no useful information gained by doing so (one might think that the newly-inpainted nightly solution might be useful in terms of getting a new $Z^2$ score for the statistics, but the $Z^2$ for the inpainted data is not well-defined: it has zero nsamples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221ddbc-b7a1-4352-afda-852cbc762ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    # We need this if we want to make a plot comparing the new simultaneous inpaint\n",
    "    original_data_mean = [lstavg['data'].copy() for lstavg in cross_lstavg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049096c-3d53-4929-b594-cb683a226132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_simultaneous_inpainting:\n",
    "    inpaint_dpss_models = []\n",
    "\n",
    "    for i, (stack, auto_stack) in enumerate(zip(cross_stacks, auto_stacks)):\n",
    "        \n",
    "        _avg, dpss_models = average_and_inpaint_simultaneously(\n",
    "            stack,\n",
    "            auto_stack\n",
    "            inpaint_bands = inpaint_bands,\n",
    "            return_models = make_plots,\n",
    "            cache = _INPAINT_CACHE_,\n",
    "            filter_properties = {\n",
    "                \"min_dly\": inpaint_mindelay, \n",
    "                \"horizon\": delay_filter_horizon,\n",
    "                \"standoff\": delay_filter_standoff, \n",
    "            },\n",
    "            eigenval_cutoff=[delay_filter_eigencutoff], \n",
    "        )\n",
    "\n",
    "        inpaint_dpss_models.append(dpss_models)\n",
    "        cross_lstavg[i]['data'] = _avg['data']\n",
    "        cross_lstavg[i]['flags'] = _avg['flags']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805bcaf-040e-4bd4-93de-a735cccccabc",
   "metadata": {},
   "source": [
    "Let's make some plots to inspect how the inpainting did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced3356-0394-4ec0-8574-8475f85d3abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_biggest_inpaint_differences(band, n: int = 5):\n",
    "    inpdata = cross_lstavg[0]['data'][:, band]\n",
    "    flgdata = np.where(\n",
    "        cross_lstavg[0]['nsamples'][:, band] == 0, np.nan, original_data_mean[0][:, band]\n",
    "    )\n",
    "    diff = np.nanmax(np.abs(inpdata - flgdata), axis=1).flatten()\n",
    "    diff[np.isnan(diff)] = -1\n",
    "    idx = np.argsort(diff)\n",
    "\n",
    "    baselines_with_biggest_differences = []\n",
    "    for ii in idx[::-1][:n]:\n",
    "        pol_idx = ii % len(cross_stacks[0].pols)\n",
    "        ap_idx = ii // len(cross_stacks[0].pols)\n",
    "        baselines_with_biggest_differences.append((*cross_stacks[0].antpairs[ap_idx], cross_stacks[0].pols[pol_idx]))\n",
    "    return baselines_with_biggest_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57e4f7-5b11-44f4-8aca-015a89150e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots and do_simultaneous_inpainting:\n",
    "    biggest_inpaint_diffs = {}\n",
    "    n_biggest_diffs = 5\n",
    "\n",
    "    for band in inpaint_bands:\n",
    "        biggest_inpaint_diffs[(band.start, band.stop)] = get_biggest_inpaint_differences(band, n=n_biggest_diffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3fdbc-12d3-4364-bb47-74b8151b7d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots and do_simultaneous_inpainting:\n",
    "    fig, ax = plt.subplots(len(biggest_inpaint_diffs)*n_biggest_diffs, 1, figsize=(15, 2.5*len(biggest_inpaint_diffs)*n_biggest_diffs), layout='constrained')\n",
    "\n",
    "    kk = 0\n",
    "\n",
    "    complete_flags = cross_stacks[0].flagged_or_inpainted()\n",
    "\n",
    "    for jj, (band, blpol_list) in enumerate(biggest_inpaint_diffs.items()):\n",
    "        band = slice(*band)\n",
    "        for ii, blpol in enumerate(blpol_list):\n",
    "\n",
    "            apidx = cross_stacks[0].antpairs.index(blpol[:2])\n",
    "            polidx = cross_stacks[0].pols.index(blpol[2])\n",
    "\n",
    "            diff = np.abs(\n",
    "                np.where(\n",
    "                    cross_lstavg[0]['flags'][apidx, band, polidx], np.nan, original_data_mean[0][apidx, band, polidx]\n",
    "                ) - cross_lstavg[0]['data'][apidx, band, polidx]\n",
    "            )\n",
    "\n",
    "            worst_idx = np.argmax(diff[np.isfinite(diff)])\n",
    "            subband = slice(max(worst_idx - 50, 0), min(worst_idx+50, len(diff)))\n",
    "\n",
    "            fq = cross_stacks[0].freq_array[band][subband] / 1e6\n",
    "            ax[kk].plot(\n",
    "                fq, \n",
    "                np.abs(\n",
    "                    np.where(\n",
    "                        cross_lstavg[0]['flags'][apidx, band, polidx], np.nan, original_data_mean[0][apidx, band, polidx]\n",
    "                    )[subband]\n",
    "                ), \n",
    "                lw=3, ls='-', color='k', label='flagged mean'\n",
    "            )\n",
    "            ax[kk].plot(fq, np.abs(cross_lstavg[0]['data'][apidx, band, polidx][subband]), lw=3, ls='--', color='red', label='simul. inpaint')\n",
    "\n",
    "            ax[kk].plot(fq, np.abs(inpaint_dpss_models[0][blpol][band][subband]), lw=2, color='purple', ls=':', label='model')\n",
    "\n",
    "            gotlabel = False\n",
    "            for i, jd in enumerate(cross_stacks[0].nights):\n",
    "                flg = complete_flags[i, apidx, band, polidx][subband]\n",
    "                if np.all(flg):\n",
    "                    continue\n",
    "\n",
    "                d = np.abs(cross_stacks[0].data[i, apidx, band, polidx][subband])\n",
    "                ax[kk].plot(fq, d, lw=1, alpha=0.6, color=styles[jd]['color'])\n",
    "\n",
    "                if np.any(flg):\n",
    "                    ax[kk].scatter(fq[flg], d[flg], marker='o', edgecolors=styles[jd]['color'], facecolors='none', alpha=0.4, label='flagged datum' if not gotlabel else None)\n",
    "                    gotlabel = True\n",
    "            ax[kk].legend(ncols=2)\n",
    "            ax[kk].set_title(str(blpol))\n",
    "\n",
    "            kk += 1\n",
    "    fig.suptitle(\"Examples of Biggest Differences in Inpainted Solutions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd58cc9-70c4-46a7-a893-fdc38b41d3a1",
   "metadata": {},
   "source": [
    "### Write Out Averaged Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538e308-d4da-48ca-a511-603266e2236a",
   "metadata": {},
   "source": [
    "So far, we have the `cross_lstavg` as _either_ a flagged-mode average, or a simultaneously-inpainted average (if `do_simultaneous_inpainting==True`). If the configuration requests\n",
    "old-style per-night inpainting, then do it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860918b3-e0fa-4ea0-be3b-2ddd28e69a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_inpainted_average:\n",
    "    cross_lstavg = [\n",
    "        lstbin.averaging.reduce_lst_bins(\n",
    "            lststack=stack,\n",
    "            inpainted_mode=True,\n",
    "            get_mad=write_med_mad,\n",
    "        ) for stack in cross_stacks\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6db06-c4a8-4776-8f46-c4c264cae9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make it a bit easier to create the outfiles\n",
    "uvd_template = lstbin.io.create_empty_uvd(\n",
    "    pols=stackconf.pols,\n",
    "    file_list=stackconf.matched_metas,\n",
    "    history=history,\n",
    "    antpairs=stackconf.autopairs + stackconf.antpairs,\n",
    "    start_jd=stackconf.properties['first_jd'],\n",
    "    freq_min=freq_min,\n",
    "    freq_max=freq_max,\n",
    "    lst_branch_cut=stackconf.properties[\"lst_branch_cut\"],\n",
    "    lsts=stackconf.lst_grid,\n",
    "    vis_units=vis_units\n",
    ")\n",
    "\n",
    "create_file = partial(\n",
    "    lstbin.io.create_lstbin_output_file,\n",
    "    uvd_template=uvd_template,\n",
    "    outdir=outdir,\n",
    "    overwrite=overwrite,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0bb4a-b45c-476f-9d17-11111ac03d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save_lstbin_data:\n",
    "    out_files = {}\n",
    "    kinds = [\"LST\", \"STD\"]\n",
    "    if write_med_mad:\n",
    "        kinds += [\"MED\", \"MAD\"]\n",
    "    for kind in kinds:\n",
    "\n",
    "        fname = lstbin.io.format_outfile_name(\n",
    "            lst=stackconf.lst_grid_edges[0],\n",
    "            pols=stackconf.pols,\n",
    "            fname_format=fname_format,\n",
    "            inpaint_mode=True,\n",
    "            lst_branch_cut=stackconf.properties[\"lst_branch_cut\"],\n",
    "            kind=kind\n",
    "        )\n",
    "\n",
    "        out_files[kind] = create_file(fname=fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a99068-e637-48b9-85cc-661fe48ad8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_data(rdc: dict, stack: lstbin.LSTStack, nbls_so_far: int, lstidx: int):\n",
    "    chunk_size = stack.Nbls\n",
    "\n",
    "    write = partial(\n",
    "        uvd_template.write_uvh5_part,\n",
    "        blt_inds=np.arange(nbls_so_far, nbls_so_far + chunk_size) * stackconf.n_lsts + lstidx,\n",
    "        flag_array=rdc['flags'],\n",
    "    )\n",
    "    \n",
    "    write(\n",
    "        filename=out_files[\"LST\"],\n",
    "        data_array=rdc[\"data\"],\n",
    "        nsample_array=rdc[\"nsamples\"],\n",
    "    )\n",
    "    print(f\"Wrote {out_files['LST']}\")\n",
    "    \n",
    "    write(\n",
    "        filename=out_files[\"STD\"],\n",
    "        data_array=rdc[\"std\"],\n",
    "        nsample_array=rdc[\"days_binned\"],\n",
    "    )\n",
    "    print(f\"Wrote {out_files['STD']}\")\n",
    "    \n",
    "    if write_med_mad:\n",
    "        write(\n",
    "            filename=out_files[\"MED\"],\n",
    "            data_array=rdc[\"median\"],\n",
    "            nsample_array=rdc[\"nsamples\"],\n",
    "        )\n",
    "        print(f\"Wrote {out_files['MED']}\")\n",
    "        \n",
    "        write(\n",
    "            filename=out_files[\"MAD\"],\n",
    "            data_array=rdc[\"mad\"],\n",
    "            nsample_array=rdc[\"days_binned\"],\n",
    "        )\n",
    "        print(f\"Wrote {out_files['MAD']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d0343-c469-4f87-af27-3570827627e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save_lstbin_data:\n",
    "    for lstidx in range(stackconf.n_lsts):\n",
    "        write_data(autos_lstavg[lstidx], auto_stacks[lstidx], 0, lstidx)\n",
    "        write_data(cross_lstavg[lstidx], cross_stacks[lstidx], auto_stacks[lstidx].Nbls, lstidx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00f546-da75-4d7e-9252-0b06920aa26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not get_metrics:\n",
    "    # The rest of the notebook is simply getting metrics and inspecting them.\n",
    "    print_metadata()\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1829d46e-b428-4740-9ff9-07ad3aa9cd26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:54:35.025659Z",
     "iopub.status.busy": "2024-03-20T12:54:35.025016Z",
     "iopub.status.idle": "2024-03-20T12:54:35.061107Z",
     "shell.execute_reply": "2024-03-20T12:54:35.060118Z",
     "shell.execute_reply.started": "2024-03-20T12:54:35.025611Z"
    }
   },
   "source": [
    "### Distributions of $Z^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd99bf6-6ee7-4a42-bea3-534debf15060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_stats = [\n",
    "    lstmet.LSTBinStats.from_reduced_data(rdc=rdc, antpairs=cross_stacks[0].antpairs, pols=stackconf.pols, reds=reds_with_pols) for rdc in cross_lstavg\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854206a-7886-4556-9a4a-d390bb3a1bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zdist_pred = lststat.zsquare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ecc99-b476-417e-8f6d-74a5a0efe88a",
   "metadata": {},
   "source": [
    "#### Simple Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92491f93-a985-460e-86ad-23610757802e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autoplot(zsquare):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    x = np.logspace(-5, 7, 200)\n",
    "\n",
    "    xc = 10**((np.log10(x[1:]) + np.log10(x[:-1]))/2)\n",
    "    dndzsq = zdist_pred.pdf(xc)\n",
    "\n",
    "    for i, zsq in enumerate(zsquare):\n",
    "        ax[0].hist(zsq.metrics.flatten(), bins=x, label=f'LST Bin {i}', density=True, histtype='step')\n",
    "\n",
    "    ax[0].plot(xc, dndzsq, label='Predicted')\n",
    "    ax[0].set_xscale('log')\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].set_ylim(1e-12, 1e4)\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel(r\"Log10 $Z^2$\")\n",
    "    ax[0].set_title(\"PDF of $Z^2$\")\n",
    "\n",
    "    # Plot the CDF\n",
    "    x = np.logspace(-5, np.log10(max(np.nanmax(zsq.metrics) for zsq in zsquare)), 100)\n",
    "\n",
    "    for zsq in zsquare:\n",
    "        zsq = zsq.metrics[np.isfinite(zsq.metrics)]\n",
    "        size = zsq.size\n",
    "    \n",
    "        cdf_data = [np.sum(zsq < c)/size for c in x]\n",
    "        ax[1].plot(x, cdf_data)\n",
    "    \n",
    "    ax[1].plot(x, zdist_pred.cdf(x))\n",
    "    ax[1].set_xlabel(r\"$Z^2$\")\n",
    "    ax[1].set_title(\"CDF of $Z^2$\")\n",
    "    ax[1].set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c371fc5-f119-4de8-8a52-ba4c505103ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    autoplot(zsquare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d0bee-a457-4794-81cf-c82672740338",
   "metadata": {},
   "source": [
    "#### Get list of bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57eed1-eb95-44cb-b0d9-e940b065934c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def consecutive(data: np.ndarray, stepsize: int=1) -> list[tuple[int, int]]:\n",
    "    \"\"\"From https://stackoverflow.com/a/46606745/1467820\"\"\"\n",
    "    sequences = np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "    \n",
    "    l = []\n",
    "    for s in sequences:\n",
    "        if len(s) > 1:\n",
    "            l.append((s[0], s[-1]))\n",
    "        else:\n",
    "            l.append((s[0], s[0]+1))\n",
    "            \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd5c40-400a-4224-8a21-e1dd584d67c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allbad = {}\n",
    "inpainted_regions = {}\n",
    "\n",
    "for lstidx, (zuv, stack) in enumerate(zip(zsquare, cross_stacks)):\n",
    "    inpaint_flags = stack.inpainted()\n",
    "    for iap, (a, b) in enumerate(zuv.antpairs):\n",
    "        for ipol, pol in enumerate(zuv.pols):\n",
    "            pol = {'ee': 0, 'nn': 1}[pol]\n",
    "\n",
    "\n",
    "            for night, zsqn in enumerate(zuv.metrics[:, iap, :, ipol]):\n",
    "                jdint = zuv.nights[night]\n",
    "\n",
    "                # Get contiguous regions of bad (|Z| > 3) data\n",
    "                badfreqs = np.nonzero(zsqn > 9)[0]\n",
    "                if len(badfreqs) > 0:\n",
    "                    ranges = consecutive(badfreqs)\n",
    "\n",
    "                    for rng in ranges:\n",
    "                        allbad[(lstidx, a, b, pol, jdint, rng[0], rng[1])] = zsqn[rng[0]:rng[1]]\n",
    "\n",
    "                if stackconf.inpaint_files is not None:\n",
    "                    badfreqs = np.nonzero(inpaint_flags[night, iap, :, ipol])\n",
    "                    if len(badfreqs) > 0:\n",
    "                        ranges = consecutive(badfreqs)\n",
    "\n",
    "                        for rng in ranges:\n",
    "                            allbad[(lstidx, a, b, pol, jdint, rng[0], rng[1])] = zsqn[rng[0]:rng[1]]\n",
    "    \n",
    "                else:\n",
    "                    # Get contiguous regions of inpainted data (anything that is flagged outside FM)\n",
    "                    for band in inpaint_bands:\n",
    "                        badfreqs = np.nonzero(stack.flags[night, iap, band, ipol])[0]\n",
    "\n",
    "                        if len(badfreqs) > 0:\n",
    "                            ranges = consecutive(badfreqs)\n",
    "\n",
    "                            for rng in ranges:\n",
    "                                inpainted_regions[(lstidx, a, b, pol, jdint, rng[0], rng[1])] = zsqn[band][rng[0]:rng[1]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f321de-8fd9-41b5-a2fb-92d5ff4d94db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_lengths = [b - a for _, _, _, _, _, a, b in allbad.keys()]\n",
    "if len(chunk_lengths) > 0:\n",
    "    print(\"Biggest Frequency Chunk With |Z|>3: \", np.max(chunk_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61998a93-638a-4f4b-9e54-161ecc543691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save_metric_data:\n",
    "    # Write out the \"bad\" data\n",
    "    fname = out_fname.format(kind=\"HIGHZ\")\n",
    "\n",
    "    with h5py.File(outdir / fname, 'w') as fl:\n",
    "        fl['indices'] = np.array(list(allbad.keys()))  # integer array\n",
    "        fl['zsq'] = np.concatenate(tuple(allbad.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce532f-fa59-4d6e-90bd-9737b71c9c8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T14:31:20.304124Z",
     "iopub.status.busy": "2024-03-20T14:31:20.303539Z",
     "iopub.status.idle": "2024-03-20T14:31:20.310295Z",
     "shell.execute_reply": "2024-03-20T14:31:20.308960Z",
     "shell.execute_reply.started": "2024-03-20T14:31:20.304075Z"
    }
   },
   "source": [
    "#### Histogram of freq-chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab2c4c-8b5c-4847-bf56-ebda5e1bad1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots and len(chunk_lengths) > 0:\n",
    "    plt.hist(chunk_lengths, bins=np.arange(np.min(chunk_lengths), np.max(chunk_lengths)+1))\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Channel-Chunk Length with |Z|>3\")\n",
    "    plt.ylabel(\"Number of Occurences\");\n",
    "elif make_plots:\n",
    "    print(\"No |Z| > 3 data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106c9f8-052d-4231-847d-935b3641fed2",
   "metadata": {},
   "source": [
    "#### BoxPlots of Z^2 across axis chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a624ebb-096a-46bf-8eaa-c09e0abdb1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _set_boxplot_ax_props(nboxes: int, ax):\n",
    "    ax.axhline(zdist_pred.ppf(0.5), ls='-', color='gray')\n",
    "    ax.fill_between([-0.5, nboxes-0.5], [zdist_pred.ppf(0.16)]*2, [zdist_pred.ppf(0.84)]*2, color='gray', alpha=0.2)\n",
    "    ax.fill_between([-0.5, nboxes-0.5], [zdist_pred.ppf(0.02)]*2, [zdist_pred.ppf(0.98)]*2, color='gray', alpha=0.2)\n",
    "    \n",
    "    ax.axhline(1, ls='--', color='C3', lw=1)\n",
    "    ax.set_ylim(1e-1, None)\n",
    "    ax.set_xlim(-0.5, nboxes-0.5)\n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel(r\"$Z^2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45617ebd-403f-42e0-9b7d-7af8ae6ddf08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zsq_flags = [(stack.flagged_or_inpainted() | (~np.isfinite(zsq.metrics))) for zsq, stack in zip(zsquare, cross_stacks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaccced-bd4b-4fef-b429-a3265ee6ead0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def box_plot_all_groups(zscores, stacks):\n",
    "    fig, axx = plt.subplots(len(subsets), 1, sharex=True, figsize=(12, 3*len(subsets)), layout='constrained')\n",
    "\n",
    "    allbls = [(a, b, p) for a, b in stackconf.antpairs for p in stackconf.pols]\n",
    "\n",
    "    for j, (name, selector) in enumerate(subsets.items()):\n",
    "        ax = axx[j]\n",
    "            \n",
    "        for i, band in enumerate(bands_considered):\n",
    "            for n, night in enumerate(data_jd_ints):\n",
    "                allz = lstmet.get_compressed_zscores(\n",
    "                    zscores, band=band, nights=night, bl_selectors=selector,\n",
    "                    flags = zsq_flags\n",
    "                )\n",
    "                \n",
    "                bplot = ax.boxplot(\n",
    "                    allz, positions = [i-0.3 + 0.05*n], \n",
    "                    showfliers=False, whis=(0,100), showmeans=True,\n",
    "                    labels=[f\"chs {band[0]}-{band[1]}\" if (n==len(data_jd_ints)//2 and j==(len(subsets)-1)) else \"\"], \n",
    "                )\n",
    "                bplot['boxes'][0].set_color(styles[night]['color'])\n",
    "                bplot['boxes'][0].set_linestyle(styles[night]['ls'])\n",
    "                bplot['whiskers'][0].set_color(styles[night]['color'])\n",
    "                bplot['whiskers'][0].set_linestyle(styles[night]['ls'])\n",
    "                bplot['whiskers'][1].set_color(styles[night]['color'])\n",
    "                bplot['whiskers'][1].set_linestyle(styles[night]['ls'])\n",
    "                \n",
    "                bplot['caps'][0].set_color(styles[night]['color'])\n",
    "                bplot['caps'][1].set_color(styles[night]['color'])\n",
    "                \n",
    "                bplot['means'][0].set_marker(\"*\")\n",
    "                bplot['means'][0].set_markerfacecolor(styles[night]['color'])\n",
    "                bplot['means'][0].set_markeredgecolor(styles[night]['color'])\n",
    "                bplot['means'][0].set_markersize(10)\n",
    "                \n",
    "                if i==0 and j==0:\n",
    "                    # Dummy lines for legend\n",
    "                    ax.plot([1,2], [np.nan, np.nan], **styles[night], label=str(night))\n",
    "                    \n",
    "        _set_boxplot_ax_props(len(bands_considered), ax)\n",
    "        ax.set_ylabel(name.replace(\" baselines\", \"\"))\n",
    "    \n",
    "    axx[0].legend(ncols=3)\n",
    "    \n",
    "    return axx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415df566-008c-411a-bcf0-652a530d703d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    box_plot_all_groups(zsquare, cross_stacks);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f54eab-7e8b-4f2d-9f56-9cd4d616aaa9",
   "metadata": {},
   "source": [
    "### Mean Z^2 Over Different Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933726e7-b4e1-4a36-a54d-33a56ee9feb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c298a-7a97-4976-84dd-68c7f89c145b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_zsquare(axis, **kw):\n",
    "    return [\n",
    "        lstmet.reduce_stack_over_axis(\n",
    "            np.ma.mean, lstmet.downselect_zscores(zsq, flags=flg, **kw), axis=axis\n",
    "        )  for zsq, flg in zip(zsquare, zsq_flags)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907412f-4d20-4473-a913-8a1503775394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['band_reduced_mean'] = {}\n",
    "for band in bands_considered:\n",
    "    metrics['band_reduced_mean'][band] = reduce_zsquare(band=band, axis='freqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1494c6b-a640-4b3d-8a8f-a6a5122a09cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['bl_reduced_mean'] = {}\n",
    "allbls = [(a,b,p) for a,b in stackconf.antpairs for p in stackconf.pols]\n",
    "\n",
    "for j, (name, selector) in enumerate(subsets.items()):\n",
    "    metrics['bl_reduced_mean'][name] = reduce_zsquare(bl_selectors=selector, axis='bls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10debe1f-74dc-4f9f-8aa5-596b749f8454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['night_reduced_mean'] = reduce_zsquare(axis='nights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593f6ae-e3f4-4d05-b789-27b384b4ffa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['night_and_bl_reduced_mean'] = {}\n",
    "\n",
    "for j, (name, selector) in enumerate(subsets.items()):    \n",
    "    metrics['night_and_bl_reduced_mean'][name] = reduce_zsquare(bl_selectors=selector, axis=(\"nights\", \"bls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fec29c-2154-4b44-91fb-8448d1eac73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['night_and_band_reduced_mean'] = {}\n",
    "\n",
    "for band in bands_considered:\n",
    "    metrics['night_and_band_reduced_mean'][band] = reduce_zsquare(band=band, axis=('nights', 'freqs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cacff58-e86f-46e0-adae-31c734491603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['bl_and_band_reduced_mean'] = {}\n",
    "\n",
    "for j, (name, selector) in enumerate(subsets.items()):\n",
    "    for band in bands_considered:\n",
    "        metrics['bl_and_band_reduced_mean'][(band, name)] = reduce_zsquare(band=band, bl_selectors=selector, axis=('bls', 'freqs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edd1b0-a47e-4f78-b27d-c88cf5ffbaff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics['all_reduced_mean'] = {}\n",
    "\n",
    "for j, (name, selector) in enumerate(subsets.items()):    \n",
    "    for band in bands_considered:\n",
    "        metrics['all_reduced_mean'][(band, name)] = reduce_zsquare(band=band, bl_selectors=selector, axis=('bls', 'freqs', 'nights'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298113bf-abbb-456a-ad51-13c151f1cefe",
   "metadata": {},
   "source": [
    "#### Plot Totally Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872050f-7a20-4839-bcd5-1ad135875e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_styles = {name: {'color': f\"C{i%len(subsets)}\", 'ls': ['-', '--', ':', '-.'][i//4]} for i, name in enumerate(subsets.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87967b6-baf0-4b2d-8e80-0cb59851ef1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    done = set()\n",
    "    for (band, subset_name), means in metrics['all_reduced_mean'].items():\n",
    "        mid = np.mean(band)\n",
    "        size=0 if band[1]-band[0]==200 else (1 if band[1]-band[0] < 1500 else 2)\n",
    "\n",
    "        plt.errorbar(\n",
    "            [np.mean(band)], \n",
    "            means[0], \n",
    "            xerr=[[mid - band[0]]], \n",
    "            marker='ox*'[size], \n",
    "            markersize=8, \n",
    "            **subset_styles[subset_name], \n",
    "            label=subset_name.replace(\"baselines\", \"\") if subset_name not in done else None\n",
    "        )\n",
    "        done.add(subset_name)\n",
    "    plt.legend(ncols=2)\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dcd393-f774-458b-a714-b30fcde3cd0a",
   "metadata": {},
   "source": [
    "#### Plot Reduced over Nights + Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c6f4b-5a3f-4c6b-8371-25adbb6a7b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_baseline_zsq_plot(zscores, stack):\n",
    "    # TODO: need a better cmap to easily see what's \"good\" and \"bad\"\n",
    "    \n",
    "    fig, axx = plt.subplots(len(bands_considered)-3, 2, sharey=True, figsize=(24, 5*(len(bands_considered)-3)), layout='constrained')\n",
    "    \n",
    "    cmap = mpl.colors.ListedColormap([\"C0\", f\"C1\", f\"C3\"])\n",
    "    for i, band in enumerate(bands_considered):\n",
    "        if band[1] - band[0] > 200:\n",
    "            continue\n",
    "\n",
    "        ax = axx[i]\n",
    "        \n",
    "        mean_zsq = metrics['night_and_band_reduced_mean'][band][0]\n",
    "    \n",
    "        uvws = stack.uvw_array[:stack.Nbls][:, :2]\n",
    "        uvws[uvws[:, 1] < 0] *= -1\n",
    "\n",
    "        ax[0].scatter(uvws[:, 0], uvws[:, 1], c=mean_zsq[:, 0], norm=mpl.colors.LogNorm( vmin=1, vmax=1000), marker='H', s=60, cmap=cmap)\n",
    "        ax[0].set_title(stackconf.pols[0])\n",
    "        ax[0].set_aspect(\"equal\", 'datalim')\n",
    "        ax[0].set_xlim(-200, 200)\n",
    "\n",
    "        cbar = ax[1].scatter(uvws[:, 0], uvws[:, 1], c=mean_zsq[:, 1], norm=mpl.colors.LogNorm( vmin=1, vmax=1000), marker='H', s=60, cmap=cmap)\n",
    "        ax[1].set_title(stackconf.pols[1])\n",
    "        ax[1].set_aspect(\"equal\", 'datalim')\n",
    "        ax[1].set_xlim(-200, 200)\n",
    "        ax[0].grid(True)\n",
    "        ax[1].grid(True)\n",
    "        \n",
    "        ax[0].set_ylabel(str(band))\n",
    "        \n",
    "        plt.colorbar(cbar, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c1f27-2b69-491a-8910-6e67a7acc9f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    make_baseline_zsq_plot(zsquare, cross_stacks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661fba7-a599-4fa4-b308-9ea0cd94eec0",
   "metadata": {},
   "source": [
    "#### Plot Reduced over Nights and bls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4740d-28eb-4394-b32e-1aacda366bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_excess_variance_wrt_freq():\n",
    "    for subset, zsq in metrics['night_and_bl_reduced_mean'].items():\n",
    "        # do the mean over the two LST bins here...\n",
    "        zsq = np.nanmean(zsq, axis=0)\n",
    "        \n",
    "        plt.plot(stackconf.config.datameta.freq_array / 1e6, zsq, label=subset.replace(\"baselines\", \"\"), **subset_styles[subset])\n",
    "        \n",
    "    plt.xlabel(\"Freq [MHz]\")\n",
    "    plt.ylabel(r\"Mean $Z^2$ across Nights, LSTs and Baselines\")\n",
    "    plt.legend(ncols=2)\n",
    "    plt.ylim(7e-1, 100)\n",
    "    plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b636d-a4ce-431c-a15f-144a5b22d9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    plot_excess_variance_wrt_freq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaefd51-59e9-40bb-9ace-029db67450ff",
   "metadata": {},
   "source": [
    "#### Plot Reduced over Bls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b067b0-0f47-473f-849e-48b8cb91b8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_reduced_over_bls(zstack):\n",
    "    images = {}\n",
    "\n",
    "    for subset, zsqs in metrics['bl_reduced_mean'].items():\n",
    "        images[subset] = np.ones((len(data_jd_ints), len(zstack.freq_array)), dtype=float) * np.nan\n",
    "\n",
    "        for ijd, jd in enumerate(data_jd_ints):\n",
    "            if jd not in zstack.nights:\n",
    "                continue\n",
    "\n",
    "            jdidx = zstack.nights.tolist().index(jd)\n",
    "            images[subset][ijd] = zsqs[0][jdidx]\n",
    "\n",
    "    nrows = int(np.ceil(len(subsets)/3))\n",
    "\n",
    "    fig, ax = plt.subplots(nrows, 3, sharex=True, sharey=True, layout='constrained', figsize=(14, 3*nrows))\n",
    "\n",
    "    cmap = mpl.colors.ListedColormap([\"C0\", \"C1\", \"C3\"])\n",
    "\n",
    "    for i, (key, img) in enumerate(images.items()):\n",
    "        axx = ax.flatten()[i]\n",
    "        plt.sca(axx)\n",
    "\n",
    "        cbar = plt.imshow(\n",
    "            img, norm=mpl.colors.LogNorm( vmin=1, vmax=1000),\n",
    "            origin='lower',\n",
    "            extent=(\n",
    "                zstack.freq_array.min()/1e6, \n",
    "                zstack.freq_array.max()/1e6,\n",
    "                0,\n",
    "                len(data_jd_ints)\n",
    "            ),\n",
    "            cmap=cmap, aspect='auto',\n",
    "            interpolation='none',\n",
    "        )\n",
    "\n",
    "        axx.yaxis.set_ticks(np.arange(img.shape[0]) +0.5)\n",
    "        axx.yaxis.set_ticklabels(data_jd_ints)\n",
    "\n",
    "        axx.set_title(key.replace(\"baselines\", \"\"), pad=-3)\n",
    "\n",
    "        if i < 3:\n",
    "            axx.tick_params('x', labeltop=True, labelbottom=False, top=True)\n",
    "\n",
    "    for j in range(i+1, ax.size):\n",
    "        ax.flatten()[j].axis('off')\n",
    "\n",
    "    cbar = plt.colorbar(cbar, ax = ax)\n",
    "    cbar.set_label(r\"Mean $Z^2$ over bl subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee644b1c-0ae0-4e0c-a7f7-c6e7f4d860e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    plot_reduced_over_bls(zsquare[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66744163-0286-4fbd-a26f-d0774b3baa71",
   "metadata": {},
   "source": [
    "### Plot Selection of the Worst Visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a6d8e-99c7-4456-b42e-2a376cbac976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_visibilities_per_type(\n",
    "    lstbin_blpols: list[tuple[int, tuple[int, int, str]]], \n",
    "    stacks: list[UVData],\n",
    "    stats: list[lstmet.LSTBinStats],\n",
    "    auto_stats: list[lstmet.LSTBinStats],\n",
    "    comments: list[str],\n",
    "    zscores: list[lstbin.binning.LSTStack],\n",
    "    freq_range=None | tuple[float, float] | list[tuple[int, int]], \n",
    "    label=None, \n",
    "    yrange=None,\n",
    "    alpha=0.5,\n",
    "):\n",
    "    all_figs = []\n",
    "    \n",
    "    lststyle = dict(color='k', lw=3, zorder=-1)\n",
    "    meta = stackconf.config.datameta\n",
    "    \n",
    "    # Get a mask that says which channels are *simultaneously* inpainted.\n",
    "    simul_inpmask = np.zeros(meta.Nfreqs, dtype=bool)\n",
    "    for band in inpaint_bands:\n",
    "        simul_inpmask[band] = True\n",
    "\n",
    "    if isinstance(freq_range, tuple):\n",
    "        mask = (meta.freq_array >= freq_range[0]) & (meta.freq_array < freq_range[1])\n",
    "        freqs=meta.freq_array[mask]/1e6\n",
    "    else:\n",
    "        mask = slice(None)\n",
    "        freqs = meta.freq_array/1e6\n",
    "\n",
    "    handles = []\n",
    "    for jdint, style in styles.items():\n",
    "        handles.append(mpl.lines.Line2D([0], [0], label=str(jdint), alpha=alpha, **style))\n",
    "\n",
    "            \n",
    "    for i, (comment, (lstidx, blpol)) in enumerate(zip(comments, lstbin_blpols)):\n",
    "        if isinstance(freq_range, list):\n",
    "            this_range = freq_range[i]\n",
    "            \n",
    "            # pad the range a bit\n",
    "            this_range = (max(this_range[0] - 100, 0), min(this_range[1]+100, 1536))\n",
    "            mask = slice(this_range[0], this_range[1])\n",
    "            freqs = meta.freq_array[mask]/1e6\n",
    "            \n",
    "        stack = stacks[lstidx]\n",
    "        zscore = zscores[lstidx]\n",
    "        \n",
    "        rawd = stack.get_data(blpol)[:, mask]        \n",
    "        rawf = stack.get_flags(blpol)[:, mask]\n",
    "        rawn = stack.get_nsamples(blpol)[:, mask]\n",
    "        \n",
    "        if np.all(rawn >= 0):\n",
    "            inp = rawf & simul_inpmask[mask]\n",
    "        else:\n",
    "            inp = rawn < 0\n",
    "        \n",
    "        lstf = stats[lstidx].flags[blpol][mask]\n",
    "        lstd = stats[lstidx].mean[blpol][mask]\n",
    "        \n",
    "        lstmed = lstd  # actually mean\n",
    "        \n",
    "        iap = zscore.antpairs.index(blpol[:2])\n",
    "        ipol = zscore.pols.index(blpol[2])\n",
    "        \n",
    "        zsq = zscore.metrics[:, iap, mask, ipol]\n",
    "        \n",
    "        if np.all(lstf):\n",
    "            print(\"ALL FLAGGED\")\n",
    "            continue\n",
    "            \n",
    "        fig, ax = plt.subplots(\n",
    "            4, 2, \n",
    "            sharex=True, figsize=(15, 8), \n",
    "            constrained_layout=True, gridspec_kw={'height_ratios': (2,1,2,1)}\n",
    "        )\n",
    "        \n",
    "        mag = np.where(rawf, np.nan, np.abs(rawd))\n",
    "        rl = np.where(rawf, np.nan, rawd.real)\n",
    "        im = np.where(rawf, np.nan, rawd.imag)\n",
    "        \n",
    "        maglstbin = np.where(lstf, np.nan, np.abs(lstd))\n",
    "        rllstbin = np.where(lstf, np.nan, lstd.real)\n",
    "        imlstbin = np.where(lstf, np.nan, lstd.imag)\n",
    "        \n",
    "        rllstbin_med = np.where(lstf, np.nan, lstmed.real)\n",
    "        imlstbin_med = np.where(lstf, np.nan, lstmed.imag)\n",
    "                \n",
    "        pred_std = np.sqrt(lstmet.get_nightly_predicted_variance(blpol, stack=stack, auto_stats = auto_stats[lstidx]) / 2)[:, mask]\n",
    "        \n",
    "        ax[0, 0].plot(freqs, maglstbin, **lststyle)\n",
    "        ax[0, 1].plot(freqs, rllstbin, **lststyle)                \n",
    "        ax[2, 1].plot(freqs, imlstbin, **lststyle)\n",
    "        \n",
    "        for jdidx, jdint in enumerate(stack.nights):\n",
    "            style = styles[jdint]\n",
    "\n",
    "            if np.all(rawf[jdidx]):\n",
    "                continue\n",
    "\n",
    "            thisinp = inp[jdidx]\n",
    "            if np.any(thisinp):\n",
    "                inp_ranges = consecutive(np.nonzero(thisinp)[0])\n",
    "            else:\n",
    "                inp_ranges = []\n",
    "            \n",
    "            # Amplitude and Phase\n",
    "            ax[0, 0].plot(freqs, mag[jdidx], **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[0, 0].fill_between(freqs[rng[0]:rng[1]], mag[jdidx, rng[0]:rng[1]], maglstbin[rng[0]:rng[1]], color=style['color'], alpha=0.2)\n",
    "                \n",
    "            ax[1, 0].plot(freqs, mag[jdidx] - maglstbin, **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[1, 0].fill_between(freqs[rng[0]:rng[1]], mag[jdidx, rng[0]:rng[1]] - maglstbin[rng[0]:rng[1]], 0, color=style['color'], alpha=0.2)\n",
    "            \n",
    "            ax[2, 0].plot(freqs, zsq[jdidx], **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[2, 0].fill_between(freqs[rng[0]:rng[1]], zsq[jdidx, rng[0]:rng[1]], 0, color=style['color'], alpha=0.2)\n",
    "\n",
    "            # Real / Imag\n",
    "            ax[0, 1].plot(freqs, rl[jdidx], **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[0, 1].fill_between(freqs[rng[0]:rng[1]], rl[jdidx, rng[0]:rng[1]], rllstbin[rng[0]:rng[1]], color=style['color'], alpha=0.2)\n",
    "            \n",
    "            rldiff = (rl[jdidx] - rllstbin_med)/pred_std[jdidx]\n",
    "            ax[1, 1].plot(freqs, rldiff, **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[1,1].fill_between(freqs[rng[0]:rng[1]], rldiff[rng[0]:rng[1]], 0, color=style['color'], alpha=0.2)\n",
    "            \n",
    "            ax[2, 1].plot(freqs, im[jdidx], **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[2, 1].fill_between(freqs[rng[0]:rng[1]], im[jdidx, rng[0]:rng[1]], imlstbin[rng[0]:rng[1]], color=style['color'], alpha=0.2)\n",
    "            \n",
    "            imdiff = (im[jdidx] - imlstbin_med)/pred_std[jdidx]\n",
    "            ax[3, 1].plot(freqs, imdiff, **style)\n",
    "            for rng in inp_ranges:\n",
    "                ax[3,1].fill_between(freqs[rng[0]:rng[1]], imdiff[rng[0]:rng[1]], 0, color=style['color'], alpha=0.2)\n",
    "\n",
    "            if yrange:\n",
    "                ax[0, 0].set_ylim(yrange)\n",
    "\n",
    "        ax[1,1].axhline(4, color='gray', ls='--')\n",
    "        ax[1,1].axhline(-4, color='gray', ls='--')\n",
    "\n",
    "        ax[3,1].axhline(4, color='gray', ls='--')\n",
    "        ax[3,1].axhline(-4, color='gray', ls='--')\n",
    "            \n",
    "        bl_coords = stackconf.config.datameta.antpos_enu[blpol[0]] - stackconf.config.datameta.antpos_enu[blpol[1]]\n",
    "        \n",
    "        fig.suptitle(\n",
    "            f\"Baseline: {blpol} [{bl_coords[0]:.1f}-EW, {bl_coords[1]:.1f}-NS]. \"\n",
    "            f\"LST = {stackconf.lst_grid[0]*12/np.pi:.5f} hr.\"\n",
    "        )\n",
    "        ax[-1, 0].set_xlabel(\"Frequency [MHz]\")\n",
    "        ax[-1, 1].set_xlabel(\"Frequency [MHz]\")\n",
    "        \n",
    "        ax[0, 0].set_ylabel(\"Magnitude\")\n",
    "        ax[0, 1].set_ylabel(\"Real Part\")\n",
    "        \n",
    "        ax[1, 0].set_ylabel(\"Magnitude Diff\")\n",
    "        ax[1, 1].set_ylabel(\"Real Z-score\")\n",
    "        ax[1, 1].set_ylim(-7, 7)\n",
    "        \n",
    "        ax[2, 0].set_ylabel(r\"$Z^2$\")\n",
    "        ax[2, 0].set_yscale('log')\n",
    "        ax[2, 0].set_ylim(1e-1,)\n",
    "        \n",
    "        ax[2, 1].set_ylabel(\"Imag Part\")\n",
    "        \n",
    "        #ax[3, 0].set_ylabel(\"Phase Diff\")\n",
    "        ax[3, 1].set_ylabel(\"Imag Z-score\")\n",
    "        ax[3, 1].set_ylim(-7, 7)\n",
    "        ax[0, 0].legend(handles=handles, ncols=5)\n",
    "\n",
    "        ax[0,1].text(0.95, 0.95, comment, transform=ax[0,1].transAxes, ha='right', va='top')\n",
    "\n",
    "        for axx in ax.flatten():\n",
    "            for line in range(0, 1536, 200):\n",
    "                axx.axvline(meta.freq_array[line]/1e6, color='gray', alpha=0.4)\n",
    "            axx.set_xlim(freqs[0], freqs[-1])\n",
    "            \n",
    "        all_figs.append(fig)\n",
    "        \n",
    "    return all_figs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe47d99-b5b3-4efa-aa53-25ee8429717e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_worst_mean_over_each_band(zscores, n=1):\n",
    "    bad_fellas = {}\n",
    "\n",
    "    nights0 = [data_jd_ints.index(jd) for jd in zscores[0].time_array[::zscores[0].Nbls].astype(int)]\n",
    "    nights1 = [data_jd_ints.index(jd) for jd in zscores[1].time_array[::zscores[1].Nbls].astype(int)]\n",
    "        \n",
    "    newmeans = {band: np.ones((len(zscores), len(data_jd_ints), len(stackconf.antpairs), len(stackconf.pols)))*np.nan for band in metrics['band_reduced_mean']}\n",
    "    \n",
    "    for band, zsqs in metrics['band_reduced_mean'].items():\n",
    "        # zsqs is length(lstbins), where each is an array of shape (nights, antpairs, pols)\n",
    "        # however, the number of nights for each lstbin could be different, so make them the same here....\n",
    "        newmeans[band][0, nights0] = zsqs[0]\n",
    "        newmeans[band][1, nights1] = zsqs[1]\n",
    "        \n",
    "    lst_night_bl_pols = [(lst, jd, bl + (pol,)) for lst in range(len(zscores)) for jd in data_jd_ints for bl in stackconf.antpairs for pol in stackconf.pols]\n",
    "    \n",
    "    for band, zsq in newmeans.items():\n",
    "        zsq = np.where(np.isnan(zsq.flatten()), -1, zsq.flatten())\n",
    "        \n",
    "        worst_idx = np.argpartition(zsq, -n)[-n:]\n",
    "        worst_zsq = zsq[worst_idx]\n",
    "        worst_idx = worst_idx[np.argsort(-worst_zsq)]\n",
    "        \n",
    "        for idx, z in zip(worst_idx, worst_zsq):\n",
    "            lst, jd, bl = lst_night_bl_pols[idx]\n",
    "            \n",
    "            if (lst, bl) not in bad_fellas:\n",
    "                bad_fellas[(lst, bl)] = []\n",
    "                \n",
    "            bad_fellas[(lst, bl)].append((jd, z, fr\"Worst $Z^2$ in band {band[0]}-{band[1]}\", band))\n",
    "\n",
    "    return bad_fellas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa5d88-9894-4ad1-87cc-e8bc2d0ae345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_worst_mean_for_continuously_bad_stuff(zscores, n=1):\n",
    "    \n",
    "    bad_fellas = {}\n",
    "    \n",
    "    chsizes = [(1, 2), (2, 10), (10, 20), (20, 50), (50, 100), (100, 1536)]\n",
    "    sized = {ch: {} for ch in chsizes}\n",
    "    for k, v in allbad.items():\n",
    "        s = k[-1] - k[-2]  # size of chunk\n",
    "        if s == 1:\n",
    "            continue\n",
    "        \n",
    "        for i, ch in enumerate(chsizes):\n",
    "            if ch[0] <= s < ch[1]:\n",
    "                sized[ch][k] = v\n",
    "\n",
    "    for chsize, thesebads in sized.items():\n",
    "        if not thesebads:\n",
    "            continue\n",
    "            \n",
    "        keys = list(thesebads.keys())\n",
    "        meanz = np.array([np.nanmean(v) for v in thesebads.values()])\n",
    "        \n",
    "        nn = min(n, len(meanz))\n",
    "        worst_idx = np.argpartition(meanz, -nn)[-nn:]\n",
    "        worst_zsq = meanz[worst_idx]\n",
    "        worst_idx = worst_idx[np.argsort(-worst_zsq)]\n",
    "\n",
    "        for idx, z in zip(worst_idx, worst_zsq):\n",
    "            lst, a, b, pol, jdint, low, high = keys[idx]\n",
    "            bl = (a, b, stackconf.pols[pol])\n",
    "            \n",
    "            if (lst, bl) not in bad_fellas:\n",
    "            \n",
    "                bad_fellas[(lst, bl)] = []\n",
    "\n",
    "            bad_fellas[(lst, bl)].append((int(jdint), z, fr\"Worst $Z^2$ over {chsize[0]}-{chsize[1]} channels\",(low, high)))\n",
    "    return bad_fellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09d780-5163-4167-9f2f-823c2ad75fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_worst_continuous_bad_zscore(zscores, n=1):\n",
    "    bad_fellas = {}\n",
    "    nights0 = [data_jd_ints.index(jd) for jd in zscores[0].time_array[::zscores[0].Nbls].astype(int)]\n",
    "    nights1 = [data_jd_ints.index(jd) for jd in zscores[1].time_array[::zscores[1].Nbls].astype(int)]\n",
    "    \n",
    "    smallbands = [b for b in bands_considered if b[1] - b[0] <= 200]\n",
    "    \n",
    "    newmeans = np.ones(\n",
    "        (len(smallbands), len(zscores), len(data_jd_ints), len(stackconf.antpairs), len(stackconf.pols))\n",
    "    )*np.nan\n",
    "    \n",
    "    for i, band in enumerate(smallbands):\n",
    "        zsqs = metrics['band_reduced_mean'][band]\n",
    "        # zsqs is length(lstbins), where each is an array of shape (nights, antpairs, pols)\n",
    "        # however, the number of nights for each lstbin could be different, so make them the same here....\n",
    "        newmeans[i, 0, nights0] = zsqs[0]\n",
    "        newmeans[i, 1, nights1] = zsqs[1]\n",
    "\n",
    "    lst_night_bl_pols = [(lst, jd, bl + (pol,)) for lst in range(len(zscores)) for jd in data_jd_ints for bl in stackconf.antpairs for pol in stackconf.pols]\n",
    "\n",
    "    zsq = np.nanmin(newmeans, axis=0)\n",
    "    \n",
    "    zsq = np.where(np.isnan(zsq).flatten(), -1, zsq.flatten())\n",
    "    \n",
    "    nn = min(n, len(zsq))\n",
    "    worst_idx = np.argpartition(zsq, -nn)[-nn:]\n",
    "    worst_zsq = zsq[worst_idx]\n",
    "    worst_idx = worst_idx[np.argsort(-worst_zsq)]\n",
    "\n",
    "    for idx, z in zip(worst_idx, worst_zsq):\n",
    "        lst, jd, bl = lst_night_bl_pols[idx]\n",
    "\n",
    "        if (lst, bl) not in bad_fellas:\n",
    "            bad_fellas[(lst, bl)] = []\n",
    "\n",
    "        bad_fellas[(lst, bl)].append((jd, z, fr\"Worst min($Z^2$) over entire band\", (0, 1536)))\n",
    "\n",
    "    return bad_fellas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c78779-851d-4fc5-aa11-dfc9eeafa809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bad_inpaints(zscores, n=1):\n",
    "    \n",
    "    bad_fellas = {}\n",
    "    \n",
    "    nights = [zsq.nights.tolist() for zsq in zscores]\n",
    "\n",
    "    chsizes = [(2, 5), (5, 10), (10, 20)]    \n",
    "    sized = {ch: {} for ch in chsizes}\n",
    "    for k, v in inpainted_regions.items():\n",
    "        s = k[-1] - k[-2]  # size of chunk\n",
    "        if s == 1:\n",
    "            continue\n",
    "        \n",
    "        for i, ch in enumerate(chsizes):\n",
    "            if ch[0] <= s < ch[1]:\n",
    "                sized[ch][k] = v\n",
    "                \n",
    "    for chsize, bads in sized.items():\n",
    "        \n",
    "        \n",
    "        keys = list(bads.keys())\n",
    "        \n",
    "        meanz = np.array([\n",
    "            np.nanmean(zscores[lst].metrics[nights[lst].index(jdint), zscores[lst].antpairs.index((a,b)), low:high, pol]) \n",
    "            for (lst, a, b, pol, jdint, low, high) in bads.keys()\n",
    "        ])\n",
    "        \n",
    "        nn = min(n, len(meanz))\n",
    "        worst_idx = np.argpartition(meanz, -nn)[-nn:]\n",
    "        worst_zsq = meanz[worst_idx]\n",
    "        worst_idx = worst_idx[np.argsort(-worst_zsq)]\n",
    "\n",
    "        for idx, z in zip(worst_idx, worst_zsq):\n",
    "            lst, a, b, pol, jdint, low, high = keys[idx]\n",
    "            bl = (a, b, stackconf.pols[pol])\n",
    "            \n",
    "            if (lst, bl) not in bad_fellas:\n",
    "            \n",
    "                bad_fellas[(lst, bl)] = []\n",
    "\n",
    "            bad_fellas[(lst, bl)].append((int(jdint), z, fr\"Worst inpainted $Z^2$ for {chsize[0]}-{chsize[1]} chans\", (low, high)))\n",
    "    return bad_fellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dd92c-8099-45fe-91e8-6ecc727a9f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    worst_mean_over_each_band = get_worst_mean_over_each_band(zsquare, n=plot_n_worst)\n",
    "    worst_mean_for_continously_bad = get_worst_mean_for_continuously_bad_stuff(zsquare, n=plot_n_worst)\n",
    "    worst_minimum_zscores_over_bands = get_worst_continuous_bad_zscore(zsquare, n=plot_n_worst)\n",
    "    worst_inpainted_regions = get_bad_inpaints(zsquare, n=plot_n_worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e810f-721a-4113-a94a-c58488e12999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    # Merge all the things that we want to take a closer look at\n",
    "    badstuff = {}\n",
    "\n",
    "    for dct in (worst_mean_over_each_band, worst_mean_for_continously_bad, worst_minimum_zscores_over_bands, worst_inpainted_regions):\n",
    "        for k, v in dct.items():\n",
    "            if k not in badstuff:\n",
    "                badstuff[k] = []\n",
    "\n",
    "            badstuff[k].extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d30300-47df-4748-b139-bc65dd026490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    freq_ranges = [sum((vv[-1] for vv in v), start=()) for v in badstuff.values()]\n",
    "    freq_ranges = [(min(v), max(v)) for v in freq_ranges]\n",
    "\n",
    "    plot_visibilities_per_type(\n",
    "        lstbin_blpols= list(badstuff.keys()), \n",
    "        stacks= cross_stacks,\n",
    "        stats= cross_stats,\n",
    "        comments=[\"\\n\".join([f\"{vv[-2]}: {vv[0]}\" for vv in v]) for v in badstuff.values()],\n",
    "        freq_range=freq_ranges,\n",
    "        alpha=0.5,\n",
    "        zscores=zsquare,\n",
    "        auto_stats=auto_stats\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41bf66-9ebe-45dd-8c68-0a85754f5494",
   "metadata": {},
   "source": [
    "### Write Out Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f0b66-50b5-4557-af8f-98276692c89d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write out the \"bad\" data\n",
    "fname = out_fname.format(kind='LSTBIN-METRICS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c73052-e21e-4863-a918-53bf6b3583a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save_metric_data:\n",
    "    def write_metric(grp, metric: dict[str, list[np.ndarray]]):\n",
    "        for key in metric:\n",
    "            _grp = grp.create_group(str(key))\n",
    "\n",
    "            for i, lstbin in enumerate(metric[key]):\n",
    "                _grp[f'zsqmean-{i}'] = lstbin\n",
    "\n",
    "\n",
    "    with h5py.File(outdir / fname, 'w') as fl:\n",
    "\n",
    "        meta = fl.create_group(\"meta\")\n",
    "        meta['pols'] = stackconf.pols\n",
    "        meta['ant1'] = np.array([a for a, b in stackconf.antpairs])\n",
    "        meta['ant2'] = np.array([b for a, b in stackconf.antpairs])\n",
    "        meta['freqs'] = stackconf.config.datameta.freq_array\n",
    "        nights = meta.create_group(\"nights\")\n",
    "        for i, zsq in enumerate(zsquare):\n",
    "            nights[str(i)] = zsq.nights\n",
    "\n",
    "        mgrp = fl.create_group(\"metrics\")\n",
    "\n",
    "        for name, mtrc in metrics.items():\n",
    "            if name=='night_reduced_mean':\n",
    "                # night reduced mean is different -- simply an array\n",
    "                nrm = mgrp.create_group(\"night_reduced_mean\")\n",
    "                for i, val in enumerate(mtrc):\n",
    "                    nrm[f'zsqmean-{i}'] = val\n",
    "            else:\n",
    "                write_metric(mgrp.create_group(name), mtrc)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f27a43-3dfe-4823-a73b-42f01ff0c823",
   "metadata": {},
   "source": [
    "## Notebook Metadata and Software Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002e09a-a26a-4aaa-a29b-e5d64279b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metadata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hera_dev_kernel",
   "language": "python",
   "name": "hera_dev_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
